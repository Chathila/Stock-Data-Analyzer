{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e030378",
   "metadata": {},
   "source": [
    "# Data Analysis and Q&A Project Using a Local LLM\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project requires you to perform a comprehensive analysis of a company's stock data using only the provided data sources and a local LLM. Your analysis should answer the following six questions strictly based on the supplied data and documents‚Äîno external data is allowed. All generated answers must be firmly based on the provided data, without any fabricated content. In addition, your logic must be clear, and any attribution of events must be causally linked.\n",
    "\n",
    "---\n",
    "\n",
    "## Provided Data\n",
    "\n",
    "You will be provided with the following data sets:\n",
    "\n",
    "#### Stock Price Data (Json format)\n",
    "* Timeframe: Jan 22 to Feb 5\n",
    "* Fields: Open, High, Low, Close, Volume\n",
    "\n",
    "#### Quarterly Earnings Data for the Past Year (Json format)\n",
    "* Contains key financial indicators (e.g., revenue, eps) for each quarter.\n",
    "\n",
    "#### Full Earnings Transcript Call\n",
    "* The complete transcript of the earnings call, including management discussions and Q&A.\n",
    "\n",
    "#### Balance Sheet Data for the Past Year (Json format)\n",
    "* Includes assets, liabilities, and shareholders' equity information.\n",
    "\n",
    "#### News Articles\n",
    "* Full text of 10 news articles related to the company during the analysis period.\n",
    "\n",
    "---\n",
    "\n",
    "## Questions\n",
    "Using the provided data and a local LLM, you need to answer the following six questions:\n",
    "\n",
    "1. What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "2. Why did the price increase on Jan 30? Please provide potential factors.\n",
    "\n",
    "3. Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "4. With unsupervised Full Self Driving scheduled to launch in limited markets like Austin by June, what regulatory challenges does Tesla foresee for a nationwide or international rollout, and how is the company strategically preparing to address these hurdles?\n",
    "\n",
    "5. What insights can be concluded from the earnings call?\n",
    "\n",
    "6. Which key news events influenced the stock performance, and what insights do they offer?\n",
    "\n",
    "---\n",
    "\n",
    "## Project Requirements\n",
    "- #### Data Source Restriction:\n",
    "Only use the provided data and documents. No external data or information is allowed.\n",
    "\n",
    "- #### Answer Generation:\n",
    "All generated answers must strictly be based on the provided data and documents. The LLM should not \"invent\" information.\n",
    "\n",
    "- #### Clear Logic and Causal Relationships:\n",
    "For each question, your answers must clearly demonstrate logical reasoning, and any attribution of cause must be explicitly linked to events in the data.\n",
    "\n",
    "- #### Prompt Design:\n",
    "You must design your own prompts for calling the local LLM to ensure that the responses are generated strictly based on the analysis results.\n",
    "\n",
    "- #### Result Evaluation:\n",
    "After generating the answers, implement an evaluation step to assess whether the responses meet the above requirements in terms of data reliance, logical clarity, and correct causation.\n",
    "\n",
    "- #### Please put the answers to these 6 questions in a dict at the end of your submitted Python nodebook file.\n",
    "\n",
    "For example\n",
    "```code\n",
    "{ \"Q1 answer\": \"Answer1\", \"Q2 answer\": \"Answer2\", \"Q3 answer\": \"Answer3\", \"Q4 answer4\": \"Answer4\", \"Q5 answer\": \"Answer5\", \"Q6 answer\": \"Answer6\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9bdfc",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "* Transformers\n",
    "* Torch (PyTorch)\n",
    "* Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3ba393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./project-venv/lib/python3.11/site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in ./project-venv/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: pandas in ./project-venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: ipython in ./project-venv/lib/python3.11/site-packages (9.1.0)\n",
      "Requirement already satisfied: filelock in ./project-venv/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./project-venv/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./project-venv/lib/python3.11/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./project-venv/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./project-venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./project-venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./project-venv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./project-venv/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./project-venv/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./project-venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./project-venv/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./project-venv/lib/python3.11/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./project-venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./project-venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./project-venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: decorator in ./project-venv/lib/python3.11/site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./project-venv/lib/python3.11/site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./project-venv/lib/python3.11/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./project-venv/lib/python3.11/site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./project-venv/lib/python3.11/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./project-venv/lib/python3.11/site-packages (from ipython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./project-venv/lib/python3.11/site-packages (from ipython) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./project-venv/lib/python3.11/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./project-venv/lib/python3.11/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in ./project-venv/lib/python3.11/site-packages (from ipython) (4.13.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./project-venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./project-venv/lib/python3.11/site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./project-venv/lib/python3.11/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./project-venv/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in ./project-venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in ./project-venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./project-venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./project-venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./project-venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./project-venv/lib/python3.11/site-packages (from stack_data->ipython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./project-venv/lib/python3.11/site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./project-venv/lib/python3.11/site-packages (from stack_data->ipython) (0.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./project-venv/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers accelerate pandas ipython\n",
    "# %pip install torch # Install PyTorch if you dont have it downloading \n",
    "\n",
    "DATA_DIR = \"447_dataset\"\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "import datetime\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290d56f",
   "metadata": {},
   "source": [
    "## Loading and Running the Local LLM\n",
    "\n",
    "1. **Imports Transformers utilities**  \n",
    "   - `AutoModelForCausalLM`: generic class for loading any GPT‚Äëstyle model  \n",
    "   - `AutoTokenizer`: matching tokenizer for converting text ‚Üî tokens  \n",
    "   - `pipeline`: high‚Äëlevel helper that ties model + tokenizer into one callable  \n",
    "\n",
    "2. **Specifies the model repository**  \n",
    "   ```python\n",
    "   model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d52b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n",
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# The pipeline will automatically use the model and tokenizer you just loaded\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) # Load the tokenizer\n",
    "\n",
    " # Create a pipeline for text generation\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 2000, # Limit the number of tokens generated\n",
    "    \"return_full_text\": False, # Return only the generated text\n",
    "    \"do_sample\": True, # Use sampling to generate text\n",
    "    \"temperature\": 0.1,# Control the randomness of the output\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"top_p\": 0.9, # Control the diversity of the output\n",
    "    \"top_k\": 50, # Control the diversity of the output\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699af2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_system_prompt = ( \n",
    "    \"You are an expert financial data analyst LLM.\\n\"\n",
    "    \"You must ensure the following rules are followed:\\n\"\n",
    "    \"1. Use only the data summaries provided in the prompt.\\n\"\n",
    "    \"2. Show clear step-by-step reasoning, linking each claim directly to the data.\\n\"\n",
    "    \"3. Ensure all explanations are clear, logical, and accurate.\\n\"\n",
    "    \"4. Do not invent or hallucinate any information.\\n\"\n",
    "    \"After your answer, provide a checklist summary indicating whether each criterion is satisfied. \"\n",
    "    \"If any criterion is not met, include a brief explanation.\"\n",
    ")\n",
    "\n",
    "\n",
    "def trim_reasoning(raw):\n",
    "    tag = \"</think>\"\n",
    "    idx = raw.find(tag)\n",
    "\n",
    "    if idx != -1:\n",
    "        answer = raw[idx + len(tag):].strip()\n",
    "    else:\n",
    "        answer = raw.strip()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1d4bb",
   "metadata": {},
   "source": [
    "### Question 1:What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "#### Prompt construction\n",
    "\n",
    "* Here we need to monitor the performance of the tesla stock over the specified days. To monitor the performance of the stock the LLM just need to understand the how the pricing of the stock was through the given period hence why the LLM will need to see the infomation in the `prices.json` file.\n",
    "* To supplement the LLM to construct its answer we will also show the information in `balancesheet.json` so it can pickup on any trends to as why stock prices deviated and change through the mentioned days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55617ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-22: Open $416.81, High $428.00, Low $414.59, Close $415.11, Volume 60,963,300\n",
      "2025-01-23: Open $416.06, High $420.73, Low $408.95, Close $412.38, Volume 50,690,600\n",
      "2025-01-24: Open $414.45, High $418.88, Low $405.78, Close $406.58, Volume 56,427,100\n",
      "2025-01-27: Open $394.80, High $406.69, Low $389.00, Close $397.15, Volume 58,125,500\n",
      "2025-01-28: Open $396.91, High $400.59, Low $386.50, Close $398.09, Volume 48,910,700\n",
      "2025-01-29: Open $395.21, High $398.59, Low $384.48, Close $389.10, Volume 68,033,600\n",
      "2025-01-30: Open $410.78, High $412.50, Low $384.41, Close $400.28, Volume 98,092,900\n",
      "2025-01-31: Open $401.53, High $419.99, Low $401.34, Close $404.60, Volume 83,568,200\n",
      "2025-02-03: Open $386.68, High $389.17, Low $374.36, Close $383.68, Volume 93,732,100\n",
      "2025-02-04: Open $382.63, High $394.00, Low $381.40, Close $392.21, Volume 57,072,200\n",
      "2025-02-05: Open $387.51, High $388.39, Low $375.53, Close $378.17, Volume 57,223,300\n"
     ]
    }
   ],
   "source": [
    "\"\"\"   \n",
    "This Function extracts the price information and converts the informations\n",
    "into a simple readable format to be included in the prompt to the LLM\n",
    "\"\"\"\n",
    "def get_prices_summary():\n",
    "    prices_path = os.path.join(DATA_DIR, \"prices.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(prices_path, \"r\") as f:\n",
    "        prices = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and index\n",
    "    prices[\"Date\"] = pd.to_datetime(prices[\"Date\"])\n",
    "    prices = prices.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build a human-readable summary for each day\n",
    "    daily_summaries = []\n",
    "    for date, row in prices.iterrows():\n",
    "        daily_summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Open ${row['Open']:.2f}, \"\n",
    "            f\"High ${row['Hight']:.2f}, \"\n",
    "            f\"Low ${row['Low']:.2f}, \"\n",
    "            f\"Close ${row['Close']:.2f}, \"\n",
    "            f\"Volume {int(row['Volume']):,}\"\n",
    "        )\n",
    "\n",
    "    # Join them into one block of text\n",
    "    daily_summary_text = \"\\n\".join(daily_summaries)\n",
    "    return daily_summary_text\n",
    "\n",
    "\n",
    "print(get_prices_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33e7d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'general_system_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Fill in the template with specific data\u001b[39;00m\n\u001b[32m     16\u001b[39m filled_user_prompt = user_prompt_template_q1.format(\n\u001b[32m     17\u001b[39m     price_info = get_prices_summary()\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m messages = [\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mgeneral_system_prompt\u001b[49m},\n\u001b[32m     22\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: filled_user_prompt},\n\u001b[32m     23\u001b[39m ]\n\u001b[32m     25\u001b[39m question1Answer = pipe(messages, **generation_args)\n\u001b[32m     26\u001b[39m display(Markdown(trimquestion1Answer[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m'\u001b[39m]))\n",
      "\u001b[31mNameError\u001b[39m: name 'general_system_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "user_prompt_template_q1 =( \"\"\"\n",
    "    Here is the summarized Tesla data for Jan‚ÄØ22 - Feb‚ÄØ5:\n",
    "    {price_info}\n",
    "\n",
    "    **Question:**  \n",
    "    What was the performance of Tesla stock over this period?\n",
    "                          \n",
    "    **Please:**\n",
    "    - Write a brief **Introduction** stating the question and data scope.  \n",
    "    - In your **Analysis**, cite the exact figures (dates, prices, percent changes, volumes).  \n",
    "    - Draw any causal insights clearly (e.g., ‚Äúthe drop on Feb‚ÄØ1 may be linked to‚Ä¶‚Äù).  \n",
    "    - Finish with a concise **Conclusion** summarizing overall performance.\n",
    "\"\"\")\n",
    "\n",
    "# Fill in the template with specific data\n",
    "filled_user_prompt = user_prompt_template_q1.format(\n",
    "    price_info = get_prices_summary()\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": filled_user_prompt},\n",
    "]\n",
    "\n",
    "question1Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question1Answer[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb7491",
   "metadata": {},
   "source": [
    "# Question 2 \n",
    "### Why did the price increase on Jan 30? Please provide potential factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc284196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</think>\n",
      "\n",
      "### What Happened?\n",
      "\n",
      "#### **Shares of Electric Vehicle pioneer Tesla (TSLA) fell 7.1% in the morning session after the Trump administration's new tariffs (25% on Canadian goods and 10% on Chinese products) shook markets.**\n",
      "\n",
      "#### **Separately, Tesla shares fell 5.1% from $1,000 to $7,394 five years ago.**\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Points from the Article**\n",
      "\n",
      "1. **Tesla shares have risen 1.4% since the beginning of the year, but at $384.48 per share, they are still trading 19.9% below its 52-week high of $479.86 from December 2024.**\n",
      "   \n",
      "   - **Wall Street analysts believe Tesla shares will bump higher in mid-Thursday trading after its disappointing fourth-quarter earnings update.**\n",
      "\n",
      "2. **CEO Elon Musk predicted Tesla's stock would reach $7,394 in mid-Thursday trading.**\n",
      "   \n",
      "   - **Musk also emphasized Tesla's long-term vision, saying 'this is the most important year for Tesla,' and 'when we look back on 2025 and the launch of unsupervised Full Self-Driving, true real-world AI that actually works... I think it probably will be viewed as maybe the most important year in Tesla's history.'**\n",
      "\n",
      "3. **Analysts overhaul Tesla stock price targets after Q4 earnings.**\n",
      "   \n",
      "   - **Musk's optimistic outlook for Tesla's 2025 and 2026 capital outlays is driving analysts to raise their price targets.**\n",
      "   \n",
      "   - **Wall Street analysts are also adjusting their price targets based on Tesla's performance in Q4.**\n",
      "\n",
      "4. **Tesla shares have added around $530 billion since late October and have been seen as one of the key beneficiaries of President Donald Trump's election in November as the company continues its pivot from its legacy automaking business to a focus on self-driving technologies, energy storage, and robotics.**\n",
      "\n",
      "5. **Musk also emphasized Tesla's long-term vision, saying 'this is the most important year for Tesla,' and 'when we look back on 2025 and the launch of unsupervised Full Self-Driving, true real-world AI that actually works... I think it probably will be viewed as maybe the most important year in Tesla's history.'**\n",
      "\n",
      "6. **Wall Street analysts are also adjusting their price targets based on Tesla's performance in Q4.**\n",
      "\n",
      "---\n",
      "\n",
      "### **Conclusion**\n",
      "\n",
      "- **Tesla shares have surpassed Wall Street analysts' price targets multiple times.**\n",
      "- **Musk's optimistic outlook for Tesla's 2025 and 2026 capital outlays is driving analysts to raise their price targets.**\n",
      "- **Wall Street analysts are also adjusting their price targets based on Tesla's performance in Q4.**\n",
      "\n",
      "- **Tesla shares have added around $530 billion since late October and have been seen as one of the key beneficiaries of President Donald Trump's election in November as the company continues its pivot from its legacy automaking business to a focus on self-driving technologies, energy storage, and robotics.**\n",
      "\n",
      "- **Musk also emphasized Tesla's long-term vision, saying 'this is the most important year for Tesla,' and 'when we look back on 2025 and the launch of unsupervised Full Self-Driving, true real-world AI that actually works... I think it probably will be viewed as maybe the most important year in Tesla's history.'**\n",
      "\n",
      "- **Wall Street analysts are also adjusting their price targets based on Tesla's performance in Q4.**\n",
      "\n",
      "---\n",
      "\n",
      "### **Final Note**\n",
      "\n",
      "- **Tesla shares have surpassed Wall Street analysts' price targets multiple times.**\n",
      "- **Musk's optimistic outlook for Tesla's 2025 and 2026 capital outlays is driving analysts to raise their price targets.**\n",
      "- **Wall Street analysts are also adjusting their price targets based on Tesla's performance in Q4.**\n",
      "\n",
      "---\n",
      "\n",
      "### **Answer**\n",
      "\n",
      "Yes, Tesla shares have surpassed Wall Street analysts' price targets multiple times.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "system_prompt_q2 = (\n",
    "    \"You are an expert financial analyst assistant in the United States. \"\n",
    "    \"Your job is to explain stock price moves using only the provided data. \"\n",
    "    \"You must be concise and give only the most critical information in your answer\"\n",
    "    \"Do not invent or fetch any outside information, everything must be grounded in the inputs.\"\n",
    ")\n",
    "\n",
    "user_prompt_q2 = \"\"\"\n",
    "\n",
    "Using only the news articles data and Tesla‚Äôs Jan‚ÄØ30 stock data, identify all plausible factors that contributed to the price uptick.\n",
    "Reference the specific news item (by title and date) or data point you‚Äôre using.  \n",
    "Explain the causal link to the price move. \n",
    "Do not use any external sources.  \n",
    "\n",
    "**Question** \n",
    "Why did Tesla‚Äôs stock price increase on January 30?\n",
    "\n",
    "Here are the news articles and price info:\n",
    "{input_data}\n",
    "\n",
    "\"Please respond in English!\"\n",
    "\"\"\"\n",
    "\n",
    "with open(\"447_dataset/news.json\", \"r\") as f:\n",
    "    news_data = json.load(f)\n",
    "\n",
    "news_json_str = json.dumps(news_data)\n",
    "\n",
    "# Example of how you'd fill & call it:\n",
    "filled_user = user_prompt_q2.format(input_data=news_json_str)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_q2},\n",
    "    {\"role\": \"user\",   \"content\": filled_user},\n",
    "]\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6428e1",
   "metadata": {},
   "source": [
    "### Question 3:Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "#### Data Used for Prompt construction\n",
    "\n",
    "* For the LLM to have any insight of quaterly financial information, I will provide it the `balancesheet.json` as this file contains the quaterly financial figures. We will use this data so the LLM is a aware of the performance of the previous 1-2 years. This gives the LLM a base to compare against the current financial quater( 2025 Q1). Since the balance sheet has a lot of infomation, we dont want to overload the LLM with too many features to consider when it comes up with its decison so we will handpick some important features from the balance sheet from each quater.\n",
    "\n",
    "\n",
    "* The Data found in the `earnings.json` also contains relavant financial information for the past five quaters, which the LLM can use compare the performance of the company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a75f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Balance Sheet Summary----------\n",
      "2023-12-31: Revenue $25.2M, Gross Profit $4.4M (17.6%), Operational Income $2.1M (8.2%), Net Income $7.9M (31.5%), EBITDA $3.5M, Total Expenses $23.1M, \n",
      "2024-03-31: Revenue $21.3M, Gross Profit $3.7M (17.4%), Operational Income $1.2M (5.5%), Net Income $1.2M (5.5%), EBITDA $2.9M, Total Expenses $20.1M, \n",
      "2024-06-30: Revenue $25.5M, Gross Profit $4.6M (18.0%), Operational Income $2.2M (8.7%), Net Income $1.5M (5.8%), EBITDA $3.3M, Total Expenses $23.3M, \n",
      "2024-09-30: Revenue $25.2M, Gross Profit $5.0M (19.8%), Operational Income $2.8M (11.0%), Net Income $2.2M (8.6%), EBITDA $4.2M, Total Expenses $22.4M, \n",
      "2024-12-31: Revenue $25.7M, Gross Profit $4.2M (16.3%), Operational Income $1.6M (6.2%), Net Income $2.3M (9.0%), EBITDA $4.4M, Total Expenses $24.1M, \n",
      "\n",
      "-----------Earnings Summary---------------\n",
      "2024-01-24: EPS predicted: 0.74, EPS actual: 0.71, EPS surprise: -0.03; Revenue predicted: $25.76B, Revenue actual: $25.17B\n",
      "2024-04-23: EPS predicted: 0.50, EPS actual: 0.45, EPS surprise: -0.04; Revenue predicted: $22.26B, Revenue actual: $21.30B\n",
      "2024-07-24: EPS predicted: 0.62, EPS actual: 0.52, EPS surprise: -0.10; Revenue predicted: $24.74B, Revenue actual: $25.50B\n",
      "2024-10-23: EPS predicted: 0.60, EPS actual: 0.72, EPS surprise: 0.12; Revenue predicted: $25.44B, Revenue actual: $25.18B\n",
      "2025-01-29: EPS predicted: 0.77, EPS actual: 0.73, EPS surprise: -0.04; Revenue predicted: $27.13B, Revenue actual: $25.71B\n"
     ]
    }
   ],
   "source": [
    "def get_earnings_summary():\n",
    "    \"\"\"\n",
    "    Reads earning.json and returns a plain summary with:\n",
    "    - EPS predicted / actual\n",
    "    - Revenue predicted / actual (in billions)\n",
    "    \"\"\"\n",
    "    earnings_path = os.path.join(DATA_DIR, \"earning.json\")\n",
    "\n",
    "    with open(earnings_path, \"r\") as f:\n",
    "        earnings_json = json.load(f)\n",
    "\n",
    "    lines = []\n",
    "    for rec in earnings_json:\n",
    "        dt = rec.get(\"EarningReleaseDate\") or rec.get(\"EarningReportDate\")\n",
    "        if not dt:\n",
    "            continue\n",
    "\n",
    "        date = pd.to_datetime(dt).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        eps_actual   = rec.get(\"EpsActual\", 0)\n",
    "        eps_forecast = rec.get(\"EpsForecast\", 0)\n",
    "        eps_surprise   = rec.get(\"EpsSurprise\", 0)\n",
    "\n",
    "        rev_actual   = rec.get(\"RevenueActual\", 0) / 1e9\n",
    "        rev_forecast = rec.get(\"RevenueForecast\", 0) / 1e9\n",
    "\n",
    "        line = (\n",
    "            f\"{date}: \"\n",
    "            f\"EPS predicted: {eps_forecast:.2f}, EPS actual: {eps_actual:.2f}, EPS surprise: {eps_surprise:.2f}; \"\n",
    "            f\"Revenue predicted: ${rev_forecast:.2f}B, Revenue actual: ${rev_actual:.2f}B\"\n",
    "        )\n",
    "        lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def get_balance_sheet_summary():\n",
    "    \"\"\"\n",
    "    This function extracts financial statement information from balencesheet.json\n",
    "    and returns a readable summary line for each quarter.\n",
    "    \"\"\"\n",
    "    bs_path = os.path.join(DATA_DIR, \"balencesheet.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(bs_path, \"r\") as f:\n",
    "        balance_sheet = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and sort\n",
    "    balance_sheet[\"Date\"] = pd.to_datetime(balance_sheet[\"Date\"])\n",
    "    balance_sheet = balance_sheet.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build human-readable lines\n",
    "    summaries = []\n",
    "    for date, row in balance_sheet.iterrows():\n",
    "        rev       = row.get(\"Total Revenue\", 0) / 1e6\n",
    "        gp        = row.get(\"Gross Profit\", 0) / 1e6\n",
    "        op_inc    = row.get(\"Operating Income\", 0) / 1e6\n",
    "        net_inc   = row.get(\"Net Income Common Stockholders\", 0) / 1e6\n",
    "        ebitda    = row.get(\"EBITDA\", 0) / 1e6\n",
    "        tot_exp   = row.get(\"Total Expenses\", 0) / 1e6\n",
    "\n",
    "        # Calculate margins and ratios safely\n",
    "        gross_margin   = gp / rev * 100 if rev else 0\n",
    "        op_margin      = op_inc / rev * 100 if rev else 0\n",
    "        net_margin     = net_inc / rev * 100 if rev else 0\n",
    "\n",
    "        summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Revenue ${rev:.1f}M, Gross Profit ${gp:.1f}M ({gross_margin:.1f}%), \"\n",
    "            f\"Operational Income ${op_inc:.1f}M ({op_margin:.1f}%), Net Income ${net_inc:.1f}M ({net_margin:.1f}%), \"\n",
    "            f\"EBITDA ${ebitda:.1f}M, Total Expenses ${tot_exp:.1f}M, \"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(summaries)\n",
    "\n",
    "print(\"----------Balance Sheet Summary----------\")\n",
    "print(get_balance_sheet_summary())\n",
    "print(\"\\n-----------Earnings Summary---------------\")\n",
    "print(get_earnings_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4695ddf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m      1\u001b[39m user_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mHere are your two data summaries:\u001b[39m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[33m- Finish with a concise **Conclusion** summarizing whether performance improved or deteriorated and why.\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     23\u001b[39m messages = [\n\u001b[32m     24\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: general_system_prompt},\n\u001b[32m     25\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,   \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: user_prompt},\n\u001b[32m     26\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m question3Answer = \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m display(Markdown(trim_reasoning(question3Answer[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m'\u001b[39m])))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:280\u001b[39m, in \u001b[36mTextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, text_inputs, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[39;00m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mChat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m         chats = (Chat(chat) \u001b[38;5;28;01mfor\u001b[39;00m chat \u001b[38;5;129;01min\u001b[39;00m text_inputs)  \u001b[38;5;66;03m# üêà üêà üêà\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1379\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1372\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1373\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1376\u001b[39m         )\n\u001b[32m   1377\u001b[39m     )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1386\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1385\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1286\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1285\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:385\u001b[39m, in \u001b[36mTextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    383\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[32m    388\u001b[39m     generated_sequence = output.sequences\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/generation/utils.py:2465\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2457\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2458\u001b[39m         input_ids=input_ids,\n\u001b[32m   2459\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2460\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2461\u001b[39m         **model_kwargs,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2464\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2470\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2472\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2476\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2477\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2478\u001b[39m         input_ids=input_ids,\n\u001b[32m   2479\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2480\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2481\u001b[39m         **model_kwargs,\n\u001b[32m   2482\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/generation/utils.py:3434\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3432\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3434\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3436\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3437\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3438\u001b[39m     outputs,\n\u001b[32m   3439\u001b[39m     model_kwargs,\n\u001b[32m   3440\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3441\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/hooks.py:176\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:839\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n\u001b[32m    838\u001b[39m slice_indices = \u001b[38;5;28mslice\u001b[39m(-logits_to_keep, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logits_to_keep, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m logits_to_keep\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m loss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/hooks.py:171\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_forward\u001b[39m(module, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     args, kwargs = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_hf_hook\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module._hf_hook.no_grad:\n\u001b[32m    173\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/hooks.py:361\u001b[39m, in \u001b[36mAlignDevicesHook.pre_forward\u001b[39m\u001b[34m(self, module, *args, **kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    354\u001b[39m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m value.data_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map\n\u001b[32m    357\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.execution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map[value.data_ptr()]\n\u001b[32m    358\u001b[39m         ):\n\u001b[32m    359\u001b[39m             \u001b[38;5;28mself\u001b[39m.tied_pointers_to_remove.add((value.data_ptr(), \u001b[38;5;28mself\u001b[39m.execution_device))\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m.execution_device), send_to_device(\n\u001b[32m    371\u001b[39m     kwargs, \u001b[38;5;28mself\u001b[39m.execution_device, skip_keys=\u001b[38;5;28mself\u001b[39m.skip_keys\n\u001b[32m    372\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/utils/modeling.py:407\u001b[39m, in \u001b[36mset_module_tensor_to_device\u001b[39m\u001b[34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# clean pre and post foward hook\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device != \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43mclear_device_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# When handling tied weights, we update tied_params_map to keep track of the tied weights that have already been allocated on the device in\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[38;5;66;03m# order to avoid duplicating memory, see above.\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    412\u001b[39m     tied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    413\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m old_value.data_ptr() \u001b[38;5;129;01min\u001b[39;00m tied_params_map\n\u001b[32m    414\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tied_params_map[old_value.data_ptr()]\n\u001b[32m    415\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/utils/memory.py:62\u001b[39m, in \u001b[36mclear_device_cache\u001b[39m\u001b[34m(garbage_collection)\u001b[39m\n\u001b[32m     60\u001b[39m     torch.npu.empty_cache()\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_mps_available(min_version=\u001b[33m\"\u001b[39m\u001b[33m2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmps\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_cuda_available():\n\u001b[32m     64\u001b[39m     torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/mps/__init__.py:85\u001b[39m, in \u001b[36mempty_cache\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mempty_cache\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     82\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03m    allocator so that those can be used in other GPU applications.\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mps_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "user_prompt = f\"\"\"\n",
    "Here are your two data summaries:\n",
    "\n",
    "**Balance Sheet Summary** \n",
    "- Balance sheet summary containing the quaterly financial information for the previous quaters \n",
    "{get_balance_sheet_summary()}\n",
    "\n",
    "\n",
    "**Earnings Summary**  \n",
    "- Earnings summary containing the quaterly earnings information for the previous quaters and the current quater(2025 Q1)\n",
    "{get_earnings_summary()}\n",
    "\n",
    "**Question:**  \n",
    "Compared with previous quarters, how is the performance of this quarter (ending 2025‚Äë01‚Äë29)?\n",
    "\n",
    "**Please:**  \n",
    "- Write a brief **Introduction** stating the question and data scope.  \n",
    "- In your **Analysis**, compare each metric (Revenue, Gross Profit, Operational Income, Net Income, EBITDA, EPS and Revenue surprises) quarter‚Äëover‚Äëquarter, citing the exact figures.  \n",
    "- Highlight any notable trends (e.g., margin expansions or EPS misses).  \n",
    "- Finish with a concise **Conclusion** summarizing whether performance improved or deteriorated and why.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\",   \"content\": user_prompt},\n",
    "]\n",
    "\n",
    "question3Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question3Answer[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9430b",
   "metadata": {},
   "source": [
    "### Question 5:What insights can be concluded from the earnings call?\n",
    "\n",
    "#### Data Used for Prompt construction\n",
    "\n",
    "* To gain insights from the earnings call, we used the transcript available in the `earning_transcript.md` file. Since the full transcript is quite lengthy, our strategy was to break it into smaller sections and summarize each section individually using the LLM. By combining these individual summaries, we created a comprehensive overview of the entire earnings call. For the final prompt, we provided the LLM with this summarized version of the transcript and asked it to identify the key insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get function from indy to summarise the earnings call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_template_q5 = \"\"\"\n",
    "\"Note: In this response, please pay particular attention to executive tone, guidance, and strategic priorities.\\n\\n\"\n",
    "Here is the summarized earnings call transcript:\n",
    "{call_summary}\n",
    "\n",
    "Question:\n",
    "What key insights can be concluded from the Tesla earnings call?\n",
    "\n",
    "Please:\n",
    "- Start with a brief **Overview** of the call‚Äôs focus.\n",
    "- Identify the **Key Themes** or concerns mentioned (e.g., demand, margin pressure, product roadmap).\n",
    "- Highlight any **management tone or forward-looking statements**.\n",
    "- Finish with a concise **Conclusion** that summarizes the strategic outlook or market signal from the call.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": filled_user_prompt},\n",
    "]\n",
    "\n",
    "question5Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question5Answer[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17271034",
   "metadata": {},
   "source": [
    "### Question 6:Which key news events influenced the stock performance, and what insights do they offer?\n",
    "\n",
    "#### Prompt construction\n",
    "\n",
    "* To analyse what news events affected the stock perferomance we will take a look at the news articles found in `news.json`. This file has new events but it seems to be large sections of text which might be hard to include in the prompt for the LLM. We will use a similar strategy to extract the most important infomation out of the news articles. We will split the news articles into batches of 3 and then ask the LLM to summarise the key information. Then we will combined these summaries to create a comprehensive summary that will be included in the final prompt to the LLM, where it will use the summary to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------The news articles have been batched up for the summarising in batches ----------\n",
      "['Article 1:\\nTitle: Tesla Caps Roller-Coaster Year With Mixed Fourth-Quarter Earnings\\nDate: January 29, 2025\\nContent:\\nTesla TSLA -4.79% decrease; red down pointing triangle Chief Executive Elon Musk talked about full self-driving cars hitting U.S. roads this year and the production of thousands of Optimus humanoid robots, after the automaker delivered mixed results in the fourth quarter.\\n\\nThe company reported declines in operating margin and automotive revenue for the period, with much of the growth coming from stronger demand for its energy-storage products and rising sales of regulatory credits.\\n\\nShares of Tesla rose 4% in after-hours trading Wednesday evening as Musk repeated his vision about Tesla becoming the world‚Äôs most valuable company because of its efforts now on robotics and self-driving vehicles.\\n\\nThe billionaire entrepreneur opened the electric-car maker‚Äôs earnings call with a focus on its future businesses, including its rollout of unsupervised autonomous vehicles in Austin in June, and an internal goal to build 10,000 Optimus humanoid robots by the end of the year.\\n\\n‚ÄúWe‚Äôre setting up for what I think will be an epic 2026 and a ridiculous ‚Äò27 and ‚Äò28‚Äîridiculously good,‚Äù Musk said. \\n\\nRevenue was up 2% for the period, lifted by stronger demand for its energy-storage products and rising sales of regulatory credits. These credits, essentially pure profit for Tesla, are sold to other automakers that buy them to meet tailpipe-emissions requirements set by the U.S. government.\\n\\nBut for its core automotive business, revenue was down 8%, in part because Tesla leaned heavily on promotional deals in the fourth quarter to drive a rebound in sales in the last three months. Overall, Tesla‚Äôs closely watched operating margin was 6.2%, down from 8.2% a year earlier.\\n\\nTesla is facing an array of challenges in the year ahead, including a chief executive whose attention is divided by his other companies and work as an adviser to President Trump.\\n\\nIts core auto business is under pressure with demand weakening for its vehicles, including its new Cybertruck pickup, and intensifying competition in China, where a price war in the electric-car market has broken out among foreign and homegrown automakers.\\n\\nMusk‚Äôs close relationship with Trump only came up once on the call with Wall Street, when an analyst asked Musk what the right policy is to support sustainable transportation in the U.S. Musk largely avoided the question.\\n\\n‚ÄúAt this point, I think that sustainable transport is inevitable,‚Äù he said. \\n\\nWith growth stalled, investors are hopeful that more affordable electric-car options promised by Musk will help revive consumer interest in the brand.\\n\\nTesla Chief Financial Officer Vaibhav Taneja reiterated on Wednesday that the company plans to release new products this year, including a new low-cost model in the first half, though he didn‚Äôt provide specifics.\\n\\nIn October, Tesla showed off prototypes for two fully autonomous vehicles‚Äîthe Cybercab, a gold two-seater with butterfly wing doors, and the Robovan, a 20-seater, art-deco style bus. Musk said the Cybercab could be available to customers for less than $30,000 with production starting by 2026. \\n\\nTesla‚Äôs market value skyrocketed to an all-time high of $1.5 trillion in December, powered by a postelection rally. The surge reflects optimism on Wall Street that Musk‚Äôs proximity to Trump will yield benefits for his businesses and help support Tesla‚Äôs ambitions in self-driving cars.\\n\\nAlong with advising Trump, Musk is leading the president‚Äôs new Department of Government Efficiency, a task force focused on reducing federal spending.\\n\\nTrump‚Äôs policy objectives, while backed by Musk, present some obstacles for Tesla‚Äôs car business. The president has pledged to roll back Biden-era subsidies for EVs, including a $7,500 tax consumer tax credit that has helped boost Tesla‚Äôs sales over the years.\\n\\nTrump is also threatening to impose a 25% tariff on Mexican and Canadian imports as soon as Saturday. While Tesla builds most cars it sells in the U.S. in Texas and California, it is reliant on suppliers in the two neighboring countries for parts. For instance, 20% to 25% of parts that are used in U.S.-built cars come from Mexico, according to federal data.\\n\\nOn Wednesday, Taneja said the tariffs are likely to impact Tesla‚Äôs profitability.\\n\\nTesla has fared better than some tech companies this week in a market selloff stoked by news from DeepSeek that it had released a powerful new AI model. The Chinese startup said its technology is particularly good at problem solving and can perform on par with OpenAI at a fraction of the cost.\\n\\nIn the near term, Tesla‚Äôs core automotive business is still critical to generating the profits behind Musk‚Äôs future AI and robotics bets. In its earnings release, Tesla said it plans to return to growth and increase production 60% in 2025.\\n\\nThe company last week unveiled a new updated version of its Model Y, one of the bestselling cars in the world. Consumer deliveries of the refreshed model are scheduled to begin in March.\\n\\nArticle 2:\\nTitle: Tesla, BMW Sue EU as Tension Mounts on Chinese EV Tariffs\\nDate: January 27, 2025\\nContent:\\n Tesla TSLA -4.79%decrease; red down pointing triangle and Germany‚Äôs BMW BMW 1.75%increase; green up pointing triangle are suing the European Commission, joining a growing band of Chinese automakers to oppose the European Union on its punitive tariffs on electric vehicles.\\n\\nBoth Tesla Shanghai and BMW filed cases at the General Court of the European Union, the bloc‚Äôs second-highest court, according to its website.\\n\\nThe filings come after the EU slapped tariffs as high as 45% on Chinese EVs after it ruled that China is unfairly subsidizing the industry and saturating the bloc with cheaper cars. Tesla‚Äôs Chinese-manufactured EVs were hit with a 7.8% tariff while BMW‚Äôs cars from the country received a 20.7% markup.\\n\\nChinese manufacturers BYD, Geely and SAIC have also filed appeals in Luxembourg.\\n\\nA BMW spokesperson said the company opposes the import duties and said they don‚Äôt strengthen the competitiveness of European auto groups.\\n\\n‚ÄúOn the contrary, the countervailing duties harm the business model of globally active companies, they limit the supply of e-cars to European customers and can therefore even slow down decarbonization in the transport sector,‚Äù the spokesperson said, adding that the company would still prefer to negotiate an agreement.\\n\\n‚ÄúAs stated before, it is important to avoid a trade conflict that only has losers in the end,‚Äù BMW said.\\n\\nTesla didn‚Äôt immediately respond to a request for comment.\\n\\nEuropean Commission spokesperson Olof Gill said on Monday that the EU remains fully open to finding a negotiated solution, but that solution needs to address ‚Äúthe clear example of unfair competition that our investigation identified on this topic‚Äù.\\n\\nThe dispute is yet another battlefront for Tesla-owner Elon Musk, who has spent recent months panning the EU for its penchant for regulating tech giants. European regulators are also probing Musk‚Äôs X social network over suspected breaches of the Digital Services Act, an EU law forcing digital platforms to do more to tackle disinformation online.\\n\\nThe legal challenges, if successful, could annul the law that enabled Brussels to slap duties on Chinese products in the first place, and their owners could then fight to claim back losses.\\n\\nArticle 3:\\nTitle: Tesla to Recall 1.2 Million Cars in China on Safety Concerns\\nDate: January 24, 2025\\nContent:\\nTesla TSLA -4.79%decrease; red down pointing triangle China plans to fix 1.2 million China-made and imported vehicles with software issues as a dozen carmakers recalled vehicles over safety concerns in the world‚Äôs largest auto market.\\n\\nThe U.S. electric-vehicle giant recalled 335,716 vehicles, a mix of imported Model S and X and locally produced Model 3 and Y cars, over a potential malfunction of the rearview camera, China‚Äôs State Administration for Market Regulation said Friday.\\n\\nIt also recalled 871,087 Model 3 and Y cars made in China due to steering issues, the state market regulator said.\\n\\nThe EV maker will deploy a software update for the affected vehicles remotely for free, the SAMR said.\\n\\nTesla China recalled 1.6 million cars last January, its largest in the country, to fix issues with its driver-assistance features that could increase the risk of crashes.\\n\\nTesla has been facing tougher competition in China, where homegrown rivals, such as BYD, have tightened their grip on the country‚Äôs EV market. The U.S. automaker sold 93,766 China-made cars last month, ranking fifth in terms of car sales in China for December after falling out of the top three spots in October.\\n\\nXiaomi, an up-and-coming domestic player, recalled 30,931 vehicles over software issues that could affect its parking-assistance feature, the market regulator said in a separate statement.\\n\\nA dozen carmakers announced recall plans on Friday. The regulator regularly publishes vehicle recall information.\\n\\nBYD, China‚Äôs top carmaker, recalled 6,843 Bao 5 plug-in hybrid off-road SUVs from its premium brand Fangchengbao due to fire risk in China. Honda Motor‚Äôs Chinese joint ventures Dongfeng Honda and GAC Honda will recall a total of 1.37 million vehicles, effective Feb. 28.', \"Article 1:\\nTitle: Why Auto Stocks Are Leading the Selloff\\nDate:  February 3, 2025\\nContent:\\nAuto stocks‚Äîa convenient investor proxy for international trade‚Äîare at the heart of Monday‚Äôs global selloff.\\n\\nHonda led the rout in Asia, while in Europe shares in Volkswagen and Stellantis‚Äîthe region‚Äôs largest automakers‚Äîwere down roughly 6% in afternoon trading. General Motors fell 6% Monday morning, among the biggest faller in the S&P 500 index.\\n\\nMost automakers use Mexico and Canada to manufacture vehicles and parts for the large and lucrative U.S. market, making the industry among the biggest losers from the 25% tariffs President Donald Trump said would come into effect on Tuesday.\\n\\nGM assembles 63% of its North America production in the U.S., compared with 83% for Ford, meaning the Chevrolet maker is likely to be worse affected by the tariffs than its crosstown rival, according to Jefferies. Non-U.S. manufacturers are in a similar position to their Detroit peers, with 67% of North American vehicles assembled in the U.S. on average.\\n\\nMexico in particular has grown in recent years as a hub for making cheaper cars. For example, Volkswagen makes its Jetta sedan and Tiguan and Taos crossovers in Mexico for U.S. consumers, while manufacturing its full-size Atlas sports-utility vehicle in Chattanooga, Tenn.\\n\\nMercedes-Benz and BMW have factories in Mexico, but they also use the U.S. as a global hub for producing expensive sports-utility vehicles. BMW produces more vehicles in the U.S. than it sells in the country. Both stocks still fell roughly 4% Monday.\\n\\nShares of Porsche also slipped, even though it ships all its vehicles sold in the U.S. from Europe.\\n\\nInvestors are already anticipating the next steps in Trump's trade war. The President has singled out trade with the European Union for criticism, specifying cars in particular.\\n\\nIn 2023, Europe accounted for 23% of the roughly $250 billion U.S. deficit in auto vehicles and parts, not far behind Mexico and Canada with 34%.\\n\\nOne automaker that wouldn't be much affected by the tariffs is Tesla, whose Chief Executive Elon Musk has joined the new U.S. administration. Nonetheless, its stock was down 5% in morning trading.\\n\\nArticle 2:\\nTitle: Trump‚Äôs Tariffs Would Hit Tesla‚Äôs Profits, Financial Chief Says\\nDate: January 29, 2025\\nContent:\\nPresident Trump‚Äôs proposed tariffs would hit Tesla‚Äôs profits, said Vaibhav Taneja, the electric-vehicle maker's chief financial officer.\\n\\n‚ÄúOver the years, we've tried to localize our supply chain in every market, but we are still very reliant on parts from across the world for all our businesses,‚Äù Taneja said.\\n\\n‚ÄúTherefore, the imposition of tariffs, which is very likely,‚Äù he said, ‚Äúwill have an impact on our business and our profitability.‚Äù\\n\\nTaneja didn‚Äôt say how large the impact would be. President Trump has talked about placing 25% tariffs on Mexico and Canada as soon as Saturday.\\n\\nArticle 3:\\nTitle: As Trade War Looms, Tesla Hikes Prices in Canada Across Lineup\\nDate: January 23, 2025\\nContent:\\n Tesla is making a U-turn on its years of price cuts‚Äîat least in Canada.\\n\\nOn a banner across the top of its Canadian website, the company says it is hiking the price of its Model 3 by as much as $9,000 CAD on Feb. 1, the same date President Trump has threatened to impose tariffs on goods imported from Mexico and Canada. That‚Äôs about an $6,275 increase in U.S. dollars.\\n\\nThe electric-car maker, whose Chief Executive Elon Musk is a close adviser to Trump, is also increasing prices on three other models it sells in Canada but by a lesser amount of $4,000 CAD. Tesla didn‚Äôt immediately respond to a request for comment.\\n\\nThe price hikes come amid changing economic policies in Canada, including the end of a national electric-vehicle rebate program known as iZEV, which ran out of funds earlier this month. Canada previously offered EV buyers $5,000 to purchase Tesla models under a certain price point, on top of some regional incentives.\\n\\nTrump said on Monday he aims to implement a 25% tariff on imports from Canada and Mexico starting on Feb. 1. It's unclear whether Canada will respond with retaliatory tariffs, which increase the cost of products imported from the U.S. to Canada\", 'Article 1:\\nTitle: Tesla Stock Looks To Advance After Tariffs Sell Off. But It\\'s No Longer A \\'Top Pick.\\'\\nDate: February 4, 2025\\nContent:\\nTesla (TSLA) stock on Tuesday shook off some of its tariffs-related losses from Monday as President Donald agreed to month-long reprieves for both Canada and Mexico. Meanwhile, TSLA consolidated in January with 2025 earnings consensus estimates plummeting 11% following Q4 earnings last week. \\n\\nMany stocks, including Tesla, were hit hard on Monday on the Trump tariff news. However, late Monday, Canadian Prime Minister Justin Trudeau announced a $1.3 billion border plan that will pause Trump\\'s tariffs for at least 30 days. Midday Monday, Trump granted Mexico a one-month reprieve from 25% tariffs that were set to take effect Tuesday, after Mexican President Claudia Sheinbaum committed to send 10,000 troops to the border to halt drug trafficking.\\n\\nU.S. tariffs on China went into effect Tuesday and China has retaliated with tariffs on U.S. crude oil, liquefied natural gas, coal and other commodities.\\n\\nTroy Teslike, whose delivery estimates and Tesla data tracking are highly respected among retail Tesla investors, on Feb. 2 posted to X that based on the company\\'s current battery supply, he doesn\\'t \"see any immediate problems due to Trump\\'s trade war with Mexico, Canada and China.\"\\n\\n\"If Trump starts a trade war with Japan, it would impact Tesla\\'s Model S and Model X production in the U.S.,\" Teslike wrote.\\n\\nTSLA rose around 2.3% to 392.40 during market action on Tuesday.\\n\\nShares tumbled 5.2% to 383.68 on Monday, falling below the 50-day moving average. Tesla flirted with an early entry Friday.\\n\\nThe Tesla Cybertruck late Monday also officially began to qualify for the full $7,500 Inflation Reduction Act, or IRA, tax credit. Trump has signaled EV tax credits could be stripped out of the IRA. The Cybertruck starting price with the tax credit is around $72,490.\\n\\nTesla Not A \\'Top Pick\\'\\n\\nPrior to Trump\\'s tariff policy dominating the news cycle, Tesla Q4 earnings missed Wednesday night, even with a Bitcoin gain, with core auto margins hitting a multiyear low. However, Chief Executive Elon Musk was extremely bullish on the earnings call. He said he expects Tesla to start paid robotaxi rides in Austin.\\n\\nMorgan Stanley analyst Adam Jonas, a longtime Tesla bull, late on Friday removed the firm\\'s \"top pick\" designation for TSLA. Jonas maintained a 430 price target and an overweight rating on the shares. Following earnings, Jonas wrote the results were \"mostly disappointing,\\' but added that the report was not \\'particularly narrative changing.\"\\n\\nMusk appeared to signal that 2025 could be another middling year for the EV giant, with only slight vehicle sales growth, as much of the conference call highlighted the possibility for incredible things to come in 2026, 2027 and 2028. As a result, analyst 2025 profit estimates have been coming down since Wednesday.\\n\\nAs of Tuesday, Tesla\\'s 2025 EPS is expected to come in at $2.95, down 11% from the $3.31 expectation prior to Q4 earnings, according to FactSet. Estimates for 2026 have come down significantly as well.\\n\\nTesla annual earnings are now not forecast to rise above the 2002 peak of $4.07 per share until 2027, according to FactSet.\\n\\nTesla Stock Performance\\n\\nTSLA is has a base with a traditional 488.54 buy point, the record high from Dec. 18, according to MarketSurge charts. The stock is about 27% below that entry.\\n\\nLast week, Tesla stock edged down 0.5% to 404.60 after briefly flashing an early entry Friday. The EV giant came right up to a downward-sloping trendline on Friday, paring gains on Trump tariff news.\\n\\nIt\\'s possible that Tesla\\'s retreat from Friday\\'s highs and Monday\\'s slide reflected an ongoing re-evaluation of Tesla\\'s earnings report and conference call.\\n\\nA move above Friday\\'s intraday high of 419.99 could offer an early entry. Investors also could use the Jan. 17 high of 439.74 to enter Tesla stock.\\n\\nTSLA stock is on the IBD Leaderboard watchlist. For this afternoon\\'s earnings, the Musk-led earnings call will be the focus, as usual.\\n\\nThe stock consolidated in January, pausing after a scorching hot fourth quarter where Tesla stock logged most of its 63% advance for 2024, especially after Trump\\'s election win.\\n\\nTesla stock ranks first in the 35-stock IBD Auto Manufacturers industry group. The stock has a 91 Composite Rating out of a best-possible 99. Shares also have a 97 Relative Strength Rating and an 84 EPS Rating.\\n\\nArticle 2:\\nTitle: Tesla stock rises after company pledges return to growth after Q4 results disappoint\\nDate: January 30, 2025\\nContent:\\nTesla (TSLA) pledged a return to growth in 2025 on Wednesday after fourth quarter results disappointed, capping off a year that saw revenue rise just 1% while profits fell sharply from a year ago. On the earnings call, Tesla CEO Elon Musk said that paid, unsupervised FSD (Full Self-Driving) is coming to Austin, Texas, in June.\\n\\nShares in the electric vehicle maker jumped nearly 4% in early trading on Thursday.\\n\\n\"With Unsupervised FSD expected to be available throughout the US by the end of 2025 and the rest of the world by the end of 2026 this will be a focus of the bulls,\" Wedbush analyst Dan Ives wrote on Thursday morning.\\n\\nFor the fourth quarter, Tesla reported revenue of $25.7 billion, well short of the $27.2 billion expected by analysts and up just 2% from a year ago. For the full year 2024, revenue rose 1% to $97.7 billion.\\n\\nAdjusted earnings per share came in at $0.73, less than the $0.75 Wall Street analysts were forecasting, according to Bloomberg data.\\n\\nOperating income totaled $1.58 billion, down 23% from last year, while adjusted net income rose 3% to $2.6 billion.\\n\\nTesla said its operating income was negatively impacted by costs associated with artificial intelligence and other R&D projects, as well as lower average selling prices for its current vehicles.\\n\\nIn its shareholder presentation, Tesla said it expects its auto business to return to growth in 2025 after total auto revenues fell 8% in the fourth quarter compared to last year and 6% in 2024 compared to 2023. Total auto production fell 7% in the fourth quarter while deliveries rose 2%.\\n\\n\"In terms of both growth and profitability, results missed consensus expectations and the outlook was relatively lacking in detail ‚Äî calling for a \\'return to growth\\' for the vehicle business (vs. consensus expectation for low teens YoY growth),\" Morgan Stanley analyst Adam Jonas wrote after the earnings were released. \"There was no reference to Elon Musk\\'s prior mention of 20% to 30% volume growth for 2025.\"\\n\\nEarlier this month, Tesla said it delivered 495,930 vehicles globally in 2024, missing analyst estimates of around 510,400. In 2024, Tesla delivered 1.78 million vehicles, a 1% drop from the prior year and marking the company\\'s first year-over-year decline, suggesting new competition, demand, and global economic conditions may be hurting the company.\\n\\nTesla said in a Thursday filing that it expects capital spending to surpass $11 billion this year and in the next two fiscal years.\\n\\nIn October, the company had projected spending between $8 billion and $10 billion in 2026.\\n\\nThe company also said plans for new vehicles and their production would result in \"less cost reduction\" than it had previously anticipated, but said using both its current and next-gen platforms on the same manufacturing lines \"enables us to prudently grow our vehicle volumes in a more capex efficient manner during uncertain times.\"\\n\\nTesla CFO Vaibhav Taneja said on a call with analysts that Model Y production will be shut down across its factories for a short time as the new Model Y changeover occurs and that the shutdown will impact margins.\\n\\nThe company reiterated that plans for new vehicles, including \"more affordable models,\" were on track to start production in the first of 2025. Tesla also said its purpose-built robotaxi, the Cybercab, is still scheduled for volume production in 2026, with fleet-testing of existing models happening \"later this year.\"\\n\\nTesla said vehicle volume this year is expected to return to growth due to advancements in vehicle autonomy and the launch of new products. The company plans to launch FSD in Europe and China in 2025.\\n\\nTesla\\'s energy storage business remains a bright spot for the company, with energy deployments expected to grow 50% year over year.\\n\\nThe company\\'s stock closed out 2024 on a Trump-fueled election win as Musk became one of Trump\\'s staunchest allies during the campaign and maintains a significant role in the Trump administration.\\n\\nAsked on Wednesday\\'s call about his role in the administration and helping push forward US industrial policy, Musk said, \"In general, we need to make manufacturing cool again in America ... We have too much talent in law and finance in America, and there should be more of that talent in manufacturing.\"\\n\\nArticle 3:\\nTitle: Why Tesla (TSLA) Shares Are Trading Lower Today\\nDate: February 3, 2025\\nContent:\\nWhat Happened?\\n\\nShares of electric vehicle pioneer Tesla (NASDAQ:TSLA) fell 7.1% in the morning session after the Trump administration\\'s new tariffs (25% on Canadian goods and 10% on Chinese products) shook markets.\\n\\nWhile similar tariffs were set for Mexico, they have been delayed. But it doesn\\'t help that Canada has already hit back with its levies on U.S. imports. Also, Canada\\'s Former Finance Minister Chrystia Freeland, who is campaigning to replace prime minister Justin Trudeau), called for a 100% tariff on Tesla. President Trump noted in a social media post that Americans might feel the sting: \"WILL THERE BE SOME PAIN? YES, MAYBE (AND MAYBE NOT!).\" The tariffs were imposed as part of measures to improve the U.S.\\'s trade gap with the rest of the world and also to tighten border security.\\n\\nThe auto industry stands in the crosshairs. Notably, Tesla builds some of its cars with parts from Canada and Mexico. Tariffs could drive up costs, making cars more expensive from the factory to the dealership.\\n\\nSeparately, there are reports Tesla is losing ground in Sweden and Norway. According to Reuters, registration numbers for Teslas in Sweden fell 44% in January 2025, while in Norway, they dropped 38% compared to the previous year.\\n\\nThe shares closed the day at $383.85, down 5.1% from previous close.\\n\\nThe stock market overreacts to news, and big price drops can present good opportunities to buy high-quality stocks. Is now the time to buy Tesla?\\n\\nWhat The Market Is Telling Us\\n\\nTesla‚Äôs shares are extremely volatile and have had 110 moves greater than 2.5% over the last year. In that context, today‚Äôs move indicates the market considers this news meaningful but not something that would fundamentally change its perception of the business.\\n\\nThe previous big move we wrote about was 5 days ago when the stock gained 6.5%. As is usually the case, the quarter had something for the bulls and something for the bears.\\n\\nOn the bullish side, the company reiterated its promise to investors to launch its unsupervised full self-driving (FSD) and Robotaxi businesses later this year. Aside from the short-term results, those excited about the stock continue to argue that quarterly results are less relevant for a company that will revolutionize areas such as energy and humanoid robots.\\n\\nFor the bears, the results themselves provided fodder. Revenue and operating income both fell short of Wall Street\\'s estimates. These misses were driven by underperformance in its Automotive and Energy segments, as Services (which includes full self-driving) actually beat analysts\\' revenue expectations. However, Services is Tesla\\'s lowest margin business line - it had an extremely bad gross margin of 5.8% for the trailing 12 months, and it fell to 4.2% this quarter.\\n\\nOverall, this is a mixed quarter, and despite these challenges, the market seems to be holding faith in Tesla\\'s long-term vision thus far.\\n\\nTesla is up 1.4% since the beginning of the year, but at $384.48 per share, it is still trading 19.9% below its 52-week high of $479.86 from December 2024. Investors who bought $1,000 worth of Tesla‚Äôs shares 5 years ago would now be looking at an investment worth $7,394.', 'Article 1:\\nTitle: Analysts overhaul Tesla stock price targets after Q4 earnings\\nDate: January 30, 2025\\nContent:\\nTesla shares bumped higher in early Thursday trading after its disappointing fourth quarter earnings update was somewhat offset by a bullish outlook from CEO Elon Musk, triggering a host of price-target changes from Wall Street analysts.\\n\\nTesla shares  (TSLA)  have added around $530 billion in market value since late October and have been seen as one of the key beneficiaries of President Donald Trump\\'s election in November as the company continues its pivot from its legacy automaking business to a focus on self-driving technologies, energy storage and robotics.\\n\\nIts core EV business, meanwhile, has suffered from high interest rates and lagging demand, with last year\\'s vehicle deliveries falling for the first time on record and profit margins narrowing because of price cuts and financing incentives.\\n\\nTela posted weaker-than-expected fourth quarter revenues of $25.71 billion, about $2 billion shy of Wall Street forecasts, with profits of 73 cents a share that also missed estimates.\\n\\nMusk, however, was characteristically upbeat in his conference call with investors and analysts following last night\\'s results and reiterated plans to launch a low-cost EV later this year and to put the first fully autonomous Tesla cars on the road by this spring.\\n\\nMusk predicts \\'ridiculously good\\' growth\\n\\n\"We\\'re setting up for what I think will be an epic 2026 and a ridiculous 2027 and 2028 ... ridiculously good,\" Musk said.\\n\\n\"Very few people understand the value of self-driving and our ability to monetize the fleet,\" he added. \"Some of these things I\\'ve said for quite a long time, and I know people have said, \\'Well, Elon, the boy who cried wolf several times.\\' But I\\'m telling you, there\\'s a damn wolf this time and you can drive it.\"\\n\\nTesla also said it expected its auto business to return to growth, although Musk did not repeat his earlier estimates of a 20% to 25% gain in deliveries.\\n\\nRelated: Analyst overhauls Tesla stock price target with Q4 earnings in focus\\n\\n\"Despite the miss, and backing off its prior 2025 vehicle sales-growth guidance, [the] shares jumped after hours as we believe the market is focused more on its expectation that Tesla aims to launch unsupervised Full Self-Driving in parts of the U.S. later in 2025,\" said CFRA analyst Garrett Nelson.\\n\\nHe trimmed his price target by $10 to $540 per share following last night\\'s update. \"We reiterate our \\'buy\\' rating, with Tesla as one of the primary beneficiaries of a more accommodating regulatory environment in the U.S.,\" he added.\\n\\nTesla could lead AI\\'s real-world advance\\n\\nMorgan Stanley\\'s Adam Jonas, who reiterated his \\'overweight\\' rating and $430 price target on Tesla stock, called the earnings report \"emblematic of a company in the transition from an automotive \\'pure play\\' to a highly diversified play on AI and robotics.\"\\n\\n\"As AI moves from the digital world (bits and bytes) to the physical world (atoms and photons), we expect to see Tesla‚Äôs total-addressable-market aperture further expand to broader domains, many of which are still not included in buy-side or sell-side financial models for the company,\" Jonas argued.\\n\\n\"While the journey may be volatile and nonlinear, we believe 2025 will be a year where investors will continue to appreciate and value these existing and nascent industries of embodied AI where we believe Tesla has established a material competitive advantage,\" he added.\\n\\nRelated: Top analyst reworks Tesla stock price, rating with Q4 earnings on deck\\n\\nThat was echoed, albeit more cautiously, by UBS analyst Joseph Spak, who maintained his sell rating on the stock but nonetheless lifted his price target to $259 a share from $226.\\n\\n\"We continue to be impressed with Tesla‚Äôs initiatives and the progress they are making on full self-driving and Optimus\" robots, he said. \"Our challenge remains that the actual numbers and more easily identifiable forecasts relate to auto and energy.\"\\n\\n\"While we do agree Tesla has as good an opportunity as anyone to achieve and capitalize on these goals, more investors we speak to acknowledge there is still technology and execution risk as well as timing uncertainty (certainly with Optimus),\" he added.\\n\\nTesla capital spending tops $11 billion\\n\\nTesla said its 2025 capital outlays are likely to rise to $11 billion, and remain at about that level in 2026 and 2027, as it expands and develops both its manufacturing platforms as well as the AI technologies needed to power its FSD and robotics ambitions.\\n\\n\"If you are a bull and believer in the AI autonomous vision for Tesla this morning,  you feel even more confident in its thesis.\" said Wedbush analyst Dan Ives, who affirmed his outperform rating and $550 price target.\\n\\n\"We believe the autonomous/AI piece is 90% of the Tesla story today and thus speaks to our $2 trillion valuation thesis for Tesla over the coming 12 to 18 months,\" he added.\\n\\nTruist Securities analyst William Stein cautioned, however, that there has been \"too much cheerleading\" and not enough \"ground-truth\" in the Tesla story, adding that investors will need more detail on Musk\\'s broader product road map.\\n\\nStein kept his hold rating in place but lifted his Tesla price target by $22 to $373 per share.\\n\\nPiper Sander analyst Alexander Potter was also cautious, leaving his \\'overweight\\' rating and $500 price target unchanged following last night\\'s update. But he noted that Tesla\\'s commentary \"has never been so unabashedly bullish.\"\\n\\n\"This is a pivotal year for Tesla,\" Musk said. \"And when we look back on 2025 and the launch of unsupervised Full Self-Driving, true real-world AI that actually works ... I think it probably will be viewed as maybe the most important year in Tesla\\'s history.\"\\n\\n\"There is no company in the world that is as good in real-world AI as Tesla,\" he added.\\n\\nTesla shares closed 2.87% higher at $400.28 each Thursday, a move that extended the stock\\'s January gain to around 5.5%.']\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def get_all_news_articles_individually():\n",
    "\n",
    "    news_path = \"/content/news.json\"\n",
    "\n",
    "    with open(news_path, \"r\") as f:\n",
    "        news_json = json.load(f)\n",
    "\n",
    "    # Create a list of formatted articles\n",
    "    formatted_articles = [\n",
    "        textwrap.dedent(\n",
    "            f\"Article {i + 1}:\\n\"\n",
    "            f\"Title: {article['title']}\\n\"\n",
    "            f\"Date: {article['date']}\\n\"\n",
    "            f\"Content:\\n{article['content']}\"\n",
    "        )\n",
    "        for i, article in enumerate(news_json)\n",
    "    ]\n",
    "\n",
    "    return formatted_articles\n",
    "\n",
    "def summarize_each_news_article_one_by_one():\n",
    "\n",
    "    news_path = \"/content/news.json\"\n",
    "    with open(news_path, \"r\") as f:\n",
    "        news_json = json.load(f)\n",
    "\n",
    "    # System prompt\n",
    "    system_prompt = (\n",
    "        \"You are a professional financial news summarizer.\\n\"\n",
    "        \"Given a news article about Tesla, produce a standalone summary that:\\n\"\n",
    "        \"- Is approximately 100‚Äì150 words long.\\n\"\n",
    "        \"- Clearly identifies the main event or announcement.\\n\"\n",
    "        \"- Highlights any financial, strategic, or regulatory implications.\\n\"\n",
    "        \"- Remains neutral and grounded in the content provided.\\n\"\n",
    "        \"Do not invent or assume any details beyond what's in the article.\"\n",
    "        \"You must respond in English!\"\n",
    "    )\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    for i, article in enumerate(news_json):\n",
    "        article_text = textwrap.dedent(f\"\"\"\n",
    "        Title: {article['title']}\n",
    "        Date: {article['date']}\n",
    "        Content:\n",
    "        {article['content']}\n",
    "        \"\"\")\n",
    "\n",
    "        user_prompt = f\"Summarize the following article:\\n\\n{article_text}\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "\n",
    "        print(f\"Summarizing article {i + 1}/{len(news_json)}...\")\n",
    "        response = pipe(messages, **generation_args)\n",
    "        summaries.append(response[0][\"generated_text\"])\n",
    "\n",
    "    return summaries\n",
    "\n",
    "news_summaries = summarize_each_news_article_one_by_one()\n",
    "\n",
    "def get_comprehensive_news_summary(news_summaries):\n",
    "  comprehensive_news_summary = []\n",
    "  for idx, summary in enumerate(news_summaries):\n",
    "    comprehensive_news_summary.append(f\"Article {idx + 1}: {(trim_reasoning(summary))}\")\n",
    "  return \"\\n\".join(comprehensive_news_summary)\n",
    "\n",
    "comprehensive_news_summary =get_comprehensive_news_summary(news_summaries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_analysis_user_prompt_template = f\"\"\"\n",
    "You are given a summary of key news events related to Tesla over a recent period.\n",
    "\n",
    "**Question:**  \n",
    "Which key news events influenced Tesla‚Äôs stock performance, and what insights do they offer?\n",
    "\n",
    "**News Summary:**  \n",
    "{comprehensive_news_summary}\n",
    "\n",
    "**Please:**\n",
    "- Identify the most impactful events and explain why they mattered.\n",
    "- Highlight whether the impact was positive or negative, and on which part of Tesla‚Äôs business (e.g., automotive, energy, robotics, AI, international).\n",
    "- Connect events to possible market sentiment (e.g., uncertainty, optimism, risk).\n",
    "- End with a concise **Conclusion** about the overall narrative and strategic outlook based on this news.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": news_analysis_user_prompt_template},\n",
    "]\n",
    "\n",
    "question6Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question6Answer[0]['generated_text'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
