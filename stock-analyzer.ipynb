{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e030378",
   "metadata": {},
   "source": [
    "# Data Analysis and Q&A Project Using a Local LLM\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project requires you to perform a comprehensive analysis of a company's stock data using only the provided data sources and a local LLM. Your analysis should answer the following six questions strictly based on the supplied data and documents—no external data is allowed. All generated answers must be firmly based on the provided data, without any fabricated content. In addition, your logic must be clear, and any attribution of events must be causally linked.\n",
    "\n",
    "---\n",
    "\n",
    "## Provided Data\n",
    "\n",
    "You will be provided with the following data sets:\n",
    "\n",
    "#### Stock Price Data (Json format)\n",
    "* Timeframe: Jan 22 to Feb 5\n",
    "* Fields: Open, High, Low, Close, Volume\n",
    "\n",
    "#### Quarterly Earnings Data for the Past Year (Json format)\n",
    "* Contains key financial indicators (e.g., revenue, eps) for each quarter.\n",
    "\n",
    "#### Full Earnings Transcript Call\n",
    "* The complete transcript of the earnings call, including management discussions and Q&A.\n",
    "\n",
    "#### Balance Sheet Data for the Past Year (Json format)\n",
    "* Includes assets, liabilities, and shareholders' equity information.\n",
    "\n",
    "#### News Articles\n",
    "* Full text of 10 news articles related to the company during the analysis period.\n",
    "\n",
    "---\n",
    "\n",
    "## Questions\n",
    "Using the provided data and a local LLM, you need to answer the following six questions:\n",
    "\n",
    "1. What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "2. Why did the price increase on Jan 30? Please provide potential factors.\n",
    "\n",
    "3. Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "4. With unsupervised Full Self Driving scheduled to launch in limited markets like Austin by June, what regulatory challenges does Tesla foresee for a nationwide or international rollout, and how is the company strategically preparing to address these hurdles?\n",
    "\n",
    "5. What insights can be concluded from the earnings call?\n",
    "\n",
    "6. Which key news events influenced the stock performance, and what insights do they offer?\n",
    "\n",
    "---\n",
    "\n",
    "## Project Requirements\n",
    "- #### Data Source Restriction:\n",
    "Only use the provided data and documents. No external data or information is allowed.\n",
    "\n",
    "- #### Answer Generation:\n",
    "All generated answers must strictly be based on the provided data and documents. The LLM should not \"invent\" information.\n",
    "\n",
    "- #### Clear Logic and Causal Relationships:\n",
    "For each question, your answers must clearly demonstrate logical reasoning, and any attribution of cause must be explicitly linked to events in the data.\n",
    "\n",
    "- #### Prompt Design:\n",
    "You must design your own prompts for calling the local LLM to ensure that the responses are generated strictly based on the analysis results.\n",
    "\n",
    "- #### Result Evaluation:\n",
    "After generating the answers, implement an evaluation step to assess whether the responses meet the above requirements in terms of data reliance, logical clarity, and correct causation.\n",
    "\n",
    "- #### Please put the answers to these 6 questions in a dict at the end of your submitted Python nodebook file.\n",
    "\n",
    "For example\n",
    "```code\n",
    "{ \"Q1 answer\": \"Answer1\", \"Q2 answer\": \"Answer2\", \"Q3 answer\": \"Answer3\", \"Q4 answer4\": \"Answer4\", \"Q5 answer\": \"Answer5\", \"Q6 answer\": \"Answer6\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9bdfc",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "* Transformers\n",
    "* Torch (PyTorch)\n",
    "* Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3ba393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./project-venv/lib/python3.11/site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in ./project-venv/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: pandas in ./project-venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: ipython in ./project-venv/lib/python3.11/site-packages (9.1.0)\n",
      "Requirement already satisfied: filelock in ./project-venv/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./project-venv/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./project-venv/lib/python3.11/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./project-venv/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./project-venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./project-venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./project-venv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./project-venv/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./project-venv/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./project-venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./project-venv/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./project-venv/lib/python3.11/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./project-venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./project-venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./project-venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: decorator in ./project-venv/lib/python3.11/site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./project-venv/lib/python3.11/site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./project-venv/lib/python3.11/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./project-venv/lib/python3.11/site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./project-venv/lib/python3.11/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./project-venv/lib/python3.11/site-packages (from ipython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./project-venv/lib/python3.11/site-packages (from ipython) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./project-venv/lib/python3.11/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./project-venv/lib/python3.11/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in ./project-venv/lib/python3.11/site-packages (from ipython) (4.13.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./project-venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./project-venv/lib/python3.11/site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./project-venv/lib/python3.11/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./project-venv/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in ./project-venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in ./project-venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./project-venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./project-venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./project-venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./project-venv/lib/python3.11/site-packages (from stack_data->ipython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./project-venv/lib/python3.11/site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./project-venv/lib/python3.11/site-packages (from stack_data->ipython) (0.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./project-venv/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers accelerate pandas ipython\n",
    "# %pip install torch # Install PyTorch if you dont have it downloading \n",
    "\n",
    "DATA_DIR = \"447_dataset\"\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290d56f",
   "metadata": {},
   "source": [
    "## Loading and Running the Local LLM\n",
    "\n",
    "1. **Imports Transformers utilities**  \n",
    "   - `AutoModelForCausalLM`: generic class for loading any GPT‑style model  \n",
    "   - `AutoTokenizer`: matching tokenizer for converting text ↔ tokens  \n",
    "   - `pipeline`: high‑level helper that ties model + tokenizer into one callable  \n",
    "\n",
    "2. **Specifies the model repository**  \n",
    "   ```python\n",
    "   model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d52b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n",
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# The pipeline will automatically use the model and tokenizer you just loaded\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) # Load the tokenizer\n",
    "\n",
    " # Create a pipeline for text generation\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 2000, # Limit the number of tokens generated\n",
    "    \"return_full_text\": False, # Return only the generated text\n",
    "    \"do_sample\": True, # Use sampling to generate text\n",
    "    \"temperature\": 0.1,# Control the randomness of the output\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"top_p\": 0.9, # Control the diversity of the output\n",
    "    \"top_k\": 50, # Control the diversity of the output\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699af2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_system_prompt = ( \n",
    "    \"You are an expert financial data analyst LLM.\\n\"\n",
    "    \"You must ensure the following rules are followed:\\n\"\n",
    "    \"1. Use only the data summaries provided in the prompt.\\n\"\n",
    "    \"2. Show clear step-by-step reasoning, linking each claim directly to the data.\\n\"\n",
    "    \"3. Ensure all explanations are clear, logical, and accurate.\\n\"\n",
    "    \"4. Do not invent or hallucinate any information.\\n\"\n",
    "    \"After your answer, provide a checklist summary indicating whether each criterion is satisfied. \"\n",
    "    \"If any criterion is not met, include a brief explanation.\"\n",
    ")\n",
    "\n",
    "\n",
    "def trim_reasoning(raw):\n",
    "    tag = \"</think>\"\n",
    "    idx = raw.find(tag)\n",
    "\n",
    "    if idx != -1:\n",
    "        answer = raw[idx + len(tag):].strip()\n",
    "    else:\n",
    "        answer = raw.strip()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1d4bb",
   "metadata": {},
   "source": [
    "### Question 1:What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "#### Prompt construction\n",
    "\n",
    "* Here we need to monitor the performance of the tesla stock over the specified days. To monitor the performance of the stock the LLM just need to understand the how the pricing of the stock was through the given period hence why the LLM will need to see the infomation in the `prices.json` file.\n",
    "* To supplement the LLM to construct its answer we will also show the information in `balancesheet.json` so it can pickup on any trends to as why stock prices deviated and change through the mentioned days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55617ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-22: Open $416.81, High $428.00, Low $414.59, Close $415.11, Volume 60,963,300\n",
      "2025-01-23: Open $416.06, High $420.73, Low $408.95, Close $412.38, Volume 50,690,600\n",
      "2025-01-24: Open $414.45, High $418.88, Low $405.78, Close $406.58, Volume 56,427,100\n",
      "2025-01-27: Open $394.80, High $406.69, Low $389.00, Close $397.15, Volume 58,125,500\n",
      "2025-01-28: Open $396.91, High $400.59, Low $386.50, Close $398.09, Volume 48,910,700\n",
      "2025-01-29: Open $395.21, High $398.59, Low $384.48, Close $389.10, Volume 68,033,600\n",
      "2025-01-30: Open $410.78, High $412.50, Low $384.41, Close $400.28, Volume 98,092,900\n",
      "2025-01-31: Open $401.53, High $419.99, Low $401.34, Close $404.60, Volume 83,568,200\n",
      "2025-02-03: Open $386.68, High $389.17, Low $374.36, Close $383.68, Volume 93,732,100\n",
      "2025-02-04: Open $382.63, High $394.00, Low $381.40, Close $392.21, Volume 57,072,200\n",
      "2025-02-05: Open $387.51, High $388.39, Low $375.53, Close $378.17, Volume 57,223,300\n"
     ]
    }
   ],
   "source": [
    "\"\"\"   \n",
    "This Function extracts the price information and converts the informations\n",
    "into a simple readable format to be included in the prompt to the LLM\n",
    "\"\"\"\n",
    "def get_prices_summary():\n",
    "    prices_path = os.path.join(DATA_DIR, \"prices.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(prices_path, \"r\") as f:\n",
    "        prices = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and index\n",
    "    prices[\"Date\"] = pd.to_datetime(prices[\"Date\"])\n",
    "    prices = prices.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build a human-readable summary for each day\n",
    "    daily_summaries = []\n",
    "    for date, row in prices.iterrows():\n",
    "        daily_summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Open ${row['Open']:.2f}, \"\n",
    "            f\"High ${row['Hight']:.2f}, \"\n",
    "            f\"Low ${row['Low']:.2f}, \"\n",
    "            f\"Close ${row['Close']:.2f}, \"\n",
    "            f\"Volume {int(row['Volume']):,}\"\n",
    "        )\n",
    "\n",
    "    # Join them into one block of text\n",
    "    daily_summary_text = \"\\n\".join(daily_summaries)\n",
    "    return daily_summary_text\n",
    "\n",
    "\n",
    "print(get_prices_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33e7d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'general_system_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Fill in the template with specific data\u001b[39;00m\n\u001b[32m     16\u001b[39m filled_user_prompt = user_prompt_template_q1.format(\n\u001b[32m     17\u001b[39m     price_info = get_prices_summary()\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m messages = [\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mgeneral_system_prompt\u001b[49m},\n\u001b[32m     22\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: filled_user_prompt},\n\u001b[32m     23\u001b[39m ]\n\u001b[32m     25\u001b[39m question1Answer = pipe(messages, **generation_args)\n\u001b[32m     26\u001b[39m display(Markdown(trimquestion1Answer[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m'\u001b[39m]))\n",
      "\u001b[31mNameError\u001b[39m: name 'general_system_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "user_prompt_template_q1 =( \"\"\"\n",
    "    Here is the summarized Tesla data for Jan 22 - Feb 5:\n",
    "    {price_info}\n",
    "\n",
    "    **Question:**  \n",
    "    What was the performance of Tesla stock over this period?\n",
    "                          \n",
    "    **Please:**\n",
    "    - Write a brief **Introduction** stating the question and data scope.  \n",
    "    - In your **Analysis**, cite the exact figures (dates, prices, percent changes, volumes).  \n",
    "    - Draw any causal insights clearly (e.g., “the drop on Feb 1 may be linked to…”).  \n",
    "    - Finish with a concise **Conclusion** summarizing overall performance.\n",
    "\"\"\")\n",
    "\n",
    "# Fill in the template with specific data\n",
    "filled_user_prompt = user_prompt_template_q1.format(\n",
    "    price_info = get_prices_summary()\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": filled_user_prompt},\n",
    "]\n",
    "\n",
    "question1Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question1Answer[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb7491",
   "metadata": {},
   "source": [
    "# Question 2 \n",
    "### Why did the price increase on Jan 30? Please provide potential factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc284196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</think>\n",
      "\n",
      "### What Happened?\n",
      "\n",
      "#### **Shares of Electric Vehicle pioneer Tesla (TSLA) fell 7.1% in the morning session after the Trump administration's new tariffs (25% on Canadian goods and 10% on Chinese products) shook markets.**\n",
      "\n",
      "#### **Separately, Tesla shares fell 5.1% from $1,000 to $7,394 five years ago.**\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Points from the Article**\n",
      "\n",
      "1. **Tesla shares have risen 1.4% since the beginning of the year, but at $384.48 per share, they are still trading 19.9% below its 52-week high of $479.86 from December 2024.**\n",
      "   \n",
      "   - **Wall Street analysts believe Tesla shares will bump higher in mid-Thursday trading after its disappointing fourth-quarter earnings update.**\n",
      "\n",
      "2. **CEO Elon Musk predicted Tesla's stock would reach $7,394 in mid-Thursday trading.**\n",
      "   \n",
      "   - **Musk also emphasized Tesla's long-term vision, saying 'this is the most important year for Tesla,' and 'when we look back on 2025 and the launch of unsupervised Full Self-Driving, true real-world AI that actually works... I think it probably will be viewed as maybe the most important year in Tesla's history.'**\n",
      "\n",
      "3. **Analysts overhaul Tesla stock price targets after Q4 earnings.**\n",
      "   \n",
      "   - **Musk's optimistic outlook for Tesla's 2025 and 2026 capital outlays is driving analysts to raise their price targets.**\n",
      "   \n",
      "   - **Wall Street analysts are also adjusting their price targets based on Tesla's performance in Q4.**\n",
      "\n",
      "4. **Tesla shares have added around $530 billion since late October and have been seen as one of the key beneficiaries of President Donald Trump's election in November as the company continues its pivot from its legacy automaking business to a focus on self-driving technologies, energy storage, and robotics.**\n",
      "\n",
      "5. **Musk also emphasized Tesla's long-term vision, saying 'this is the most important year for Tesla,' and 'when we look back on 2025 and the launch of unsupervised Full Self-Driving, true real-world AI that actually works... I think it probably will be viewed as maybe the most important year in Tesla's history.'**\n",
      "\n",
      "6. **Wall Street analysts are also adjusting their price targets based on Tesla's performance in Q4.**\n",
      "\n",
      "---\n",
      "\n",
      "### **Conclusion**\n",
      "\n",
      "- **Tesla shares have surpassed Wall Street analysts' price targets multiple times.**\n",
      "- **Musk's optimistic outlook for Tesla's 2025 and 2026 capital outlays is driving analysts to raise their price targets.**\n",
      "- **Wall Street analysts are also adjusting their price targets based on Tesla's performance in Q4.**\n",
      "\n",
      "- **Tesla shares have added around $530 billion since late October and have been seen as one of the key beneficiaries of President Donald Trump's election in November as the company continues its pivot from its legacy automaking business to a focus on self-driving technologies, energy storage, and robotics.**\n",
      "\n",
      "- **Musk also emphasized Tesla's long-term vision, saying 'this is the most important year for Tesla,' and 'when we look back on 2025 and the launch of unsupervised Full Self-Driving, true real-world AI that actually works... I think it probably will be viewed as maybe the most important year in Tesla's history.'**\n",
      "\n",
      "- **Wall Street analysts are also adjusting their price targets based on Tesla's performance in Q4.**\n",
      "\n",
      "---\n",
      "\n",
      "### **Final Note**\n",
      "\n",
      "- **Tesla shares have surpassed Wall Street analysts' price targets multiple times.**\n",
      "- **Musk's optimistic outlook for Tesla's 2025 and 2026 capital outlays is driving analysts to raise their price targets.**\n",
      "- **Wall Street analysts are also adjusting their price targets based on Tesla's performance in Q4.**\n",
      "\n",
      "---\n",
      "\n",
      "### **Answer**\n",
      "\n",
      "Yes, Tesla shares have surpassed Wall Street analysts' price targets multiple times.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "system_prompt_q2 = (\n",
    "    \"You are an expert financial analyst assistant in the United States. \"\n",
    "    \"Your job is to explain stock price moves using only the provided data. \"\n",
    "    \"You must be concise and give only the most critical information in your answer\"\n",
    "    \"Do not invent or fetch any outside information, everything must be grounded in the inputs.\"\n",
    ")\n",
    "\n",
    "user_prompt_q2 = \"\"\"\n",
    "\n",
    "Using only the news articles data and Tesla’s Jan 30 stock data, identify all plausible factors that contributed to the price uptick.\n",
    "Reference the specific news item (by title and date) or data point you’re using.  \n",
    "Explain the causal link to the price move. \n",
    "Do not use any external sources.  \n",
    "\n",
    "**Question** \n",
    "Why did Tesla’s stock price increase on January 30?\n",
    "\n",
    "Here are the news articles and price info:\n",
    "{input_data}\n",
    "\n",
    "\"Please respond in English!\"\n",
    "\"\"\"\n",
    "\n",
    "with open(\"447_dataset/news.json\", \"r\") as f:\n",
    "    news_data = json.load(f)\n",
    "\n",
    "news_json_str = json.dumps(news_data)\n",
    "\n",
    "# Example of how you'd fill & call it:\n",
    "filled_user = user_prompt_q2.format(input_data=news_json_str)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_q2},\n",
    "    {\"role\": \"user\",   \"content\": filled_user},\n",
    "]\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6428e1",
   "metadata": {},
   "source": [
    "### Question 3:Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "#### Data Used for Prompt construction\n",
    "\n",
    "* For the LLM to have any insight of quaterly financial information, I will provide it the `balancesheet.json` as this file contains the quaterly financial figures. We will use this data so the LLM is a aware of the performance of the previous 1-2 years. This gives the LLM a base to compare against the current financial quater( 2025 Q1). Since the balance sheet has a lot of infomation, we dont want to overload the LLM with too many features to consider when it comes up with its decison so we will handpick some important features from the balance sheet from each quater.\n",
    "\n",
    "\n",
    "* The Data found in the `earnings.json` also contains relavant financial information for the past five quaters, which the LLM can use compare the performance of the company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85a75f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Balance Sheet Summary----------\n",
      "2023-12-31: Revenue $25.2M, Gross Profit $4.4M (17.6%), Operational Income $2.1M (8.2%), Net Income $7.9M (31.5%), EBITDA $3.5M, Total Expenses $23.1M, \n",
      "2024-03-31: Revenue $21.3M, Gross Profit $3.7M (17.4%), Operational Income $1.2M (5.5%), Net Income $1.2M (5.5%), EBITDA $2.9M, Total Expenses $20.1M, \n",
      "2024-06-30: Revenue $25.5M, Gross Profit $4.6M (18.0%), Operational Income $2.2M (8.7%), Net Income $1.5M (5.8%), EBITDA $3.3M, Total Expenses $23.3M, \n",
      "2024-09-30: Revenue $25.2M, Gross Profit $5.0M (19.8%), Operational Income $2.8M (11.0%), Net Income $2.2M (8.6%), EBITDA $4.2M, Total Expenses $22.4M, \n",
      "2024-12-31: Revenue $25.7M, Gross Profit $4.2M (16.3%), Operational Income $1.6M (6.2%), Net Income $2.3M (9.0%), EBITDA $4.4M, Total Expenses $24.1M, \n",
      "\n",
      "-----------Earnings Summary---------------\n",
      "2024-01-24: EPS predicted: 0.74, EPS actual: 0.71, EPS surprise: -0.03; Revenue predicted: $25.76B, Revenue actual: $25.17B\n",
      "2024-04-23: EPS predicted: 0.50, EPS actual: 0.45, EPS surprise: -0.04; Revenue predicted: $22.26B, Revenue actual: $21.30B\n",
      "2024-07-24: EPS predicted: 0.62, EPS actual: 0.52, EPS surprise: -0.10; Revenue predicted: $24.74B, Revenue actual: $25.50B\n",
      "2024-10-23: EPS predicted: 0.60, EPS actual: 0.72, EPS surprise: 0.12; Revenue predicted: $25.44B, Revenue actual: $25.18B\n",
      "2025-01-29: EPS predicted: 0.77, EPS actual: 0.73, EPS surprise: -0.04; Revenue predicted: $27.13B, Revenue actual: $25.71B\n"
     ]
    }
   ],
   "source": [
    "def get_earnings_summary():\n",
    "    \"\"\"\n",
    "    Reads earning.json and returns a plain summary with:\n",
    "    - EPS predicted / actual\n",
    "    - Revenue predicted / actual (in billions)\n",
    "    \"\"\"\n",
    "    earnings_path = os.path.join(DATA_DIR, \"earning.json\")\n",
    "\n",
    "    with open(earnings_path, \"r\") as f:\n",
    "        earnings_json = json.load(f)\n",
    "\n",
    "    lines = []\n",
    "    for rec in earnings_json:\n",
    "        dt = rec.get(\"EarningReleaseDate\") or rec.get(\"EarningReportDate\")\n",
    "        if not dt:\n",
    "            continue\n",
    "\n",
    "        date = pd.to_datetime(dt).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        eps_actual   = rec.get(\"EpsActual\", 0)\n",
    "        eps_forecast = rec.get(\"EpsForecast\", 0)\n",
    "        eps_surprise   = rec.get(\"EpsSurprise\", 0)\n",
    "\n",
    "        rev_actual   = rec.get(\"RevenueActual\", 0) / 1e9\n",
    "        rev_forecast = rec.get(\"RevenueForecast\", 0) / 1e9\n",
    "\n",
    "        line = (\n",
    "            f\"{date}: \"\n",
    "            f\"EPS predicted: {eps_forecast:.2f}, EPS actual: {eps_actual:.2f}, EPS surprise: {eps_surprise:.2f}; \"\n",
    "            f\"Revenue predicted: ${rev_forecast:.2f}B, Revenue actual: ${rev_actual:.2f}B\"\n",
    "        )\n",
    "        lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def get_balance_sheet_summary():\n",
    "    \"\"\"\n",
    "    This function extracts financial statement information from balencesheet.json\n",
    "    and returns a readable summary line for each quarter.\n",
    "    \"\"\"\n",
    "    bs_path = os.path.join(DATA_DIR, \"balencesheet.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(bs_path, \"r\") as f:\n",
    "        balance_sheet = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and sort\n",
    "    balance_sheet[\"Date\"] = pd.to_datetime(balance_sheet[\"Date\"])\n",
    "    balance_sheet = balance_sheet.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build human-readable lines\n",
    "    summaries = []\n",
    "    for date, row in balance_sheet.iterrows():\n",
    "        rev       = row.get(\"Total Revenue\", 0) / 1e6\n",
    "        gp        = row.get(\"Gross Profit\", 0) / 1e6\n",
    "        op_inc    = row.get(\"Operating Income\", 0) / 1e6\n",
    "        net_inc   = row.get(\"Net Income Common Stockholders\", 0) / 1e6\n",
    "        ebitda    = row.get(\"EBITDA\", 0) / 1e6\n",
    "        tot_exp   = row.get(\"Total Expenses\", 0) / 1e6\n",
    "        liab      = row.get(\"Total Liabilities\", 0) / 1e6\n",
    "        equity    = row.get(\"Total Shareholders’ Equity\", row.get(\"Total Shareholder Equity\", 0)) / 1e6\n",
    "\n",
    "        # Calculate margins and ratios safely\n",
    "        gross_margin   = gp / rev * 100 if rev else 0\n",
    "        op_margin      = op_inc / rev * 100 if rev else 0\n",
    "        net_margin     = net_inc / rev * 100 if rev else 0\n",
    "\n",
    "        summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Revenue ${rev:.1f}M, Gross Profit ${gp:.1f}M ({gross_margin:.1f}%), \"\n",
    "            f\"Operational Income ${op_inc:.1f}M ({op_margin:.1f}%), Net Income ${net_inc:.1f}M ({net_margin:.1f}%), \"\n",
    "            f\"EBITDA ${ebitda:.1f}M, Total Expenses ${tot_exp:.1f}M, \"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(summaries)\n",
    "\n",
    "print(\"----------Balance Sheet Summary----------\")\n",
    "print(get_balance_sheet_summary())\n",
    "print(\"\\n-----------Earnings Summary---------------\")\n",
    "print(get_earnings_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4695ddf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m      1\u001b[39m user_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mHere are your two data summaries:\u001b[39m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[33m- Finish with a concise **Conclusion** summarizing whether performance improved or deteriorated and why.\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     23\u001b[39m messages = [\n\u001b[32m     24\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: general_system_prompt},\n\u001b[32m     25\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,   \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: user_prompt},\n\u001b[32m     26\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m question3Answer = \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m display(Markdown(trim_reasoning(question3Answer[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m'\u001b[39m])))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:280\u001b[39m, in \u001b[36mTextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, text_inputs, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[39;00m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mChat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m         chats = (Chat(chat) \u001b[38;5;28;01mfor\u001b[39;00m chat \u001b[38;5;129;01min\u001b[39;00m text_inputs)  \u001b[38;5;66;03m# 🐈 🐈 🐈\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1379\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1372\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1373\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1376\u001b[39m         )\n\u001b[32m   1377\u001b[39m     )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1386\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1385\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1286\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1285\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:385\u001b[39m, in \u001b[36mTextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    383\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[32m    388\u001b[39m     generated_sequence = output.sequences\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/generation/utils.py:2465\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2457\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2458\u001b[39m         input_ids=input_ids,\n\u001b[32m   2459\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2460\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2461\u001b[39m         **model_kwargs,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2464\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2470\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2472\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2476\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2477\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2478\u001b[39m         input_ids=input_ids,\n\u001b[32m   2479\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2480\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2481\u001b[39m         **model_kwargs,\n\u001b[32m   2482\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/generation/utils.py:3434\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3432\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3434\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3436\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3437\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3438\u001b[39m     outputs,\n\u001b[32m   3439\u001b[39m     model_kwargs,\n\u001b[32m   3440\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3441\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/hooks.py:176\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:839\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n\u001b[32m    838\u001b[39m slice_indices = \u001b[38;5;28mslice\u001b[39m(-logits_to_keep, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logits_to_keep, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m logits_to_keep\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m loss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/hooks.py:171\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_forward\u001b[39m(module, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     args, kwargs = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_hf_hook\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module._hf_hook.no_grad:\n\u001b[32m    173\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/hooks.py:361\u001b[39m, in \u001b[36mAlignDevicesHook.pre_forward\u001b[39m\u001b[34m(self, module, *args, **kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    354\u001b[39m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m value.data_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map\n\u001b[32m    357\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.execution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map[value.data_ptr()]\n\u001b[32m    358\u001b[39m         ):\n\u001b[32m    359\u001b[39m             \u001b[38;5;28mself\u001b[39m.tied_pointers_to_remove.add((value.data_ptr(), \u001b[38;5;28mself\u001b[39m.execution_device))\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m.execution_device), send_to_device(\n\u001b[32m    371\u001b[39m     kwargs, \u001b[38;5;28mself\u001b[39m.execution_device, skip_keys=\u001b[38;5;28mself\u001b[39m.skip_keys\n\u001b[32m    372\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/utils/modeling.py:407\u001b[39m, in \u001b[36mset_module_tensor_to_device\u001b[39m\u001b[34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# clean pre and post foward hook\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device != \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43mclear_device_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# When handling tied weights, we update tied_params_map to keep track of the tied weights that have already been allocated on the device in\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[38;5;66;03m# order to avoid duplicating memory, see above.\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    412\u001b[39m     tied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    413\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m old_value.data_ptr() \u001b[38;5;129;01min\u001b[39;00m tied_params_map\n\u001b[32m    414\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tied_params_map[old_value.data_ptr()]\n\u001b[32m    415\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/utils/memory.py:62\u001b[39m, in \u001b[36mclear_device_cache\u001b[39m\u001b[34m(garbage_collection)\u001b[39m\n\u001b[32m     60\u001b[39m     torch.npu.empty_cache()\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_mps_available(min_version=\u001b[33m\"\u001b[39m\u001b[33m2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmps\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_cuda_available():\n\u001b[32m     64\u001b[39m     torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/mps/__init__.py:85\u001b[39m, in \u001b[36mempty_cache\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mempty_cache\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     82\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03m    allocator so that those can be used in other GPU applications.\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mps_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "user_prompt = f\"\"\"\n",
    "Here are your two data summaries:\n",
    "\n",
    "**Balance Sheet Summary** \n",
    "- Balance sheet summary containing the quaterly financial information for the previous quaters \n",
    "{get_balance_sheet_summary()}\n",
    "\n",
    "\n",
    "**Earnings Summary**  \n",
    "- Earnings summary containing the quaterly earnings information for the previous quaters and the current quater(2025 Q1)\n",
    "{get_earnings_summary()}\n",
    "\n",
    "**Question:**  \n",
    "Compared with previous quarters, how is the performance of this quarter (ending 2025‑01‑29)?\n",
    "\n",
    "**Please:**  \n",
    "- Write a brief **Introduction** stating the question and data scope.  \n",
    "- In your **Analysis**, compare each metric (Revenue, Gross Profit, Operational Income, Net Income, EBITDA, EPS and Revenue surprises) quarter‑over‑quarter, citing the exact figures.  \n",
    "- Highlight any notable trends (e.g., margin expansions or EPS misses).  \n",
    "- Finish with a concise **Conclusion** summarizing whether performance improved or deteriorated and why.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\",   \"content\": user_prompt},\n",
    "]\n",
    "\n",
    "question3Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question3Answer[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9430b",
   "metadata": {},
   "source": [
    "### Question 5:What insights can be concluded from the earnings call?\n",
    "\n",
    "#### Data Used for Prompt construction\n",
    "\n",
    "* To gain insights from the earnings call, we used the transcript available in the `earning_transcript.md` file. Since the full transcript is quite lengthy, our strategy was to break it into smaller sections and summarize each section individually using the LLM. By combining these individual summaries, we created a comprehensive overview of the entire earnings call. For the final prompt, we provided the LLM with this summarized version of the transcript and asked it to identify the key insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get function from indy to summarise the earnings call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_template_q5 = \"\"\"\n",
    "\"Note: In this response, please pay particular attention to executive tone, guidance, and strategic priorities.\\n\\n\"\n",
    "Here is the summarized earnings call transcript:\n",
    "{call_summary}\n",
    "\n",
    "**Question:**  \n",
    "What key insights can be concluded from the Tesla earnings call?\n",
    "\n",
    "**Please:**\n",
    "- Start with a brief **Overview** of the call’s focus.\n",
    "- Identify the **Key Themes** or concerns mentioned (e.g., demand, margin pressure, product roadmap).\n",
    "- Highlight any **management tone or forward-looking statements**.\n",
    "- Finish with a concise **Conclusion** that summarizes the strategic outlook or market signal from the call.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": filled_user_prompt},\n",
    "]\n",
    "\n",
    "question1Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question1Answer[0]['generated_text'])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
