{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e030378",
   "metadata": {},
   "source": [
    "# Data Analysis and Q&A Project Using a Local LLM\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project requires you to perform a comprehensive analysis of a company's stock data using only the provided data sources and a local LLM. Your analysis should answer the following six questions strictly based on the supplied data and documents—no external data is allowed. All generated answers must be firmly based on the provided data, without any fabricated content. In addition, your logic must be clear, and any attribution of events must be causally linked.\n",
    "\n",
    "---\n",
    "\n",
    "## Provided Data\n",
    "\n",
    "You will be provided with the following data sets:\n",
    "\n",
    "#### Stock Price Data (Json format)\n",
    "* Timeframe: Jan 22 to Feb 5\n",
    "* Fields: Open, High, Low, Close, Volume\n",
    "\n",
    "#### Quarterly Earnings Data for the Past Year (Json format)\n",
    "* Contains key financial indicators (e.g., revenue, eps) for each quarter.\n",
    "\n",
    "#### Full Earnings Transcript Call\n",
    "* The complete transcript of the earnings call, including management discussions and Q&A.\n",
    "\n",
    "#### Balance Sheet Data for the Past Year (Json format)\n",
    "* Includes assets, liabilities, and shareholders' equity information.\n",
    "\n",
    "#### News Articles\n",
    "* Full text of 10 news articles related to the company during the analysis period.\n",
    "\n",
    "---\n",
    "\n",
    "## Questions\n",
    "Using the provided data and a local LLM, you need to answer the following six questions:\n",
    "\n",
    "1. What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "2. Why did the price increase on Jan 30? Please provide potential factors.\n",
    "\n",
    "3. Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "4. With unsupervised Full Self Driving scheduled to launch in limited markets like Austin by June, what regulatory challenges does Tesla foresee for a nationwide or international rollout, and how is the company strategically preparing to address these hurdles?\n",
    "\n",
    "5. What insights can be concluded from the earnings call?\n",
    "\n",
    "6. Which key news events influenced the stock performance, and what insights do they offer?\n",
    "\n",
    "---\n",
    "\n",
    "## Project Requirements\n",
    "#### Data Source Restriction:\n",
    "- Only use the provided data and documents. No external data or information is allowed.\n",
    "\n",
    "#### Answer Generation:\n",
    "- All generated answers must strictly be based on the provided data and documents. The LLM should not \"invent\" information.\n",
    "\n",
    "#### Clear Logic and Causal Relationships:\n",
    "- For each question, your answers must clearly demonstrate logical reasoning, and any attribution of cause must be explicitly linked to events in the data.\n",
    "\n",
    "#### Prompt Design:\n",
    "- You must design your own prompts for calling the local LLM to ensure that the responses are generated strictly based on the analysis results.\n",
    "\n",
    "#### Result Evaluation:\n",
    "- After generating the answers, implement an evaluation step to assess whether the responses meet the above requirements in terms of data reliance, logical clarity, and correct causation.\n",
    "\n",
    "#### Please put the answers to these 6 questions in a dict at the end of your submitted Python nodebook file.\n",
    "\n",
    "For example\n",
    "```code\n",
    "{ \"Q1 answer\": \"Answer1\", \"Q2 answer\": \"Answer2\", \"Q3 answer\": \"Answer3\", \"Q4 answer4\": \"Answer4\", \"Q5 answer\": \"Answer5\", \"Q6 answer\": \"Answer6\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3ba393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/spear1/.local/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in /home/spear1/.local/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (1.3.5)\n",
      "Requirement already satisfied: ipython in /home/spear1/.local/lib/python3.10/site-packages (8.35.0)\n",
      "Requirement already satisfied: filelock in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/spear1/.local/lib/python3.10/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from ipython) (4.4.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython) (4.8.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/lib/python3/dist-packages (from ipython) (2.11.2)\n",
      "Requirement already satisfied: stack_data in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/spear1/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/spear1/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in /home/spear1/.local/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/spear1/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/spear1/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/spear1/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/spear1/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/spear1/.local/lib/python3.10/site-packages (from stack_data->ipython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/spear1/.local/lib/python3.10/site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/spear1/.local/lib/python3.10/site-packages (from stack_data->ipython) (0.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers accelerate pandas ipython\n",
    "# %pip install torch # Install PyTorch if you dont have it downloading \n",
    "\n",
    "DATA_DIR = \"447_dataset\"\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "import datetime\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290d56f",
   "metadata": {},
   "source": [
    "## Loading and Running the Local LLM\n",
    "\n",
    "1. **Imports Transformers utilities**  \n",
    "   - `AutoModelForCausalLM`: generic class for loading any GPT‑style model  \n",
    "   - `AutoTokenizer`: matching tokenizer for converting text ↔ tokens  \n",
    "   - `pipeline`: high‑level helper that ties model + tokenizer into one callable  \n",
    "\n",
    "2. **Specifies the model repository**  \n",
    "   ```python\n",
    "   model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d52b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# The pipeline will automatically use the model and tokenizer you just loaded\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) # Load the tokenizer\n",
    "\n",
    " # Create a pipeline for text generation\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 2000, # Limit the number of tokens generated\n",
    "    \"return_full_text\": False, # Return only the generated text\n",
    "    \"do_sample\": True, # Use sampling to generate text\n",
    "    \"temperature\": 0.1,# Control the randomness of the output\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"top_p\": 0.9, # Control the diversity of the output\n",
    "    \"top_k\": 50, # Control the diversity of the output\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "699af2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_system_prompt = ( \n",
    "    \"You are an expert financial data analyst LLM.\\n\"\n",
    "    \"You must ensure the following rules are followed:\\n\"\n",
    "    \"1. Use only the data summaries provided in the prompt.\\n\"\n",
    "    \"2. Show clear step-by-step reasoning, linking each claim directly to the data.\\n\"\n",
    "    \"3. Ensure all explanations are clear, logical, and accurate.\\n\"\n",
    "    \"4. Do not invent or hallucinate any information.\\n\"\n",
    "    \"After your answer, provide a checklist summary indicating whether each criterion is satisfied. \"\n",
    "    \"If any criterion is not met, include a brief explanation.\"\n",
    ")\n",
    "\n",
    "\n",
    "def trim_reasoning(raw):\n",
    "    tag = \"</think>\"\n",
    "    idx = raw.find(tag)\n",
    "\n",
    "    if idx != -1:\n",
    "        answer = raw[idx + len(tag):].strip()\n",
    "    else:\n",
    "        answer = raw.strip()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b8eac",
   "metadata": {},
   "source": [
    "## Evaluation of the LLM response using the LLM as an evaluator\n",
    "\n",
    "The bellow code cell will show how we built our function to evaluate the LLM response based on the following parameters:\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "26c2a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_system_prompt = (\n",
    "    \"You are a critical and strict reviewer tasked with evaluating the quality and integrity of a financial analysis answers generated by another LLM.\\n\"\n",
    "    \"Your job is to verify that the answer:\\n\"\n",
    "    \"1. You need to strictly make sure only the data provided is used in the response (no outside info).\\n\"\n",
    "    \"2. Clearly explains its logic and reasoning.\\n\"\n",
    "    \"3. Attributes any cause-effect relationships directly to the data.\\n\"\n",
    "    \"4. You must strictly avoid speculation or using made-up facts.\\n\"\n",
    "    \"Please provide a checklist review with Yes/No for each point, followed by a short explanation of any issues you found.\"\n",
    ")\n",
    "\n",
    "evaluation_system_prompt_extra = (\"YOU MUST JUST EVALUATE THE ANSWER GIVEN BY THE LLM!\")\n",
    "\n",
    "\n",
    "evaluation_user_prompt_template = \"\"\"\n",
    "    Below is a question, the data provided, and the answer generated by the LLM:\n",
    "\n",
    "    **Question Answered by the LLM:**\n",
    "    {question}\n",
    "\n",
    "    **Data Provided to the LLM:**\n",
    "    {data_snippet}\n",
    "\n",
    "    **LLM's Answer:**\n",
    "    {llm_answer}\n",
    "\n",
    "    You must carefully evaluate the LLM's answer based on the criteria described as follows:\n",
    "    1. You need to strictly make sure only the data provided is used in the response (no outside info).\n",
    "    2. Clearly explains its logic and reasoning.\n",
    "    3. Attributes any cause-effect relationships directly to the data.\n",
    "    4. You must strictly avoid speculation or using made-up facts.\n",
    "    \"\"\"\n",
    "def evaluate_response(generated_answer, data, question):\n",
    "    evaluation_prompt = evaluation_user_prompt_template.format(\n",
    "        question= question,\n",
    "        data_snippet=\"\\n\\n\".join(data),  # or a trimmed version of summaries\n",
    "        llm_answer=generated_answer\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": evaluation_system_prompt},\n",
    "        {\"role\": \"system\", \"content\": evaluation_system_prompt_extra},\n",
    "        {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "    ]\n",
    "\n",
    "    evaluation_result = pipe(messages, **generation_args)\n",
    "    display(Markdown(trim_reasoning(evaluation_result[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1d4bb",
   "metadata": {},
   "source": [
    "### Question 1:What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "#### Prompt construction\n",
    "\n",
    "* Here we need to monitor the performance of the tesla stock over the specified days. To monitor the performance of the stock the LLM just need to understand the how the pricing of the stock was through the given period hence why the LLM will need to see the infomation in the `prices.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "55617ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"   \n",
    "This Function extracts the price information and converts the informations\n",
    "into a simple readable format to be included in the prompt to the LLM\n",
    "\"\"\"\n",
    "def get_prices_summary():\n",
    "    prices_path = os.path.join(DATA_DIR, \"prices.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(prices_path, \"r\") as f:\n",
    "        prices = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and index\n",
    "    prices[\"Date\"] = pd.to_datetime(prices[\"Date\"])\n",
    "    prices = prices.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build a human-readable summary for each day\n",
    "    daily_summaries = []\n",
    "    for date, row in prices.iterrows():\n",
    "        daily_summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Open ${row['Open']:.2f}, \"\n",
    "            f\"High ${row['Hight']:.2f}, \"\n",
    "            f\"Low ${row['Low']:.2f}, \"\n",
    "            f\"Close ${row['Close']:.2f}, \"\n",
    "            f\"Volume {int(row['Volume']):,}\"\n",
    "        )\n",
    "\n",
    "    # Join them into one block of text\n",
    "    daily_summary_text = \"\\n\".join(daily_summaries)\n",
    "    return daily_summary_text\n",
    "\n",
    "\n",
    "#print(get_prices_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e33e7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Introduction  \n",
       "Tesla stock performance from January 22nd to February 5th was analyzed using provided data summaries. The study examined opening, high, low, close prices, and trading volumes across these dates. The goal was to assess the stock's stability and volatility during this period.\n",
       "\n",
       "---\n",
       "\n",
       "### Analysis  \n",
       "\n",
       "#### Key Dates and Figures  \n",
       "| Date       | Open Price | High Price | Low Price | Close Price | Trading Volume | Volume % Change (%) |\n",
       "|------------|-------------|------------|-----------|-------------|----------------|--------------------|\n",
       "| 2025-01-22 | $416.81     | $428.00    | $414.59   | $415.11      | 60,963         | +0.5%              |\n",
       "| 2025-01-23 | $416.06     | $420.73    | $408.95   | $412.38      | 50,690         | -0.6%             |\n",
       "| 2025-01-24 | $414.45     | $418.88    | $405.78   | $406.58      | 56,427         | -1.2%             |\n",
       "| 2025-01-27 | $394.80     | $406.69    | $389.00   | $397.15      | 58,125         | -2.1%             |\n",
       "| 2025-01-28 | $396.91     | $400.59    | $386.50   | $398.09      | 48,910         | -1.4%             |\n",
       "| 2025-01-29 | $395.21     | $398.59    | $384.48   | $389.10      | 68,033         | -2.0%             |\n",
       "\n",
       "#### Trading Activity  \n",
       "- **Volume % Change**: Trading volumes peaked on the 22nd at 60,963 shares, suggesting strong interest. The volume dropped on the 23rd to 50,690 shares, likely due to selling pressure or market sentiment. The volume increased on the 24th to 56,427 shares, indicating some buying momentum.\n",
       "- **Volume Analysis**: The volume remained consistent on the second half of the period, suggesting continued activity despite some price declines.\n",
       "\n",
       "#### Price Movements  \n",
       "- **High to Low**: The stock experienced small increases on the 27th and 28th, reflecting potential positive news or earnings reports.\n",
       "- **Low to High**: The stock faced significant drops on the 24th and 29th, indicating possible selling pressure or market reactions.\n",
       "\n",
       "#### Percentage Changes  \n",
       "- The stock maintained a relatively stable level throughout the period, with minor fluctuations. The percentage changes were mostly within ±1%, indicating moderate volatility.\n",
       "\n",
       "#### Causal Insights  \n",
       "1. **Earnings Report Impact**: The increase on the 27th could be linked to Tesla's earnings report, which often triggers positive news and increases investor interest.\n",
       "2. **Market Corrections**: The drops on the 24th and 29th may have been due to market corrections or external factors affecting Tesla's performance.\n",
       "\n",
       "---\n",
       "\n",
       "### Conclusion  \n",
       "Over the period from January 22nd to February 5th, Tesla stock exhibited mixed performance. The stock generally maintained a steady level, with minor volatility observed on the 24th and 29th. The stock rose temporarily towards the end of the second week, driven by potential earnings reports. Overall, Tesla's stock performed moderately well during this time frame, with some days marked by heightened volatility."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_prompt_template_q1 =( \"\"\"\n",
    "    Here is the summarized Tesla data for Jan 22 - Feb 5:\n",
    "    {price_info}\n",
    "\n",
    "    **Question:**  \n",
    "    What was the performance of Tesla stock over this period?\n",
    "                          \n",
    "    **Please:**\n",
    "    - Write a brief **Introduction** stating the question and data scope.  \n",
    "    - In your **Analysis**, cite the exact figures (dates, prices, percent changes, volumes).  \n",
    "    - Draw any causal insights clearly (e.g., “the drop on Feb 1 may be linked to…”).  \n",
    "    - Finish with a concise **Conclusion** summarizing overall performance.\n",
    "    - You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\")\n",
    "\n",
    "# Fill in the template with specific data\n",
    "filled_user_prompt = user_prompt_template_q1.format(\n",
    "    price_info = get_prices_summary()\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": filled_user_prompt},\n",
    "]\n",
    "\n",
    "question1Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question1Answer[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee8adcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Evaluation of Answer:**\n",
       "\n",
       "The answer provided is comprehensive and adheres strictly to the specified criteria. Here's a breakdown of how it meets each criterion:\n",
       "\n",
       "1. **Uses Only Data Provided**:  \n",
       "   The answer meticulously uses all the data points provided. It includes every single day from January 22 to February 5, detailing the open, high, low, close prices, and trading volumes for each day. There is no addition or speculation beyond the data presented.\n",
       "\n",
       "2. **Clearly Explains Its Logic and Reasoning**:  \n",
       "   The answer begins with an introduction that outlines the purpose of the analysis. It then proceeds to explain the rationale behind each segment of the data. For instance, it mentions the peak trading volume on January 22, which suggests strong interest, and the subsequent decline on January 29, possibly due to market corrections. This structured approach ensures clarity and understanding among readers.\n",
       "\n",
       "3. **Attività Cause-Effect Relationships Directly to Data**:  \n",
       "   The answer effectively attributes price movements to underlying factors. For example, the rise on January 27 is linked to the assumption that Tesla's earnings report would positively impact the stock price. Similarly, the decline on January 29 is attributed to market corrections, both of which are directly supported by the data provided.\n",
       "\n",
       "4. **Avoids Speculation or Making Up Facts**:  \n",
       "   The answer avoids any speculative claims or assumptions beyond what is evident in the data. All attributions of price movements to specific events are grounded in the provided information, ensuring factual accuracy.\n",
       "\n",
       "In conclusion, the answer is thorough, uses only the data provided, explains its reasoning clearly, attributes causes correctly, and avoids speculation or making up facts. Therefore, it receives a high score according to the specified criteria."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating the response for Question 1 using the LLM\n",
    "question_1 = \"What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\"\n",
    "price_summary = get_prices_summary()\n",
    "evaluate_response(trim_reasoning(question1Answer[0]['generated_text']), price_summary, question_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc95b2",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 1\n",
    "\n",
    "Overall, this answer was more detailed and data-driven than our previous attempts, which we liked. It clearly broke down the price movements, trading volumes, and even grouped insights around volatility and potential causes. We appreciated that it highlighted specific dates and referenced volume spikes accurately. However, some of the causal links — like attributing a rise on the 27th to earnings or calling a drop on the 24th a market correction — still feel speculative because the provided data doesn’t include any earnings report directly tied to that day. It was nice that the answer attempted to analyze sentiment, but we agreed that it still slightly overstepped the “no hallucination” rule. The formatting was clean, and the conclusion wrapped up the trends well. Overall, it’s a solid response but could improve by sticking closer to just what the numbers show.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb7491",
   "metadata": {},
   "source": [
    "# Question 2 \n",
    "### Why did the price increase on Jan 30? Please provide potential factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc284196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Improve Product Quality and Customer Satisfaction  \n",
      "- Cost Management and Efficiency Improvements  \n",
      "- Revenue Growth of 15%\n",
      "\n",
      "- Company performance showed strong Q2 results with revenue growth of 15% YoY and operating income improvement of 2% YOY.  \n",
      "- Key financial metrics include revenue of $867 million, operating income of $195 million, EBITDA of $180 million, and net income of $175 million.  \n",
      "- Management emphasized continued innovation and cost control efforts as part of the strategy.  \n",
      "- Future outlook highlights positive expectations for growth and diversification opportunities.\n",
      "\n",
      "- Revenue growth from $10 billion to $12 billion.  \n",
      "- Net profit increased by 15%.  \n",
      "- Cost management strategies implemented to reduce expenses.  \n",
      "- Future expansion plans targeting new markets.\n",
      "\n",
      "- Revenue growth of 15% YoY, driven by strong demand for new products.  \n",
      "- Cost management improvements, with operating expenses reduced by 20%.  \n",
      "- Strong segment margins across all product lines, particularly in the tech and consumer segments.  \n",
      "- Strategic focus on expansion into emerging markets and enhanced customer support.\n",
      "\n",
      "- Revenue growth from $10B to $12B, driven by strong demand and competitive pricing.  \n",
      "- Net profit increased from $5B to $6B, reflecting improved profitability and cost efficiency.  \n",
      "- Cost management strategies reduced expenses by 10%, supporting sustainable growth.  \n",
      "- Customer satisfaction improvements led to higher repeat business and brand loyalty.  \n",
      "- Strategic initiatives such as market expansion and R&D investment are expected to drive future success.\n",
      "\n",
      "- Revenue growth of [specific figure] year-over-year, driven by strong demand and efficient cost management.  \n",
      "- Product diversification and expansion, showing potential for future market expansion and higher profitability.  \n",
      "- Pricing strategy focused on affordability while maintaining competitive edge, with aggressive marketing efforts.  \n",
      "- Operational improvements such as automation and enhanced supply chain management, leading to cost savings and increased efficiency.  \n",
      "- Call emphasizes continued focus on innovation and customer satisfaction as key drivers for long-term success.\n",
      "\n",
      "- Revenue growth from $10 billion to $12 billion.  \n",
      "- Cost management improvements leading to a 9% segment margin increase.  \n",
      "- Future expansion plans including new markets.\n",
      "\n",
      "- Revenue growth from $10 billion to $12 billion.  \n",
      "- Net profit increase by 15% from last year.  \n",
      "- Cost management improvements, including expense reductions of 10%.  \n",
      "- Enhanced customer satisfaction, leading to a 5% increase in retention rate.  \n",
      "- Strategic partnerships expansion and improved operational efficiency.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "system_prompt_ts = (\n",
    "    \"\"\"\n",
    "    You are an expert financial analysis assistant.  \n",
    "    Always respond in clear, concise English.  \n",
    "    Use only the information explicitly provided in the user’s inputs.  \n",
    "    Do not invent, fetch, or reference any external data.  \n",
    "    Produce only bullet points—no prose.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "user_prompt_ts = (\n",
    "    \"\"\"\n",
    "Please summarize the following earnings‑call excerpt into 3–4 bullet points,\n",
    "focusing on key financial metrics, guidance, or other actionable insights.\n",
    "Do not add commentary or restate the question—just the bullets.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "with open(\"447_dataset/earning_transcript.md\", \"r\") as f:\n",
    "    earnings_transcript_data = f.read()\n",
    "\n",
    "lines = earnings_transcript_data.splitlines()\n",
    "\n",
    "chunks = []\n",
    "current_chunk = []\n",
    "max_lines_per_chunk = 50\n",
    "\n",
    "for line in lines:\n",
    "    current_chunk.append(line)\n",
    "    # once we've collected 50 lines, seal off a chunk\n",
    "    if len(current_chunk) >= max_lines_per_chunk:\n",
    "        # join back into one string\n",
    "        chunk_text = \"\\n\".join(current_chunk)\n",
    "        chunks.append(chunk_text)\n",
    "        # reset for the next chunk\n",
    "        current_chunk = []\n",
    "\n",
    "if current_chunk:\n",
    "    chunk_text = \"\\n\".join(current_chunk)\n",
    "    chunks.append(chunk_text)\n",
    "\n",
    "transcript_summary = []\n",
    "\n",
    "def clean_summary(raw):\n",
    "    # 1) remove any explicit <think>…</think> if they ever appear\n",
    "    s = re.sub(r\"<think>.*?</think>\", \"\", raw, flags=re.S)\n",
    "    # 2) drop any lines beginning with “Thought:” or “Thinking”\n",
    "    s = re.sub(r\"(?m)^(Thought:|Thinking:?).*\\n?\", \"\", s)\n",
    "    # 3) keep only from the first bullet (dash or •) onward\n",
    "    m = re.search(r\"(?m)^[-•]\\s+\", s)\n",
    "    if m:\n",
    "        return s[m.start():].strip()\n",
    "    # fallback: strip leading/trailing whitespace\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "for i in range(len(chunks)):\n",
    "    filled_user_ts = user_prompt_ts.format(earnings_transcript=chunks[i])\n",
    "    messages_ts = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt_ts},\n",
    "        {\"role\": \"user\",   \"content\": filled_user_ts},\n",
    "    ] \n",
    "    out = pipe(messages_ts, **generation_args)\n",
    "    raw = out[0][\"generated_text\"]\n",
    "    summary = clean_summary(raw)\n",
    "    transcript_summary.append(summary)\n",
    "\n",
    "full_transcript_summary = \"\\n\\n\".join(transcript_summary)\n",
    "\n",
    "\n",
    "\n",
    "# you can print it or write it to a file\n",
    "print(full_transcript_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d085a8",
   "metadata": {},
   "source": [
    "### Extract News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e0243",
   "metadata": {},
   "source": [
    "### Extract Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "with open(\"447_dataset/news.json\", \"r\") as f:\n",
    "    all_news = json.load(f)\n",
    "\n",
    "def parse_date(s: str) -> datetime.date:\n",
    "    return datetime.strptime(s.strip(), \"%B %d, %Y\").date()\n",
    "\n",
    "\n",
    "\n",
    "# define your window\n",
    "start = datetime(2025, 1, 25).date()\n",
    "end   = datetime(2025, 1,  30).date()\n",
    "\n",
    "news_window = [\n",
    "    article\n",
    "    for article in all_news\n",
    "    if start <= parse_date(article[\"date\"]) <= end\n",
    "]\n",
    "\n",
    "print(f\"Found {len(news_window)} articles between {start} and {end}:\")\n",
    "for a in news_window:\n",
    "    print(f\"- {a['date']}: {a['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea22a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"EpsActual\": 0.71,\n",
      "    \"EpsForecast\": 0.74037,\n",
      "    \"EpsSurprise\": -0.03,\n",
      "    \"RevenueActual\": 25167000000,\n",
      "    \"RevenueSurprise\": -596790000,\n",
      "    \"RevenueForecast\": 25763787850,\n",
      "    \"EarningReportDate\": \"2024-01-24T21:15:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"EpsActual\": 0.45,\n",
      "    \"EpsForecast\": 0.49506,\n",
      "    \"EpsSurprise\": -0.04,\n",
      "    \"RevenueActual\": 21301000000,\n",
      "    \"RevenueForecast\": 22255924550,\n",
      "    \"RevenueSurprise\": -954920000,\n",
      "    \"EarningReleaseDate\": \"2024-04-23T20:10:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"EpsActual\": 0.52,\n",
      "    \"EpsForecast\": 0.62013,\n",
      "    \"EpsSurprise\": -0.1,\n",
      "    \"RevenueActual\": 25500000000,\n",
      "    \"RevenueForecast\": 24740776400,\n",
      "    \"RevenueSurprise\": 759220000,\n",
      "    \"EarningReleaseDate\": \"2024-07-24T00:00:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"EpsActual\": 0.72,\n",
      "    \"EpsForecast\": 0.59756,\n",
      "    \"EpsSurprise\": 0.12,\n",
      "    \"RevenueActual\": 25182000000,\n",
      "    \"RevenueForecast\": 25441566840,\n",
      "    \"RevenueSurprise\": -259570000,\n",
      "    \"EarningReleaseDate\": \"2024-10-23T20:09:00Z\"\n",
      "  },\n",
      "  {\n",
      "    \"EpsActual\": 0.73,\n",
      "    \"EpsForecast\": 0.76703,\n",
      "    \"EpsSurprise\": -0.04,\n",
      "    \"EpsSurprisePercent\": -5.1948,\n",
      "    \"RevenueActual\": 25707000000,\n",
      "    \"RevenueSurprise\": -1424760000,\n",
      "    \"RevenueForecast\": 27131755850,\n",
      "    \"EarningReleaseDate\": \"2025-01-29T21:09:00Z\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# load all earnings entries\n",
    "with open(\"447_dataset/earning.json\", \"r\") as f:\n",
    "    earnings = json.load(f)\n",
    "\n",
    "# print the extracted data\n",
    "earnings = json.dumps(earnings, indent=2, ensure_ascii=False)\n",
    "print(earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76450e06",
   "metadata": {},
   "source": [
    "### Relavant Price Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def load_prices(path: str):\n",
    "    \"\"\"Load the full list of price bars from a JSON file.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def filter_by_date(prices, start_date: str, end_date: str):\n",
    "    \"\"\"\n",
    "    Return only those price entries whose 'Date' field\n",
    "    falls between start_date and end_date, inclusive.\n",
    "    Dates must be in 'YYYY-MM-DD' format.\n",
    "    \"\"\"\n",
    "    start = datetime.fromisoformat(start_date).date()\n",
    "    end   = datetime.fromisoformat(end_date).date()\n",
    "\n",
    "    return [\n",
    "        p for p in prices\n",
    "        if start <= datetime.fromisoformat(p[\"Date\"]).date() <= end\n",
    "    ]\n",
    "\n",
    "\n",
    "    \n",
    "start_date = \"2025-01-20\"\n",
    "end_date   = \"2025-01-30\"\n",
    "\n",
    "prices = load_prices(\"447_dataset/prices.json\")\n",
    "window = filter_by_date(prices, start_date, end_date)\n",
    "\n",
    "relevant_prices = json.dumps(window, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3d8053d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 41\u001b[0m\n\u001b[1;32m     32\u001b[0m filled_user_q2 \u001b[38;5;241m=\u001b[39m user_prompt_q2\u001b[38;5;241m.\u001b[39mformat(earnings_data \u001b[38;5;241m=\u001b[39m earnings, relevant_price_data \u001b[38;5;241m=\u001b[39m relevant_prices, news_data \u001b[38;5;241m=\u001b[39m news_window, transcript_data \u001b[38;5;241m=\u001b[39m full_transcript_summary)\n\u001b[1;32m     34\u001b[0m messages_q2 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     35\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt_q2},\n\u001b[1;32m     36\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: filled_user_q2},\n\u001b[1;32m     37\u001b[0m     ] \n\u001b[0;32m---> 41\u001b[0m output_q2 \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages_q2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_q2[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:280\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mChat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m         chats \u001b[38;5;241m=\u001b[39m (Chat(chat) \u001b[38;5;28;01mfor\u001b[39;00m chat \u001b[38;5;129;01min\u001b[39;00m text_inputs)  \u001b[38;5;66;03m# 🐈 🐈 🐈\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1379\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1372\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1373\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1376\u001b[0m         )\n\u001b[1;32m   1377\u001b[0m     )\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1386\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1385\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1386\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1286\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1285\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1286\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1287\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:385\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    383\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 385\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[1;32m    388\u001b[0m     generated_sequence \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msequences\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2465\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2457\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2458\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2459\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2460\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2461\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2462\u001b[0m     )\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2465\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2472\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2476\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2477\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2478\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2479\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2480\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2482\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:3434\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3434\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3436\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3437\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3438\u001b[0m     outputs,\n\u001b[1;32m   3439\u001b[0m     model_kwargs,\n\u001b[1;32m   3440\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3441\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:823\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    819\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    820\u001b[0m )\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:549\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    538\u001b[0m         partial(decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs),\n\u001b[1;32m    539\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m         position_embeddings,\n\u001b[1;32m    547\u001b[0m     )\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:262\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:169\u001b[0m, in \u001b[0;36mQwen2Attention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    168\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m--> 169\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "system_prompt_q2 = (\"\"\"\n",
    "You are an expert financial analysis assistant.  \n",
    "Use only the information explicitly provided in the user’s inputs.  \n",
    "Do not invent, fetch, or reference any external data.\n",
    "You must suport all answers with evidence and reasoning\n",
    "\"\"\")\n",
    "\n",
    "user_prompt_q2 = \"\"\"\n",
    "Below is all the data—no other sources allowed:\n",
    "\n",
    "You must suport all answers with evidence and reasoning\n",
    "\n",
    "Be verbrose\n",
    "\n",
    "1) Earnings results (earning.json):\n",
    "{earnings_data}\n",
    "\n",
    "2) Stock price summary:\n",
    "{relevant_price_data}\n",
    "\n",
    "3) News articles during the time:\n",
    "{news_data}\n",
    "\n",
    "4) Summary of an earnings talk the prior day:\n",
    "{transcript_data}\n",
    "\n",
    "Question\n",
    "Why did the stock price increase on January 30?\n",
    "List the likely drivers with an explanation, and cite exactly which data (earnings, transcript, news article, or price bar) supports it.\n",
    "\"\"\"\n",
    "\n",
    "filled_user_q2 = user_prompt_q2.format(earnings_data = earnings, relevant_price_data = relevant_prices, news_data = news_window, transcript_data = full_transcript_summary)\n",
    "\n",
    "messages_q2 = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt_q2},\n",
    "        {\"role\": \"user\",   \"content\": filled_user_q2},\n",
    "    ] \n",
    "\n",
    "\n",
    "\n",
    "output_q2 = pipe(messages_q2, **generation_args)\n",
    "print(output_q2[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6428e1",
   "metadata": {},
   "source": [
    "### Question 3:Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "#### Data Used for Prompt construction\n",
    "\n",
    "* For the LLM to have any insight of quaterly financial information, I will provide it the `balancesheet.json` as this file contains the quaterly financial figures. We will use this data so the LLM is a aware of the performance of the previous 1-2 years. This gives the LLM a base to compare against the current financial quater( 2025 Q1). Since the balance sheet has a lot of infomation, we dont want to overload the LLM with too many features to consider when it comes up with its decison so we will handpick some important features from the balance sheet from each quater.\n",
    "\n",
    "\n",
    "* The Data found in the `earnings.json` also contains relavant financial information for the past five quaters, which the LLM can use compare the performance of the company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a75f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Balance Sheet Summary----------\n",
      "2023-12-31: Revenue $25.2M, Gross Profit $4.4M (17.6%), Operational Income $2.1M (8.2%), Net Income $7.9M (31.5%), EBITDA $3.5M, Total Expenses $23.1M, \n",
      "2024-03-31: Revenue $21.3M, Gross Profit $3.7M (17.4%), Operational Income $1.2M (5.5%), Net Income $1.2M (5.5%), EBITDA $2.9M, Total Expenses $20.1M, \n",
      "2024-06-30: Revenue $25.5M, Gross Profit $4.6M (18.0%), Operational Income $2.2M (8.7%), Net Income $1.5M (5.8%), EBITDA $3.3M, Total Expenses $23.3M, \n",
      "2024-09-30: Revenue $25.2M, Gross Profit $5.0M (19.8%), Operational Income $2.8M (11.0%), Net Income $2.2M (8.6%), EBITDA $4.2M, Total Expenses $22.4M, \n",
      "2024-12-31: Revenue $25.7M, Gross Profit $4.2M (16.3%), Operational Income $1.6M (6.2%), Net Income $2.3M (9.0%), EBITDA $4.4M, Total Expenses $24.1M, \n",
      "\n",
      "-----------Earnings Summary---------------\n",
      "2024-01-24: EPS predicted: 0.74, EPS actual: 0.71, EPS surprise: -0.03; Revenue predicted: $25.76B, Revenue actual: $25.17B\n",
      "2024-04-23: EPS predicted: 0.50, EPS actual: 0.45, EPS surprise: -0.04; Revenue predicted: $22.26B, Revenue actual: $21.30B\n",
      "2024-07-24: EPS predicted: 0.62, EPS actual: 0.52, EPS surprise: -0.10; Revenue predicted: $24.74B, Revenue actual: $25.50B\n",
      "2024-10-23: EPS predicted: 0.60, EPS actual: 0.72, EPS surprise: 0.12; Revenue predicted: $25.44B, Revenue actual: $25.18B\n",
      "2025-01-29: EPS predicted: 0.77, EPS actual: 0.73, EPS surprise: -0.04; Revenue predicted: $27.13B, Revenue actual: $25.71B\n"
     ]
    }
   ],
   "source": [
    "def get_earnings_summary():\n",
    "    \"\"\"\n",
    "    Reads earning.json and returns a plain summary with:\n",
    "    - EPS predicted / actual\n",
    "    - Revenue predicted / actual (in billions)\n",
    "    \"\"\"\n",
    "    earnings_path = os.path.join(DATA_DIR, \"earning.json\")\n",
    "\n",
    "    with open(earnings_path, \"r\") as f:\n",
    "        earnings_json = json.load(f)\n",
    "\n",
    "    lines = []\n",
    "    for rec in earnings_json:\n",
    "        dt = rec.get(\"EarningReleaseDate\") or rec.get(\"EarningReportDate\")\n",
    "        if not dt:\n",
    "            continue\n",
    "\n",
    "        date = pd.to_datetime(dt).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        eps_actual   = rec.get(\"EpsActual\", 0)\n",
    "        eps_forecast = rec.get(\"EpsForecast\", 0)\n",
    "        eps_surprise   = rec.get(\"EpsSurprise\", 0)\n",
    "\n",
    "        rev_actual   = rec.get(\"RevenueActual\", 0) / 1e9\n",
    "        rev_forecast = rec.get(\"RevenueForecast\", 0) / 1e9\n",
    "\n",
    "        line = (\n",
    "            f\"{date}: \"\n",
    "            f\"EPS predicted: {eps_forecast:.2f}, EPS actual: {eps_actual:.2f}, EPS surprise: {eps_surprise:.2f}; \"\n",
    "            f\"Revenue predicted: ${rev_forecast:.2f}B, Revenue actual: ${rev_actual:.2f}B\"\n",
    "        )\n",
    "        lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def get_balance_sheet_summary():\n",
    "    \"\"\"\n",
    "    This function extracts financial statement information from balencesheet.json\n",
    "    and returns a readable summary line for each quarter.\n",
    "    \"\"\"\n",
    "    bs_path = os.path.join(DATA_DIR, \"balencesheet.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(bs_path, \"r\") as f:\n",
    "        balance_sheet = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and sort\n",
    "    balance_sheet[\"Date\"] = pd.to_datetime(balance_sheet[\"Date\"])\n",
    "    balance_sheet = balance_sheet.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build human-readable lines\n",
    "    summaries = []\n",
    "    for date, row in balance_sheet.iterrows():\n",
    "        rev       = row.get(\"Total Revenue\", 0) / 1e6\n",
    "        gp        = row.get(\"Gross Profit\", 0) / 1e6\n",
    "        op_inc    = row.get(\"Operating Income\", 0) / 1e6\n",
    "        net_inc   = row.get(\"Net Income Common Stockholders\", 0) / 1e6\n",
    "        ebitda    = row.get(\"EBITDA\", 0) / 1e6\n",
    "        tot_exp   = row.get(\"Total Expenses\", 0) / 1e6\n",
    "\n",
    "        # Calculate margins and ratios safely\n",
    "        gross_margin   = gp / rev * 100 if rev else 0\n",
    "        op_margin      = op_inc / rev * 100 if rev else 0\n",
    "        net_margin     = net_inc / rev * 100 if rev else 0\n",
    "\n",
    "        summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Revenue ${rev:.1f}M, Gross Profit ${gp:.1f}M ({gross_margin:.1f}%), \"\n",
    "            f\"Operational Income ${op_inc:.1f}M ({op_margin:.1f}%), Net Income ${net_inc:.1f}M ({net_margin:.1f}%), \"\n",
    "            f\"EBITDA ${ebitda:.1f}M, Total Expenses ${tot_exp:.1f}M, \"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(summaries)\n",
    "\n",
    "print(\"----------Balance Sheet Summary----------\")\n",
    "print(get_balance_sheet_summary())\n",
    "print(\"\\n-----------Earnings Summary---------------\")\n",
    "print(get_earnings_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4695ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Introduction**\n",
       "\n",
       "The question asks us to evaluate the performance of the company during the quarter ending on 2025-01-29 compared to the previous year's same quarter. By examining the provided data, we can identify key trends and insights that shed light on the company's financial health and future prospects.\n",
       "\n",
       "**Analysis**\n",
       "\n",
       "To assess the performance, we analyze each relevant metric:\n",
       "\n",
       "1. **Revenue**: The revenue for the quarter ending on 2025-01-29 is $25.7M, matching the revenue reported for the same period in 2024. This indicates no change in total revenue during this reporting period.\n",
       "\n",
       "2. **Gross Profit**: The gross profit for 2025-01-29 is $4.2M, whereas it was $4.6M in 2024. This represents an 8% decrease in gross profit, suggesting potential cost increases or higher operating expenses.\n",
       "\n",
       "3. **Operating Income**: Operating income for 2025-01-29 is $3.3M, down from $3.5M in 2024. This decline reflects additional expenses beyond gross profit, such as administrative costs or interest payments.\n",
       "\n",
       "4. **Net Income**: The net income for 2025-01-29 is $2.2M, a significant drop from $2.9M in 2024. This indicates reduced profitability post-tax, likely due to higher operational costs or tax implications.\n",
       "\n",
       "5. **EBITDA**: EBITDA for 2025-01-29 is $4.4M, up by approximately 33% compared to 2024. This positive figure highlights improved profitability before tax, signaling better efficiency.\n",
       "\n",
       "6. **EPS**: The earnings per share (EPS) for 2025-01-29 is $0.73, down from $0.71 in 2024. While the revenue growth was modest, the drop in EPS suggests underlying issues related to profitability.\n",
       "\n",
       "7. **Revenue Surprises**: The revenue surprise for 2025-01-29 is -0.04%, indicating actual revenue was slightly lower than expected. In contrast, the 2024-12-31 quarter had a surprise of -0.03%.\n",
       "\n",
       "**Conclusion**\n",
       "\n",
       "The performance of the company during the quarter ending on 2025-01-29 shows a mixed result. Although there was a slight improvement in revenue, the significant drop in net income and EPS indicate a deterioration in overall profitability. Key areas of concern include increased operational expenses, particularly in gross profit and operating income, which could impact future financial stability. Further analysis of these metrics will help determine the next steps for the company's financial strategy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question3_user_prompt = f\"\"\"\n",
    "Here are your two data summaries:\n",
    "\n",
    "**Balance Sheet Summary** \n",
    "- Balance sheet summary containing the quaterly financial information for the previous quaters \n",
    "{get_balance_sheet_summary()}\n",
    "\n",
    "\n",
    "**Earnings Summary**  \n",
    "- Earnings summary containing the quaterly earnings information for the previous quaters and the current quater(2025 Q1)\n",
    "{get_earnings_summary()}\n",
    "\n",
    "**Question:**  \n",
    "Compared with previous quarters, how is the performance of this quarter (ending 2025‑01‑29)?\n",
    "\n",
    "**Please:**  \n",
    "- Write a brief **Introduction** stating the question and data scope.  \n",
    "- In your **Analysis**, compare each metric (Revenue, Gross Profit, Operational Income, Net Income, EBITDA, EPS and Revenue surprises) quarter‑over‑quarter, citing the exact figures.  \n",
    "- Highlight any notable trends (e.g., margin expansions or EPS misses).  \n",
    "- Finish with a concise **Conclusion** summarizing whether performance improved or deteriorated and why.\n",
    "- You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\",   \"content\": question3_user_prompt},\n",
    "]\n",
    "\n",
    "question3Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question3Answer[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aadc9aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Evaluation of the Answer\n",
       "\n",
       "#### **Criteria Overview**\n",
       "The answer needs to meet three main criteria:\n",
       "1. **Data Usage**: Only the provided data should be used.\n",
       "2. **Logic Explanation**: Clear reasoning behind the conclusions.\n",
       "3. **Cause-Effect Relationships**: Direct links between data points.\n",
       "\n",
       "#### **Evaluation Analysis**\n",
       "\n",
       "1. **Data Usage**:\n",
       "   - The answer uses data from multiple quarters, including 2024 and 2025, to compare performance.\n",
       "   - Data points such as revenue, gross profit, operating income, net income, EBITDA, and EPS are included.\n",
       "   - All necessary data is referenced, ensuring compliance with the first criterion.\n",
       "\n",
       "2. **Logic Explanation**:\n",
       "   - The answer logically compares each financial metric across the years.\n",
       "   - For example, it notes that revenue remained similar while net income decreased, explaining why.\n",
       "   - The explanation is clear and concise, addressing the second criterion effectively.\n",
       "\n",
       "3. **Cause-Effect Relationships**:\n",
       "   - The answer identifies specific causes for changes, such as decreased gross profit and higher operating expenses.\n",
       "   - It connects these causes to their respective effects, providing a logical flow.\n",
       "   - However, the answer does not provide specific numerical values for EBITDA and EPS, which may limit precision.\n",
       "\n",
       "#### **Strengths**\n",
       "- The answer effectively addresses the primary criteria.\n",
       "- It provides sufficient detail to understand the performance trends without unnecessary complexity.\n",
       "\n",
       "#### **Areas for Improvement**\n",
       "- Including specific numerical examples for EBITDA and EPS could enhance clarity and precision.\n",
       "- The lack of quantitative data for EBITDA and EPS might reduce the answer's effectiveness in meeting the third criterion.\n",
       "\n",
       "#### **Final Assessment**\n",
       "The answer is well-structured and meets the essential criteria. It clearly explains the reasons behind the performance differences and establishes cause-effect relationships where applicable. While minor improvements could further enhance its precision, the current version is sufficiently effective."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation of the response for question 3 using the LLM\n",
    "\n",
    "question_3 = \"Compared with previous quarters, how is the performance of this quarter (ending 2025‑01‑29)?\"\n",
    "data_q3 = \"\\n\".join([\n",
    "    \"----------Balance Sheet Summary----------\", \n",
    "    get_balance_sheet_summary(), \n",
    "    \"\\n-----------Earnings Summary---------------\", \n",
    "    get_earnings_summary()\n",
    "])\n",
    "\n",
    "evaluate_response(trim_reasoning(question3Answer[0]['generated_text']), data_q3, question_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a3abe",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 3\n",
    "\n",
    "The structure of the response is clear and well-organized, breaking down each metric effectively. However, it compares the wrong quarters — claiming a year-over-year comparison with 2024-01 but actually pulling numbers from 2024-12. Several values are also inaccurate: for example, revenue wasn’t flat, it increased slightly (~2%), and operating income was misreported. The revenue surprise was also miscalculated (off by several percentage points).The tone is professional, and the format works well. The model seems to struggle a bit with showing relationship to the data but it was abale to structure a decent answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707608a",
   "metadata": {},
   "source": [
    "# DO QUESTION 4 INDUWARA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9430b",
   "metadata": {},
   "source": [
    "### Question 5:What insights can be concluded from the earnings call?\n",
    "\n",
    "#### Data Used for Prompt construction\n",
    "\n",
    "* To gain insights from the earnings call, we used the transcript available in the `earning_transcript.md` file. Since the full transcript is quite lengthy, our strategy was to break it into smaller sections and summarize each section individually using the LLM. By combining these individual summaries, we created a comprehensive overview of the entire earnings call. For the final prompt, we provided the LLM with this summarized version of the transcript and asked it to identify the key insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get function from indy to summarise the earnings call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "127d5198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Summary of Key Insights from the Tesla Earnings Call:\n",
       "\n",
       "#### Overview:\n",
       "The earnings call highlighted Tesla's strong fundamentals, driven by robust revenue growth and effective cost management. The company has expanded its product line, focusing on electric vehicles (EVs) and other high-demand areas. Management emphasized innovation and cost control, aiming to sustain profitability while driving future growth.\n",
       "\n",
       "#### Key Themes:\n",
       "1. **Revenue Growth**: Tesla reported a 15% YoY revenue growth, primarily due to strong demand for new products, particularly EVs. This expansion aligns with Tesla's strategy to diversify into new markets.\n",
       "   \n",
       "2. **Cost Management**: Despite the 15% revenue growth, operating income improved by 2% YOY, indicating effective cost management. Automation and enhanced supply chain management were key initiatives to achieve this improvement.\n",
       "\n",
       "3. **Customer Satisfaction**: While customer retention rates increased by 5%, there was no explicit mention of specific improvements beyond this. This could suggest room for further enhancement in service offerings.\n",
       "\n",
       "4. **Future Expansion Plans**: Tesla has already begun expanding into new markets, including EVs, which aligns with their overall strategy to diversify and grow.\n",
       "\n",
       "#### Management Tone:\n",
       "Management consistently emphasized innovation and cost control as core drivers of long-term success. This focus reflects Tesla's commitment to sustainability and profitability, which are critical for sustained growth.\n",
       "\n",
       "#### Future Goals:\n",
       "Tesla aims to continue driving growth and diversifying into emerging markets. Their expansion into EVs and other high-demand areas demonstrates a proactive approach to future success.\n",
       "\n",
       "#### Conclusion:\n",
       "The earnings call provides strong evidence of Tesla's fundamentals, expansion plans, and innovation focus. The company's ability to manage costs effectively and expand into new markets underscores their potential for sustained success."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_prompt_template_q5 = f\"\"\"\n",
    "\"Note: In this response, please pay particular attention to executive tone, guidance, and strategic priorities.\\n\\n\"\n",
    "Here is the summarized earnings call transcript:\n",
    "{full_transcript_summary}\n",
    "\n",
    "Question:\n",
    "What key insights can be concluded from the Tesla earnings call?\n",
    "\n",
    "Please:\n",
    "- Start with a **Overview** of the call’s focus.\n",
    "- Identify the **Key Themes** or concerns mentioned and briefly explain then with context from the call(e.g., demand, margin pressure, product roadmap).\n",
    "- Highlight any **management tone or forward-looking statements**.\n",
    "- Try to identify any statements about future goals of the company.\n",
    "- Finish with a concise **Conclusion** that summarizes the strategic outlook or market signal from the call.\n",
    "- You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt_template_q5},\n",
    "]\n",
    "\n",
    "question5Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question5Answer[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b704854c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Summary of Key Insights from the Tesla Earnings Call:\n",
       "\n",
       "#### Overview:\n",
       "The earnings call highlighted Tesla's strong fundamentals, driven by robust revenue growth and effective cost management. The company has expanded its product line, focusing on electric vehicles (EVs) and other high-demand areas. Management emphasized innovation and cost control, aiming to sustain profitability while driving future growth.\n",
       "\n",
       "#### Key Themes:\n",
       "1. **Revenue Growth**: Tesla reported a 15% YoY revenue growth, primarily due to strong demand for new products, particularly EVs. This expansion aligns with Tesla's strategy to diversify into new markets.\n",
       "   \n",
       "2. **Cost Management**: Despite the 15% revenue growth, operating income improved by 2% YOY, indicating effective cost management. Automation and enhanced supply chain management were key initiatives to achieve this improvement.\n",
       "\n",
       "3. **Customer Satisfaction**: While customer retention rates increased by 5%, there was no explicit mention of specific improvements beyond this. This could suggest room for further enhancement in service offerings.\n",
       "\n",
       "4. **Future Expansion Plans**: Tesla has already started expanding into new markets, including EVs, which aligns with their overall strategy to diversify and grow.\n",
       "\n",
       "#### Management Tone:\n",
       "Management consistently emphasized innovation and cost control as core drivers of long-term success. This focus reflects Tesla's strategy to sustain profitability while driving future growth.\n",
       "\n",
       "#### Future Goals:\n",
       "Tesla aims to continue driving growth and diversifying into new markets. Their expansion into EVs and other high-demand areas aligns with their overall strategy to grow.\n",
       "\n",
       "#### Conclusion:\n",
       "The earnings call provides strong evidence of Tesla's fundamentals, driven by robust revenue growth and effective cost management. The company has successfully managed these factors to achieve sustainable profitability while driving future growth."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation of the response for question 5 using the LLM\n",
    "\n",
    "question_5 = \"What key insights can be concluded from the Tesla earnings call?\"\n",
    "evaluate_response(trim_reasoning(question5Answer[0]['generated_text']), full_transcript_summary, question_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc18829",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 5\n",
    "\n",
    "# INDY HAS TO FINIsh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17271034",
   "metadata": {},
   "source": [
    "### Question 6:Which key news events influenced the stock performance, and what insights do they offer?\n",
    "\n",
    "#### Prompt construction\n",
    "\n",
    "* To analyse what news events affected the stock perferomance we will take a look at the news articles found in `news.json`. This file has new events but it seems to be large sections of text which might be hard to include in the prompt for the LLM. We will use a similar strategy to extract the most important infomation out of the news articles. We will split the news articles into batches of 3 and then ask the LLM to summarise the key information. Then we will combined these summaries to create a comprehensive summary that will be included in the final prompt to the LLM, where it will use the summary to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing article 1/10...\n",
      "Summarizing article 2/10...\n",
      "Summarizing article 3/10...\n",
      "Summarizing article 4/10...\n",
      "Summarizing article 5/10...\n",
      "Summarizing article 6/10...\n",
      "Summarizing article 7/10...\n",
      "Summarizing article 8/10...\n",
      "Summarizing article 9/10...\n",
      "Summarizing article 10/10...\n"
     ]
    }
   ],
   "source": [
    "def get_all_news_articles_individually():\n",
    "\n",
    "    news_path = os.path.join(DATA_DIR, \"news.json\")\n",
    "\n",
    "    with open(news_path, \"r\") as f:\n",
    "        news_json = json.load(f)\n",
    "\n",
    "    # Create a list of formatted articles\n",
    "    formatted_articles = [\n",
    "        textwrap.dedent(\n",
    "            f\"Article {i + 1}:\\n\"\n",
    "            f\"Title: {article['title']}\\n\"\n",
    "            f\"Date: {article['date']}\\n\"\n",
    "            f\"Content:\\n{article['content']}\"\n",
    "        )\n",
    "        for i, article in enumerate(news_json)\n",
    "    ]\n",
    "\n",
    "    return formatted_articles\n",
    "\n",
    "def summarize_each_news_article_one_by_one():\n",
    "    news_path = os.path.join(DATA_DIR, \"news.json\")\n",
    "\n",
    "    with open(news_path, \"r\") as f:\n",
    "        news_json = json.load(f)\n",
    "\n",
    "    # System prompt\n",
    "    summarise_news_system_prompt = (\n",
    "        \"You are a professional financial news summarizer.\\n\"\n",
    "        \"Given a news article about Tesla, produce a standalone summary that:\\n\"\n",
    "        \"- Is approximately 100–150 words long.\\n\"\n",
    "        \"- Clearly identifies the main event or announcement.\\n\"\n",
    "        \"- Highlights any financial, strategic, or regulatory implications.\\n\"\n",
    "        \"- Remains neutral and grounded in the content provided.\\n\"\n",
    "        \"Do not invent or assume any details beyond what's in the article.\"\n",
    "        \"You must respond in English!\"\n",
    "    )\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    for i, article in enumerate(news_json):\n",
    "        article_text = textwrap.dedent(f\"\"\"\n",
    "        Title: {article['title']}\n",
    "        Date: {article['date']}\n",
    "        Content:\n",
    "        {article['content']}\n",
    "        \"\"\")\n",
    "\n",
    "        user_prompt = f\"Summarize the following article:\\n\\n{article_text}\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": summarise_news_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "\n",
    "        print(f\"Summarizing article {i + 1}/{len(news_json)}...\")\n",
    "        response = pipe(messages, **generation_args)\n",
    "        summaries.append(response[0][\"generated_text\"])\n",
    "\n",
    "    return summaries\n",
    "\n",
    "news_summaries = summarize_each_news_article_one_by_one()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "675ad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comprehensive_news_summary(news_summaries):\n",
    "  comprehensive_news_summary = []\n",
    "  for idx, summary in enumerate(news_summaries):\n",
    "    comprehensive_news_summary.append(f\"Article {idx + 1}: {(trim_reasoning(summary))}\")\n",
    "    comprehensive_news_summary.append(\"\\n\")\n",
    "  return \"\\n\".join(comprehensive_news_summary)\n",
    "\n",
    "comprehensive_news_summary =get_comprehensive_news_summary(news_summaries)\n",
    "#display(Markdown(comprehensive_news_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b346e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Analysis of Tesla News Events and Strategic Outlook\n",
       "\n",
       "#### Key Events and Their Impact\n",
       "\n",
       "1. **Fourth-Qtr Earnings Update (Article 1):**\n",
       "   - **Event:** Tesla reported mixed fourth-quarter results, with operating margins and revenue declining significantly. Despite this, the company saw strong demand for its energy storage products and regulatory credits, contributing to both revenue growth and improved margins.\n",
       "   - **Impact:** This highlighted Tesla's ability to leverage its energy storage solutions and regulatory credits to drive growth, even in challenging economic conditions. It also underscored the importance of customer trust and brand reputation in maintaining market share.\n",
       "   - **Business Area:** Automotive (Energy Storage Products)\n",
       "\n",
       "2. **Recalls and Pricing Strategy (Articles 3 & 6):**\n",
       "   - **Event:** Tesla faced recalls in China and the US, primarily due to safety concerns related to driver-assistance features. In Canada, the Model 3 was recalled, raising prices by up to $9,000 CAD.\n",
       "   - **Impact:** These recalls highlighted Tesla's sensitivity to safety risks and the difficulty of securing global supply chains. The pricing strategy reflected Tesla's commitment to maintaining consumer trust and protecting its brand image.\n",
       "   - **Business Area:** Energy (Driver-Assistance Features)\n",
       "\n",
       "3. **Global Competition and Supply Chain Risks (Article 4):**\n",
       "   - **Event:** Tesla's auto sector face challenges from weaker demand and intense competition, particularly in China. While Tesla's recent partnerships with DeepSeek and intentions to release a new Model Y suggest resilience, the automotive industry's competitive landscape remains unstable.\n",
       "   - **Impact:** This highlighted Tesla's vulnerability to global supply chain disruptions and the importance of domestic dependencies in maintaining market leadership.\n",
       "   - **Business Area:** Automotive (Global Competition)\n",
       "\n",
       "4. **Strategic Commitments (Article 7):**\n",
       "   - **Event:** Tesla announced a 2025 return to growth, including the delivery of Full Self-Driving (FSD) technology and plans to launch the Model 3 in Europe and China.\n",
       "   - **Impact:** This strategic commitment reflects Tesla's long-term vision for diversification into autonomous driving and advanced technologies, positioning it as a leader in sustainable and innovative industries.\n",
       "   - **Business Area:** Robotics/AI (Full Self-Driving Technology)\n",
       "\n",
       "5. **Market Sentiment and Tariffs (Articles 5 & 9):**\n",
       "   - **Event:** President Trump's tariffs on China and Mexico's import of Tesla vehicles, plus a 25% U.S. tariff on global car production, impacted Tesla's profitability and stock performance.\n",
       "   - **Impact:** These tariffs created a competitive environment, forcing Tesla to adjust pricing strategies and navigate complex market dynamics. The current state of U.S. tariffs adds to the broader economic context of trade tensions.\n",
       "   - **Business Area:** Global (Tariff Impact)\n",
       "\n",
       "#### Conclusion\n",
       "\n",
       "Tesla's news events reflect a blend of innovation, diversification, and strategic planning, positioned as a leader in sustainable and autonomous technologies. The company's ability to adapt to changing market conditions, including global supply chain risks and regulatory changes, demonstrates resilience. The strategic commitment to return to growth in 2025 aligns with Tesla's long-term vision, aiming to become a dominant player in the automotive industry. While the current tariffs pose a challenge, Tesla's focus on innovation and diversification positions it for continued success in navigating the evolving global economy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_analysis_user_prompt_template = f\"\"\"\n",
    "You are given a summary of key news events related to Tesla over a recent period.\n",
    "\n",
    "**Question:**  \n",
    "Which key news events influenced Tesla’s stock performance, and what insights do they offer?\n",
    "\n",
    "**News Summary:**  \n",
    "{comprehensive_news_summary}\n",
    "\n",
    "**Please:**\n",
    "- Identify the most impactful events and explain why they mattered.\n",
    "- Highlight whether the impact was positive or negative, and on which part of Tesla’s business (e.g., automotive, energy, robotics, AI, international).\n",
    "- Connect events to possible market sentiment (e.g., uncertainty, optimism, risk).\n",
    "- End with a concise **Conclusion** about the overall narrative and strategic outlook based on this news.\n",
    "- You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": news_analysis_user_prompt_template},\n",
    "]\n",
    "\n",
    "question6Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question6Answer[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a568fa",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 6\n",
    "\n",
    "As a team, we felt the response did a good job overall in structuring the analysis around key themes like earnings, tariffs, product recalls, and strategic commitments. Breaking down the news into categories helped make the insights easier to follow, and we appreciated that each event included a potential impact on Tesla’s stock or operations.\n",
    "\n",
    "That said, we noticed a few areas for improvement. First, Article 2 about Tesla and BMW suing the EU wasn’t included in the summary, even though it’s relevant to Tesla’s global operations and regulatory risks. We also felt that while the analysis mentions investor sentiment and resilience, it could have more clearly connected specific news events to actual stock movement. For example, how much the stock rose or fell after a specific announcement would have added more depth.\n",
    "\n",
    "Well-organized and insightful overall, but the response could be strengthened by ensuring all articles are covered, all claims are grounded in the data, and that cause-effect relationships are more explicitly shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3cb55a",
   "metadata": {},
   "source": [
    "## LLM responses to the Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9ee1df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_answers = {\n",
    "    \"Question 1 \": question1Answer[0][\"generated_text\"],\n",
    "    \"Question 2 \": \"\",\n",
    "    \"Question 3 \": question3Answer[0][\"generated_text\"],\n",
    "    \"Question 4 \": \" \",\n",
    "    \"Question 5 \": \" \",\n",
    "    \"Question 6 \":  question6Answer[0]['generated_text'],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
