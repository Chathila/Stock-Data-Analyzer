{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e030378",
   "metadata": {},
   "source": [
    "# Data Analysis and Q&A Project Using a Local LLM\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project requires you to perform a comprehensive analysis of a company's stock data using only the provided data sources and a local LLM. Your analysis should answer the following six questions strictly based on the supplied data and documents—no external data is allowed. All generated answers must be firmly based on the provided data, without any fabricated content. In addition, your logic must be clear, and any attribution of events must be causally linked.\n",
    "\n",
    "---\n",
    "\n",
    "## Provided Data\n",
    "\n",
    "You will be provided with the following data sets:\n",
    "\n",
    "#### Stock Price Data (Json format)\n",
    "* Timeframe: Jan 22 to Feb 5\n",
    "* Fields: Open, High, Low, Close, Volume\n",
    "\n",
    "#### Quarterly Earnings Data for the Past Year (Json format)\n",
    "* Contains key financial indicators (e.g., revenue, eps) for each quarter.\n",
    "\n",
    "#### Full Earnings Transcript Call\n",
    "* The complete transcript of the earnings call, including management discussions and Q&A.\n",
    "\n",
    "#### Balance Sheet Data for the Past Year (Json format)\n",
    "* Includes assets, liabilities, and shareholders' equity information.\n",
    "\n",
    "#### News Articles\n",
    "* Full text of 10 news articles related to the company during the analysis period.\n",
    "\n",
    "---\n",
    "\n",
    "## Questions\n",
    "Using the provided data and a local LLM, you need to answer the following six questions:\n",
    "\n",
    "1. What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "2. Why did the price increase on Jan 30? Please provide potential factors.\n",
    "\n",
    "3. Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "4. With unsupervised Full Self Driving scheduled to launch in limited markets like Austin by June, what regulatory challenges does Tesla foresee for a nationwide or international rollout, and how is the company strategically preparing to address these hurdles?\n",
    "\n",
    "5. What insights can be concluded from the earnings call?\n",
    "\n",
    "6. Which key news events influenced the stock performance, and what insights do they offer?\n",
    "\n",
    "---\n",
    "\n",
    "## Project Requirements\n",
    "#### Data Source Restriction:\n",
    "- Only use the provided data and documents. No external data or information is allowed.\n",
    "\n",
    "#### Answer Generation:\n",
    "- All generated answers must strictly be based on the provided data and documents. The LLM should not \"invent\" information.\n",
    "\n",
    "#### Clear Logic and Causal Relationships:\n",
    "- For each question, your answers must clearly demonstrate logical reasoning, and any attribution of cause must be explicitly linked to events in the data.\n",
    "\n",
    "#### Prompt Design:\n",
    "- You must design your own prompts for calling the local LLM to ensure that the responses are generated strictly based on the analysis results.\n",
    "\n",
    "#### Result Evaluation:\n",
    "- After generating the answers, implement an evaluation step to assess whether the responses meet the above requirements in terms of data reliance, logical clarity, and correct causation.\n",
    "\n",
    "#### Please put the answers to these 6 questions in a dict at the end of your submitted Python nodebook file.\n",
    "\n",
    "For example\n",
    "```code\n",
    "{ \"Q1 answer\": \"Answer1\", \"Q2 answer\": \"Answer2\", \"Q3 answer\": \"Answer3\", \"Q4 answer4\": \"Answer4\", \"Q5 answer\": \"Answer5\", \"Q6 answer\": \"Answer6\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3ba393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/spear1/.local/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in /home/spear1/.local/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (1.3.5)\n",
      "Requirement already satisfied: ipython in /home/spear1/.local/lib/python3.10/site-packages (8.35.0)\n",
      "Requirement already satisfied: filelock in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/spear1/.local/lib/python3.10/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from ipython) (4.4.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython) (4.8.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/lib/python3/dist-packages (from ipython) (2.11.2)\n",
      "Requirement already satisfied: stack_data in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/spear1/.local/lib/python3.10/site-packages (from ipython) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/spear1/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/spear1/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in /home/spear1/.local/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/spear1/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/spear1/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/spear1/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/spear1/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/spear1/.local/lib/python3.10/site-packages (from stack_data->ipython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/spear1/.local/lib/python3.10/site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/spear1/.local/lib/python3.10/site-packages (from stack_data->ipython) (0.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers accelerate pandas ipython\n",
    "# %pip install torch # Install PyTorch if you dont have it downloading \n",
    "\n",
    "DATA_DIR = \"447_dataset\"\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "import datetime\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290d56f",
   "metadata": {},
   "source": [
    "## Loading and Running the Local LLM\n",
    "\n",
    "1. **Imports Transformers utilities**  \n",
    "   - `AutoModelForCausalLM`: generic class for loading any GPT‑style model  \n",
    "   - `AutoTokenizer`: matching tokenizer for converting text ↔ tokens  \n",
    "   - `pipeline`: high‑level helper that ties model + tokenizer into one callable  \n",
    "\n",
    "2. **Specifies the model repository**  \n",
    "   ```python\n",
    "   model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d52b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# The pipeline will automatically use the model and tokenizer you just loaded\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) # Load the tokenizer\n",
    "\n",
    " # Create a pipeline for text generation\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 2000, # Limit the number of tokens generated\n",
    "    \"return_full_text\": False, # Return only the generated text\n",
    "    \"do_sample\": True, # Use sampling to generate text\n",
    "    \"temperature\": 0.1,# Control the randomness of the output\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"top_p\": 0.9, # Control the diversity of the output\n",
    "    \"top_k\": 50, # Control the diversity of the output\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "699af2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_system_prompt = ( \n",
    "    \"You are an expert financial data analyst LLM.\\n\"\n",
    "    \"You must ensure the following rules are followed:\\n\"\n",
    "    \"1. Use only the data summaries provided in the prompt.\\n\"\n",
    "    \"2. Show clear step-by-step reasoning, linking each claim directly to the data.\\n\"\n",
    "    \"3. Ensure all explanations are clear, logical, and accurate.\\n\"\n",
    "    \"4. Do not invent or hallucinate any information.\\n\"\n",
    "    \"After your answer, provide a checklist summary indicating whether each criterion is satisfied. \"\n",
    "    \"If any criterion is not met, include a brief explanation.\"\n",
    ")\n",
    "\n",
    "\n",
    "def trim_reasoning(raw):\n",
    "    tag = \"</think>\"\n",
    "    idx = raw.find(tag)\n",
    "\n",
    "    if idx != -1:\n",
    "        answer = raw[idx + len(tag):].strip()\n",
    "    else:\n",
    "        answer = raw.strip()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b8eac",
   "metadata": {},
   "source": [
    "## Evaluation of the LLM response using the LLM as an evaluator\n",
    "\n",
    "The bellow code cell will show how we built our function to evaluate the LLM response based on the following parameters:\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26c2a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_system_prompt = (\n",
    "    \"You are a critical and strict reviewer tasked with evaluating financial-analysis answers. \"\n",
    "    \"Your job is to verify that the answer:\\n\"\n",
    "    \"1. Uses *only* the provided data (no outside info).\\n\"\n",
    "    \"2. Clearly explains its logic and reasoning.\\n\"\n",
    "    \"3. Attributes any cause-effect relationships directly to the data.\\n\"\n",
    "    \"4. Avoids speculation or made-up facts.\\n\"\n",
    "    \"Respond with a simple Yes/No checklist for each point, then a brief explanation of any failures.\"\n",
    ")\n",
    "\n",
    "evaluation_system_prompt_extra = (\"YOU MUST JUST EVALUATE THE ANSWER GIVEN BY THE LLM!\")\n",
    "\n",
    "\n",
    "evaluation_user_prompt_template = \"\"\"\n",
    "   Here’s what you need to evaluate:\n",
    "\n",
    "    **Question:**  \n",
    "    {question}\n",
    "\n",
    "    **Data Provided:**  \n",
    "    {data_snippet}\n",
    "\n",
    "    **LLM’s Answer:**  \n",
    "    {llm_answer}\n",
    "\n",
    "    Please produce:\n",
    "    \n",
    "    1. A four-item checklist, each with “Yes” or “No” next to:\n",
    "    - “Only uses provided data”\n",
    "    - “Clear logic & reasoning”\n",
    "    - “All causes linked to data”\n",
    "    - “No speculation or made-up facts”\n",
    "\n",
    "    2. For any “No” items, a one-sentence explanation of the issue.\n",
    "        \"\"\"\n",
    "def evaluate_response(generated_answer, data, question):\n",
    "    evaluation_prompt = evaluation_user_prompt_template.format(\n",
    "        question= question,\n",
    "        data_snippet=\"\\n\\n\".join(data),  # or a trimmed version of summaries\n",
    "        llm_answer=generated_answer\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": evaluation_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "    ]\n",
    "\n",
    "    evaluation_result = pipe(messages, **generation_args)\n",
    "    display(Markdown(trim_reasoning(evaluation_result[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1d4bb",
   "metadata": {},
   "source": [
    "### Question 1:What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "#### Prompt construction\n",
    "\n",
    "* Here we need to monitor the performance of the tesla stock over the specified days. To monitor the performance of the stock the LLM just need to understand the how the pricing of the stock was through the given period hence why the LLM will need to see the infomation in the `prices.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55617ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\"\"\"   \n",
    "This Function extracts the price information and converts the informations\n",
    "into a simple readable format to be included in the prompt to the LLM\n",
    "\"\"\"\n",
    "def get_prices_summary():\n",
    "    prices_path = os.path.join(DATA_DIR, \"prices.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(prices_path, \"r\") as f:\n",
    "        prices = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and index\n",
    "    prices[\"Date\"] = pd.to_datetime(prices[\"Date\"])\n",
    "    prices = prices.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build a human-readable summary for each day\n",
    "    daily_summaries = []\n",
    "    for date, row in prices.iterrows():\n",
    "        daily_summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Open ${row['Open']:.2f}, \"\n",
    "            f\"High ${row['Hight']:.2f}, \"\n",
    "            f\"Low ${row['Low']:.2f}, \"\n",
    "            f\"Close ${row['Close']:.2f}, \"\n",
    "            f\"Volume {int(row['Volume']):,}\"\n",
    "        )\n",
    "\n",
    "    # Join them into one block of text\n",
    "    daily_summary_text = \"\\n\".join(daily_summaries)\n",
    "    return daily_summary_text\n",
    "\n",
    "\n",
    "#print(get_prices_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e33e7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Summary of Tesla Stock Performance (Jan 22 - Feb 5)\n",
       "\n",
       "---\n",
       "\n",
       "#### **Introduction**\n",
       "This analysis provides a concise overview of Tesla (TSLA) stock performance from Monday, January 22nd, to Friday, February 5th, 2025. The data spans approximately 14 days, covering daily open/close prices, volume, and percentage changes. The goal is to evaluate Tesla's stock performance during this period, focusing on key trends and movements.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Analysis**\n",
       "\n",
       "| Date       | Open Price | High Price | Low Price | Close Price | Volume | % Change (Open-to-Close) | % Change (High-to-Low) | % Change (Low-to-Close) |\n",
       "|------------|-------------|------------|-----------|-------------|-------|------------------------|--------------------|-------------------------|\n",
       "| **2025-01-22** | $416.81     | $428.00    | $414.59   | $415.11      | 60,963 | -0.2%                 | -0.3%               | -0.6%                   |\n",
       "| **2025-01-23** | $416.06     | $420.73    | $408.95   | $412.38      | 50,690 | +0.1%                 | -0.1%               | -0.1%                   |\n",
       "| **2025-01-24** | $414.45     | $418.88    | $405.78   | $406.58      | 56,427 | +0.2%                 | -0.3%               | -0.2%                   |\n",
       "| **2025-01-27** | $394.80     | $406.69    | $389.00   | $397.15      | 58,125 | -0.5%                 | +0.4%               | -0.1%                   |\n",
       "| **2025-01-28** | $396.91     | $400.59    | $386.50   | $398.09      | 48,910 | +0.1%                 | -0.1%               | -0.0%                   |\n",
       "| **2025-01-29** | $395.21     | $398.59    | $384.48   | $389.10      | 68,033 | -0.3%                 | +0.2%               | -0.2%                   |\n",
       "| **2025-01-30** | $410.78     | $412.50    | $384.41   | $400.28      | 98,092 | -0.1%                 | +0.2%               | -0.0%                   |\n",
       "| **2025-01-31** | $401.53     | $419.99    | $401.34   | $404.60      | 83,568 | -0.1%                 | +0.4%               | -0.1%                   |\n",
       "\n",
       "---\n",
       "\n",
       "#### **Causal Insights**\n",
       "1. **Price Fluctuations**: The stock experienced significant fluctuations throughout the period, with increases and decreases driven by market sentiment, company earnings, and macroeconomic factors.\n",
       "2. **Volume Analysis**: The volume numbers varied significantly, with higher trading activity on certain days, potentially reflecting investor interest or corporate earnings.\n",
       "3. **Market Sentiment**: There was evidence of both bullish and bearish sentiment, particularly evident on the 23rd and 24th days, where the stock opened higher despite ending lower.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Conclusion**\n",
       "Over the period from January 22nd to February 5th, 2025, Tesla stock exhibited both upward and downward movements. While the stock saw some resilience, it also faced challenges that contributed to its overall decline. The combination of short-term gains and sustained losses suggests that Tesla's stock performance during this period was influenced by a mix of market conditions and company-specific factors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_prompt_template_q1 =( \"\"\"\n",
    "    Here is the summarized Tesla data for Jan 22 - Feb 5:\n",
    "    {price_info}\n",
    "\n",
    "    **Question:**  \n",
    "    What was the performance of Tesla stock over this period?\n",
    "                          \n",
    "    **Please:**\n",
    "    - Write a brief **Introduction** stating the question and data scope.  \n",
    "    - In your **Analysis**, cite the exact figures (dates, prices, percent changes, volumes).  \n",
    "    - Draw any causal insights clearly (e.g., “the drop on Feb 1 may be linked to…”).  \n",
    "    - Finish with a concise **Conclusion** summarizing overall performance.\n",
    "    - You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\")\n",
    "\n",
    "# Fill in the template with specific data\n",
    "filled_user_prompt = user_prompt_template_q1.format(\n",
    "    price_info = get_prices_summary()\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": filled_user_prompt},\n",
    "]\n",
    "\n",
    "question1Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question1Answer[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee8adcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Evaluation Checklist\n",
       "\n",
       "1. **Does the answer use only the provided data?**\n",
       "   - **Yes**  \n",
       "     The answer includes all relevant data points such as open, high, low, close, and volume for each trading day within the specified period. No additional or external data is used.\n",
       "\n",
       "2. **Is the logic explained clearly?**\n",
       "   - **Yes**  \n",
       "     The answer demonstrates a logical flow by explaining how each metric influences the next. For example, it connects the percentage change from open to close with the subsequent day's performance, showing a clear cause-effect relationship.\n",
       "\n",
       "3. **Are cause-effect relationships directly attributed to the data?**\n",
       "   - **Yes**  \n",
       "     Each movement in the stock price is explained based on the provided data. For instance, the stock increasing after a positive open-price move is attributed to the data itself, without speculation.\n",
       "\n",
       "4. **Avoids speculation or made-up facts?**\n",
       "   - **Yes**  \n",
       "     The answer does not include any hypothetical scenarios or assumptions. All claims are grounded in the provided data, ensuring factual accuracy.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The provided financial analysis accurately uses only the given data, explains the logic clearly, attributes cause-effect relationships directly to the data, and avoids speculation or made-up facts. Therefore, it meets all the specified criteria."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating the response for Question 1 using the LLM\n",
    "question_1 = \"What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\"\n",
    "price_summary = get_prices_summary()\n",
    "evaluate_response(trim_reasoning(question1Answer[0]['generated_text']), price_summary, question_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc95b2",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 1\n",
    "\n",
    "Based on the ouptut, the model did a good job at summarizing the prices, neatly organziing everything into a table. The answer used the relevant data an provided the market movent details as well. It was able to notice key trends and link peices of data togehter such as arket movement and the volumes. The answer additonally did not include any hypothetical scenarios and assumptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb7491",
   "metadata": {},
   "source": [
    "# Question 2 \n",
    "### Why did the price increase on Jan 30? Please provide potential factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc284196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "system_prompt_ts = (\n",
    "    \"\"\"\n",
    "    You are an expert financial analysis assistant.  \n",
    "    Always respond in clear, concise English.  \n",
    "    Use only the information explicitly provided in the user’s inputs.  \n",
    "    Do not invent, fetch, or reference any external data.  \n",
    "    Produce only bullet points—no prose.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "user_prompt_ts = (\n",
    "    \"\"\"\n",
    "Please summarize the following earnings‑call excerpt into 3–4 bullet points,\n",
    "focusing on key financial metrics, guidance, or other actionable insights.\n",
    "Do not add commentary or restate the question—just the bullets.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "with open(\"447_dataset/earning_transcript.md\", \"r\") as f:\n",
    "    earnings_transcript_data = f.read()\n",
    "\n",
    "lines = earnings_transcript_data.splitlines()\n",
    "\n",
    "chunks = []\n",
    "current_chunk = []\n",
    "max_lines_per_chunk = 50\n",
    "\n",
    "for line in lines:\n",
    "    current_chunk.append(line)\n",
    "    if len(current_chunk) >= max_lines_per_chunk:\n",
    "        chunk_text = \"\\n\".join(current_chunk)\n",
    "        chunks.append(chunk_text)\n",
    "        current_chunk = []\n",
    "\n",
    "if current_chunk:\n",
    "    chunk_text = \"\\n\".join(current_chunk)\n",
    "    chunks.append(chunk_text)\n",
    "\n",
    "transcript_summary = []\n",
    "\n",
    "def clean_summary(raw):\n",
    "    s = re.sub(r\"<think>.*?</think>\", \"\", raw, flags=re.S)\n",
    "    s = re.sub(r\"(?m)^(Thought:|Thinking:?).*\\n?\", \"\", s)\n",
    "    m = re.search(r\"(?m)^[-•]\\s+\", s)\n",
    "    if m:\n",
    "        return s[m.start():].strip()\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "for i in range(len(chunks)):\n",
    "    filled_user_ts = user_prompt_ts.format(earnings_transcript=chunks[i])\n",
    "    messages_ts = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt_ts},\n",
    "        {\"role\": \"user\",   \"content\": filled_user_ts},\n",
    "    ] \n",
    "    out = pipe(messages_ts, **generation_args)\n",
    "    raw = out[0][\"generated_text\"]\n",
    "    summary = clean_summary(raw)\n",
    "    transcript_summary.append(summary)\n",
    "\n",
    "full_transcript_summary = \"\\n\\n\".join(transcript_summary)\n",
    "\n",
    "print(full_transcript_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d085a8",
   "metadata": {},
   "source": [
    "### Extract News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e0243",
   "metadata": {},
   "source": [
    "### Extract Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "with open(\"447_dataset/news.json\", \"r\") as f:\n",
    "    all_news = json.load(f)\n",
    "\n",
    "def parse_date(s: str) -> datetime.date:\n",
    "    return datetime.strptime(s.strip(), \"%B %d, %Y\").date()\n",
    "\n",
    "\n",
    "\n",
    "# define your window\n",
    "start = datetime(2025, 1, 25).date()\n",
    "end   = datetime(2025, 1,  30).date()\n",
    "\n",
    "news_window = [\n",
    "    article\n",
    "    for article in all_news\n",
    "    if start <= parse_date(article[\"date\"]) <= end\n",
    "]\n",
    "\n",
    "print(f\"Found {len(news_window)} articles between {start} and {end}:\")\n",
    "for a in news_window:\n",
    "    print(f\"- {a['date']}: {a['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load all earnings entries\n",
    "with open(\"447_dataset/earning.json\", \"r\") as f:\n",
    "    earnings = json.load(f)\n",
    "\n",
    "# print the extracted data\n",
    "earnings = json.dumps(earnings, indent=2, ensure_ascii=False)\n",
    "print(earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76450e06",
   "metadata": {},
   "source": [
    "### Relavant Price Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def load_prices(path: str):\n",
    "    \"\"\"Load the full list of price bars from a JSON file.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def filter_by_date(prices, start_date: str, end_date: str):\n",
    "    \"\"\"\n",
    "    Return only those price entries whose 'Date' field\n",
    "    falls between start_date and end_date, inclusive.\n",
    "    Dates must be in 'YYYY-MM-DD' format.\n",
    "    \"\"\"\n",
    "    start = datetime.fromisoformat(start_date).date()\n",
    "    end   = datetime.fromisoformat(end_date).date()\n",
    "\n",
    "    return [\n",
    "        p for p in prices\n",
    "        if start <= datetime.fromisoformat(p[\"Date\"]).date() <= end\n",
    "    ]\n",
    "\n",
    "\n",
    "    \n",
    "start_date = \"2025-01-20\"\n",
    "end_date   = \"2025-01-30\"\n",
    "\n",
    "prices = load_prices(\"447_dataset/prices.json\")\n",
    "window = filter_by_date(prices, start_date, end_date)\n",
    "\n",
    "relevant_prices = json.dumps(window, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8053d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_q2 = (\"\"\"\n",
    "You are an expert financial analysis assistant.  \n",
    "Use only the information explicitly provided in the user’s inputs.  \n",
    "Do not invent, fetch, or reference any external data.\n",
    "You must suport all answers with evidence and reasoning\n",
    "\"\"\")\n",
    "\n",
    "user_prompt_q2 = \"\"\"\n",
    "Below is all the data—no other sources allowed:\n",
    "\n",
    "You must suport all answers with evidence and reasoning\n",
    "\n",
    "Be verbrose\n",
    "\n",
    "1) Earnings results (earning.json):\n",
    "{earnings_data}\n",
    "\n",
    "2) Stock price summary:\n",
    "{relevant_price_data}\n",
    "\n",
    "3) News articles during the time:\n",
    "{news_data}\n",
    "\n",
    "4) Summary of an earnings talk the prior day:\n",
    "{transcript_data}\n",
    "\n",
    "Question\n",
    "Why did the stock price increase on January 30?\n",
    "List the likely drivers with an explanation, and cite exactly which data (earnings, transcript, news article, or price bar) supports it.\n",
    "\"\"\"\n",
    "\n",
    "filled_user_q2 = user_prompt_q2.format(earnings_data = earnings, relevant_price_data = relevant_prices, news_data = news_window, transcript_data = full_transcript_summary)\n",
    "\n",
    "messages_q2 = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt_q2},\n",
    "        {\"role\": \"user\",   \"content\": filled_user_q2},\n",
    "    ] \n",
    "\n",
    "\n",
    "\n",
    "output_q2 = pipe(messages_q2, **generation_args)\n",
    "print(output_q2[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6428e1",
   "metadata": {},
   "source": [
    "### Question 3:Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "#### Data Used for Prompt construction\n",
    "\n",
    "* For the LLM to have any insight of quaterly financial information, I will provide it the `balancesheet.json` as this file contains the quaterly financial figures. We will use this data so the LLM is a aware of the performance of the previous 1-2 years. This gives the LLM a base to compare against the current financial quater( 2025 Q1). Since the balance sheet has a lot of infomation, we dont want to overload the LLM with too many features to consider when it comes up with its decison so we will handpick some important features from the balance sheet from each quater.\n",
    "\n",
    "\n",
    "* The Data found in the `earnings.json` also contains relavant financial information for the past five quaters, which the LLM can use compare the performance of the company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a75f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earnings_summary():\n",
    "    \"\"\"\n",
    "    Reads earning.json and returns a plain summary with:\n",
    "    - EPS predicted / actual\n",
    "    - Revenue predicted / actual (in billions)\n",
    "    \"\"\"\n",
    "    earnings_path = os.path.join(DATA_DIR, \"earning.json\")\n",
    "\n",
    "    with open(earnings_path, \"r\") as f:\n",
    "        earnings_json = json.load(f)\n",
    "\n",
    "    lines = []\n",
    "    for rec in earnings_json:\n",
    "        dt = rec.get(\"EarningReleaseDate\") or rec.get(\"EarningReportDate\")\n",
    "        if not dt:\n",
    "            continue\n",
    "\n",
    "        date = pd.to_datetime(dt).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        eps_actual   = rec.get(\"EpsActual\", 0)\n",
    "        eps_forecast = rec.get(\"EpsForecast\", 0)\n",
    "        eps_surprise   = rec.get(\"EpsSurprise\", 0)\n",
    "\n",
    "        rev_actual   = rec.get(\"RevenueActual\", 0) / 1e9\n",
    "        rev_forecast = rec.get(\"RevenueForecast\", 0) / 1e9\n",
    "\n",
    "        line = (\n",
    "            f\"{date}: \"\n",
    "            f\"EPS predicted: {eps_forecast:.2f}, EPS actual: {eps_actual:.2f}, EPS surprise: {eps_surprise:.2f}; \"\n",
    "            f\"Revenue predicted: ${rev_forecast:.2f}B, Revenue actual: ${rev_actual:.2f}B\"\n",
    "        )\n",
    "        lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def get_balance_sheet_summary():\n",
    "    \"\"\"\n",
    "    This function extracts financial statement information from balencesheet.json\n",
    "    and returns a readable summary line for each quarter.\n",
    "    \"\"\"\n",
    "    bs_path = os.path.join(DATA_DIR, \"balencesheet.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(bs_path, \"r\") as f:\n",
    "        balance_sheet = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and sort\n",
    "    balance_sheet[\"Date\"] = pd.to_datetime(balance_sheet[\"Date\"])\n",
    "    balance_sheet = balance_sheet.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build human-readable lines\n",
    "    summaries = []\n",
    "    for date, row in balance_sheet.iterrows():\n",
    "        rev       = row.get(\"Total Revenue\", 0) / 1e6\n",
    "        gp        = row.get(\"Gross Profit\", 0) / 1e6\n",
    "        op_inc    = row.get(\"Operating Income\", 0) / 1e6\n",
    "        net_inc   = row.get(\"Net Income Common Stockholders\", 0) / 1e6\n",
    "        ebitda    = row.get(\"EBITDA\", 0) / 1e6\n",
    "        tot_exp   = row.get(\"Total Expenses\", 0) / 1e6\n",
    "\n",
    "        # Calculate margins and ratios safely\n",
    "        gross_margin   = gp / rev * 100 if rev else 0\n",
    "        op_margin      = op_inc / rev * 100 if rev else 0\n",
    "        net_margin     = net_inc / rev * 100 if rev else 0\n",
    "\n",
    "        summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Revenue ${rev:.1f}M, Gross Profit ${gp:.1f}M ({gross_margin:.1f}%), \"\n",
    "            f\"Operational Income ${op_inc:.1f}M ({op_margin:.1f}%), Net Income ${net_inc:.1f}M ({net_margin:.1f}%), \"\n",
    "            f\"EBITDA ${ebitda:.1f}M, Total Expenses ${tot_exp:.1f}M, \"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(summaries)\n",
    "\n",
    "print(\"----------Balance Sheet Summary----------\")\n",
    "print(get_balance_sheet_summary())\n",
    "print(\"\\n-----------Earnings Summary---------------\")\n",
    "print(get_earnings_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4695ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "question3_user_prompt = f\"\"\"\n",
    "Here are your two data summaries:\n",
    "\n",
    "**Balance Sheet Summary** \n",
    "- Balance sheet summary containing the quaterly financial information for the previous quaters \n",
    "{get_balance_sheet_summary()}\n",
    "\n",
    "\n",
    "**Earnings Summary**  \n",
    "- Earnings summary containing the quaterly earnings information for the previous quaters and the current quater(2025 Q1)\n",
    "{get_earnings_summary()}\n",
    "\n",
    "**Question:**  \n",
    "Compared with previous quarters, how is the performance of this quarter (ending 2025‑01‑29)?\n",
    "\n",
    "**Please:**  \n",
    "- Write a brief **Introduction** stating the question and data scope.  \n",
    "- In your **Analysis**, compare each metric (Revenue, Gross Profit, Operational Income, Net Income, EBITDA, EPS and Revenue surprises) quarter‑over‑quarter, citing the exact figures.  \n",
    "- Highlight any notable trends (e.g., margin expansions or EPS misses).  \n",
    "- Finish with a concise **Conclusion** summarizing whether performance improved or deteriorated and why.\n",
    "- You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\",   \"content\": question3_user_prompt},\n",
    "]\n",
    "\n",
    "question3Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question3Answer[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the response for question 3 using the LLM\n",
    "\n",
    "question_3 = \"Compared with previous quarters, how is the performance of this quarter (ending 2025‑01‑29)?\"\n",
    "data_q3 = \"\\n\".join([\n",
    "    \"----------Balance Sheet Summary----------\", \n",
    "    get_balance_sheet_summary(), \n",
    "    \"\\n-----------Earnings Summary---------------\", \n",
    "    get_earnings_summary()\n",
    "])\n",
    "\n",
    "evaluate_response(trim_reasoning(question3Answer[0]['generated_text']), data_q3, question_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a3abe",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 3\n",
    "\n",
    "The structure of the response is clear and well-organized, breaking down each metric effectively. However, it compares the wrong quarters — claiming a year-over-year comparison with 2024-01 but actually pulling numbers from 2024-12. Several values are also inaccurate: for example, revenue wasn’t flat, it increased slightly (~2%), and operating income was misreported. The revenue surprise was also miscalculated (off by several percentage points).The tone is professional, and the format works well. The model seems to struggle a bit with showing relationship to the data but it was abale to structure a decent answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707608a",
   "metadata": {},
   "source": [
    "# DO QUESTION 4 INDUWARA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9430b",
   "metadata": {},
   "source": [
    "### Question 5:What insights can be concluded from the earnings call?\n",
    "\n",
    "#### Data Used for Prompt construction\n",
    "\n",
    "* To gain insights from the earnings call, we used the transcript available in the `earning_transcript.md` file. Since the full transcript is quite lengthy, our strategy was to break it into smaller sections and summarize each section individually using the LLM. By combining these individual summaries, we created a comprehensive overview of the entire earnings call. For the final prompt, we provided the LLM with this summarized version of the transcript and asked it to identify the key insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get function from indy to summarise the earnings call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_template_q5 = f\"\"\"\n",
    "\"Note: In this response, please pay particular attention to executive tone, guidance, and strategic priorities.\\n\\n\"\n",
    "Here is the summarized earnings call transcript:\n",
    "{full_transcript_summary}\n",
    "\n",
    "Question:\n",
    "What key insights can be concluded from the Tesla earnings call?\n",
    "\n",
    "Please:\n",
    "- Start with a **Overview** of the call’s focus.\n",
    "- Identify the **Key Themes** or concerns mentioned and briefly explain then with context from the call(e.g., demand, margin pressure, product roadmap).\n",
    "- Highlight any **management tone or forward-looking statements**.\n",
    "- Try to identify any statements about future goals of the company.\n",
    "- Finish with a concise **Conclusion** that summarizes the strategic outlook or market signal from the call.\n",
    "- You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt_template_q5},\n",
    "]\n",
    "\n",
    "question5Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question5Answer[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the response for question 5 using the LLM\n",
    "\n",
    "question_5 = \"What key insights can be concluded from the Tesla earnings call?\"\n",
    "evaluate_response(trim_reasoning(question5Answer[0]['generated_text']), full_transcript_summary, question_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc18829",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 5\n",
    "\n",
    "# INDY HAS TO FINIsh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17271034",
   "metadata": {},
   "source": [
    "### Question 6:Which key news events influenced the stock performance, and what insights do they offer?\n",
    "\n",
    "#### Prompt construction\n",
    "\n",
    "* To analyse what news events affected the stock perferomance we will take a look at the news articles found in `news.json`. This file has new events but it seems to be large sections of text which might be hard to include in the prompt for the LLM. We will use a similar strategy to extract the most important infomation out of the news articles. We will split the news articles into batches of 3 and then ask the LLM to summarise the key information. Then we will combined these summaries to create a comprehensive summary that will be included in the final prompt to the LLM, where it will use the summary to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_news_articles_individually():\n",
    "\n",
    "    news_path = os.path.join(DATA_DIR, \"news.json\")\n",
    "\n",
    "    with open(news_path, \"r\") as f:\n",
    "        news_json = json.load(f)\n",
    "\n",
    "    # Create a list of formatted articles\n",
    "    formatted_articles = [\n",
    "        textwrap.dedent(\n",
    "            f\"Article {i + 1}:\\n\"\n",
    "            f\"Title: {article['title']}\\n\"\n",
    "            f\"Date: {article['date']}\\n\"\n",
    "            f\"Content:\\n{article['content']}\"\n",
    "        )\n",
    "        for i, article in enumerate(news_json)\n",
    "    ]\n",
    "\n",
    "    return formatted_articles\n",
    "\n",
    "def summarize_each_news_article_one_by_one():\n",
    "    news_path = os.path.join(DATA_DIR, \"news.json\")\n",
    "\n",
    "    with open(news_path, \"r\") as f:\n",
    "        news_json = json.load(f)\n",
    "\n",
    "    # System prompt\n",
    "    summarise_news_system_prompt = (\n",
    "        \"You are a professional financial news summarizer.\\n\"\n",
    "        \"Given a news article about Tesla, produce a standalone summary that:\\n\"\n",
    "        \"- Is approximately 100–150 words long.\\n\"\n",
    "        \"- Clearly identifies the main event or announcement.\\n\"\n",
    "        \"- Highlights any financial, strategic, or regulatory implications.\\n\"\n",
    "        \"- Remains neutral and grounded in the content provided.\\n\"\n",
    "        \"Do not invent or assume any details beyond what's in the article.\"\n",
    "        \"You must respond in English!\"\n",
    "    )\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    for i, article in enumerate(news_json):\n",
    "        article_text = textwrap.dedent(f\"\"\"\n",
    "        Title: {article['title']}\n",
    "        Date: {article['date']}\n",
    "        Content:\n",
    "        {article['content']}\n",
    "        \"\"\")\n",
    "\n",
    "        user_prompt = f\"Summarize the following article:\\n\\n{article_text}\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": summarise_news_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "\n",
    "        print(f\"Summarizing article {i + 1}/{len(news_json)}...\")\n",
    "        response = pipe(messages, **generation_args)\n",
    "        summaries.append(response[0][\"generated_text\"])\n",
    "\n",
    "    return summaries\n",
    "\n",
    "news_summaries = summarize_each_news_article_one_by_one()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comprehensive_news_summary(news_summaries):\n",
    "  comprehensive_news_summary = []\n",
    "  for idx, summary in enumerate(news_summaries):\n",
    "    comprehensive_news_summary.append(f\"Article {idx + 1}: {(trim_reasoning(summary))}\")\n",
    "    comprehensive_news_summary.append(\"\\n\")\n",
    "  return \"\\n\".join(comprehensive_news_summary)\n",
    "\n",
    "comprehensive_news_summary =get_comprehensive_news_summary(news_summaries)\n",
    "#display(Markdown(comprehensive_news_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_analysis_user_prompt_template = f\"\"\"\n",
    "You are given a summary of key news events related to Tesla over a recent period.\n",
    "\n",
    "**Question:**  \n",
    "Which key news events influenced Tesla’s stock performance, and what insights do they offer?\n",
    "\n",
    "**News Summary:**  \n",
    "{comprehensive_news_summary}\n",
    "\n",
    "**Please:**\n",
    "- Identify the most impactful events and explain why they mattered.\n",
    "- Highlight whether the impact was positive or negative, and on which part of Tesla’s business (e.g., automotive, energy, robotics, AI, international).\n",
    "- Connect events to possible market sentiment (e.g., uncertainty, optimism, risk).\n",
    "- End with a concise **Conclusion** about the overall narrative and strategic outlook based on this news.\n",
    "- You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": news_analysis_user_prompt_template},\n",
    "]\n",
    "\n",
    "question6Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question6Answer[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a568fa",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 6\n",
    "\n",
    "As a team, we felt the response did a good job overall in structuring the analysis around key themes like earnings, tariffs, product recalls, and strategic commitments. Breaking down the news into categories helped make the insights easier to follow, and we appreciated that each event included a potential impact on Tesla’s stock or operations.\n",
    "\n",
    "That said, we noticed a few areas for improvement. First, Article 2 about Tesla and BMW suing the EU wasn’t included in the summary, even though it’s relevant to Tesla’s global operations and regulatory risks. We also felt that while the analysis mentions investor sentiment and resilience, it could have more clearly connected specific news events to actual stock movement. For example, how much the stock rose or fell after a specific announcement would have added more depth.\n",
    "\n",
    "Well-organized and insightful overall, but the response could be strengthened by ensuring all articles are covered, all claims are grounded in the data, and that cause-effect relationships are more explicitly shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3cb55a",
   "metadata": {},
   "source": [
    "## LLM responses to the Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_answers = {\n",
    "    \"Question 1 \": question1Answer[0][\"generated_text\"],\n",
    "    \"Question 2 \": \"\",\n",
    "    \"Question 3 \": question3Answer[0][\"generated_text\"],\n",
    "    \"Question 4 \": \" \",\n",
    "    \"Question 5 \": \" \",\n",
    "    \"Question 6 \":  question6Answer[0]['generated_text'],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
