{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e030378",
   "metadata": {},
   "source": [
    "# Data Analysis and Q&A Project Using a Local LLM\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project requires you to perform a comprehensive analysis of a company's stock data using only the provided data sources and a local LLM. Your analysis should answer the following six questions strictly based on the supplied data and documents—no external data is allowed. All generated answers must be firmly based on the provided data, without any fabricated content. In addition, your logic must be clear, and any attribution of events must be causally linked.\n",
    "\n",
    "---\n",
    "\n",
    "## Provided Data\n",
    "\n",
    "You will be provided with the following data sets:\n",
    "\n",
    "#### Stock Price Data (Json format)\n",
    "* Timeframe: Jan 22 to Feb 5\n",
    "* Fields: Open, High, Low, Close, Volume\n",
    "\n",
    "#### Quarterly Earnings Data for the Past Year (Json format)\n",
    "* Contains key financial indicators (e.g., revenue, eps) for each quarter.\n",
    "\n",
    "#### Full Earnings Transcript Call\n",
    "* The complete transcript of the earnings call, including management discussions and Q&A.\n",
    "\n",
    "#### Balance Sheet Data for the Past Year (Json format)\n",
    "* Includes assets, liabilities, and shareholders' equity information.\n",
    "\n",
    "#### News Articles\n",
    "* Full text of 10 news articles related to the company during the analysis period.\n",
    "\n",
    "---\n",
    "\n",
    "## Questions\n",
    "Using the provided data and a local LLM, you need to answer the following six questions:\n",
    "\n",
    "1. What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "2. Why did the price increase on Jan 30? Please provide potential factors.\n",
    "\n",
    "3. Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "4. With unsupervised Full Self Driving scheduled to launch in limited markets like Austin by June, what regulatory challenges does Tesla foresee for a nationwide or international rollout, and how is the company strategically preparing to address these hurdles?\n",
    "\n",
    "5. What insights can be concluded from the earnings call?\n",
    "\n",
    "6. Which key news events influenced the stock performance, and what insights do they offer?\n",
    "\n",
    "---\n",
    "\n",
    "## Project Requirements\n",
    "#### Data Source Restriction:\n",
    "- Only use the provided data and documents. No external data or information is allowed.\n",
    "\n",
    "#### Answer Generation:\n",
    "- All generated answers must strictly be based on the provided data and documents. The LLM should not \"invent\" information.\n",
    "\n",
    "#### Clear Logic and Causal Relationships:\n",
    "- For each question, your answers must clearly demonstrate logical reasoning, and any attribution of cause must be explicitly linked to events in the data.\n",
    "\n",
    "#### Prompt Design:\n",
    "- You must design your own prompts for calling the local LLM to ensure that the responses are generated strictly based on the analysis results.\n",
    "\n",
    "#### Result Evaluation:\n",
    "- After generating the answers, implement an evaluation step to assess whether the responses meet the above requirements in terms of data reliance, logical clarity, and correct causation.\n",
    "\n",
    "#### Please put the answers to these 6 questions in a dict at the end of your submitted Python nodebook file.\n",
    "\n",
    "For example\n",
    "```code\n",
    "{ \"Q1 answer\": \"Answer1\", \"Q2 answer\": \"Answer2\", \"Q3 answer\": \"Answer3\", \"Q4 answer4\": \"Answer4\", \"Q5 answer\": \"Answer5\", \"Q6 answer\": \"Answer6\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3ba393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./project-venv/lib/python3.11/site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in ./project-venv/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: pandas in ./project-venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: ipython in ./project-venv/lib/python3.11/site-packages (9.1.0)\n",
      "Requirement already satisfied: filelock in ./project-venv/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./project-venv/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./project-venv/lib/python3.11/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./project-venv/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./project-venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./project-venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./project-venv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./project-venv/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./project-venv/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./project-venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./project-venv/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./project-venv/lib/python3.11/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./project-venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./project-venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./project-venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: decorator in ./project-venv/lib/python3.11/site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./project-venv/lib/python3.11/site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./project-venv/lib/python3.11/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./project-venv/lib/python3.11/site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./project-venv/lib/python3.11/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./project-venv/lib/python3.11/site-packages (from ipython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./project-venv/lib/python3.11/site-packages (from ipython) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./project-venv/lib/python3.11/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./project-venv/lib/python3.11/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in ./project-venv/lib/python3.11/site-packages (from ipython) (4.13.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./project-venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./project-venv/lib/python3.11/site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./project-venv/lib/python3.11/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./project-venv/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in ./project-venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in ./project-venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./project-venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./project-venv/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./project-venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./project-venv/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./project-venv/lib/python3.11/site-packages (from stack_data->ipython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./project-venv/lib/python3.11/site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./project-venv/lib/python3.11/site-packages (from stack_data->ipython) (0.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./project-venv/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers accelerate pandas ipython\n",
    "# %pip install torch # Install PyTorch if you dont have it downloading \n",
    "\n",
    "DATA_DIR = \"447_dataset\"\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290d56f",
   "metadata": {},
   "source": [
    "## Loading and Running the Local LLM\n",
    "\n",
    "1. **Imports Transformers utilities**  \n",
    "   - `AutoModelForCausalLM`: generic class for loading any GPT‑style model  \n",
    "   - `AutoTokenizer`: matching tokenizer for converting text ↔ tokens  \n",
    "   - `pipeline`: high‑level helper that ties model + tokenizer into one callable  \n",
    "\n",
    "2. **Specifies the model repository**  \n",
    "   ```python\n",
    "   model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8d52b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# The pipeline will automatically use the model and tokenizer you just loaded\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) # Load the tokenizer\n",
    "\n",
    " # Create a pipeline for text generation\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 2000, # Limit the number of tokens generated\n",
    "    \"return_full_text\": False, # Return only the generated text\n",
    "    \"do_sample\": True, # Use sampling to generate text\n",
    "    \"temperature\": 0.1,# Control the randomness of the output\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"top_p\": 0.9, # Control the diversity of the output\n",
    "    \"top_k\": 50, # Control the diversity of the output\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "699af2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_system_prompt = ( \n",
    "    \"You are an expert financial data analyst LLM.\\n\"\n",
    "    \"You must ensure the following rules are followed:\\n\"\n",
    "    \"1. Use only the data summaries provided in the prompt.\\n\"\n",
    "    \"2. Show clear step-by-step reasoning, linking each claim directly to the data.\\n\"\n",
    "    \"3. Ensure all explanations are clear, logical, and accurate.\\n\"\n",
    "    \"4. Do not invent or hallucinate any information.\\n\"\n",
    "    \"After your answer, provide a checklist summary indicating whether each criterion is satisfied. \"\n",
    "    \"If any criterion is not met, include a brief explanation.\"\n",
    ")\n",
    "\n",
    "\n",
    "def trim_reasoning(raw):\n",
    "    tag = \"</think>\"\n",
    "    idx = raw.find(tag)\n",
    "\n",
    "    if idx != -1:\n",
    "        answer = raw[idx + len(tag):].strip()\n",
    "    else:\n",
    "        answer = raw.strip()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b8eac",
   "metadata": {},
   "source": [
    "## Evaluation of the LLM response using the LLM as an evaluator\n",
    "\n",
    "The bellow code cell will show how we built our function to evaluate the LLM response based on the following parameters:\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26c2a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_system_prompt = (\n",
    "    \"You are a critical and strict reviewer tasked with evaluating financial-analysis answers. \"\n",
    "    \"Your job is to verify that the answer:\\n\"\n",
    "    \"1. Uses *only* the provided data (no outside info).\\n\"\n",
    "    \"2. Clearly explains its logic and reasoning.\\n\"\n",
    "    \"3. Attributes any cause-effect relationships directly to the data.\\n\"\n",
    "    \"4. Avoids speculation or made-up facts.\\n\"\n",
    "    \"Respond with a simple Yes/No checklist for each point, then a brief explanation of any failures.\"\n",
    ")\n",
    "\n",
    "evaluation_system_prompt_extra = (\"YOU MUST JUST EVALUATE THE ANSWER GIVEN BY THE LLM!\")\n",
    "\n",
    "\n",
    "evaluation_user_prompt_template = \"\"\"\n",
    "   Here’s what you need to evaluate:\n",
    "\n",
    "    **Question:**  \n",
    "    {question}\n",
    "\n",
    "    **Data Provided:**  \n",
    "    {data_snippet}\n",
    "\n",
    "    **LLM’s Answer:**  \n",
    "    {llm_answer}\n",
    "\n",
    "    Please produce:\n",
    "    \n",
    "    1. A four-item checklist, each with “Yes” or “No” next to:\n",
    "    - “Only uses provided data”\n",
    "    - “Clear logic & reasoning”\n",
    "    - “All causes linked to data”\n",
    "    - “No speculation or made-up facts”\n",
    "\n",
    "    2. For any “No” items, a one-sentence explanation of the issue.\n",
    "        \"\"\"\n",
    "def evaluate_response(generated_answer, data, question):\n",
    "    evaluation_prompt = evaluation_user_prompt_template.format(\n",
    "        question= question,\n",
    "        data_snippet=\"\\n\\n\".join(data),  # or a trimmed version of summaries\n",
    "        llm_answer=generated_answer\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": evaluation_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "    ]\n",
    "\n",
    "    evaluation_result = pipe(messages, **generation_args)\n",
    "    display(Markdown(trim_reasoning(evaluation_result[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1d4bb",
   "metadata": {},
   "source": [
    "### Question 1:What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "#### Prompt construction\n",
    "\n",
    "* Here we need to monitor the performance of the tesla stock over the specified days. To monitor the performance of the stock the LLM just need to understand the how the pricing of the stock was through the given period hence why the LLM will need to see the infomation in the `prices.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55617ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\"\"\"   \n",
    "This Function extracts the price information and converts the informations\n",
    "into a simple readable format to be included in the prompt to the LLM\n",
    "\"\"\"\n",
    "def get_prices_summary():\n",
    "    prices_path = os.path.join(DATA_DIR, \"prices.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(prices_path, \"r\") as f:\n",
    "        prices = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and index\n",
    "    prices[\"Date\"] = pd.to_datetime(prices[\"Date\"])\n",
    "    prices = prices.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build a human-readable summary for each day\n",
    "    daily_summaries = []\n",
    "    for date, row in prices.iterrows():\n",
    "        daily_summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Open ${row['Open']:.2f}, \"\n",
    "            f\"High ${row['Hight']:.2f}, \"\n",
    "            f\"Low ${row['Low']:.2f}, \"\n",
    "            f\"Close ${row['Close']:.2f}, \"\n",
    "            f\"Volume {int(row['Volume']):,}\"\n",
    "        )\n",
    "\n",
    "    # Join them into one block of text\n",
    "    daily_summary_text = \"\\n\".join(daily_summaries)\n",
    "    return daily_summary_text\n",
    "\n",
    "\n",
    "#print(get_prices_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e33e7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Summary of Tesla Stock Performance (Jan 22 - Feb 5)\n",
       "\n",
       "---\n",
       "\n",
       "#### **Introduction**\n",
       "This analysis provides a concise overview of Tesla (TSLA) stock performance from Monday, January 22nd, to Friday, February 5th, 2025. The data spans approximately 14 days, covering daily open/close prices, volume, and percentage changes. The goal is to evaluate Tesla's stock performance during this period, focusing on key trends and movements.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Analysis**\n",
       "\n",
       "| Date       | Open Price | High Price | Low Price | Close Price | Volume | % Change (Open-to-Close) | % Change (High-to-Low) | % Change (Low-to-Close) |\n",
       "|------------|-------------|------------|-----------|-------------|-------|------------------------|--------------------|-------------------------|\n",
       "| **2025-01-22** | $416.81     | $428.00    | $414.59   | $415.11      | 60,963 | -0.2%                 | -0.3%               | -0.6%                   |\n",
       "| **2025-01-23** | $416.06     | $420.73    | $408.95   | $412.38      | 50,690 | +0.1%                 | -0.1%               | -0.1%                   |\n",
       "| **2025-01-24** | $414.45     | $418.88    | $405.78   | $406.58      | 56,427 | +0.2%                 | -0.3%               | -0.2%                   |\n",
       "| **2025-01-27** | $394.80     | $406.69    | $389.00   | $397.15      | 58,125 | -0.5%                 | +0.4%               | -0.1%                   |\n",
       "| **2025-01-28** | $396.91     | $400.59    | $386.50   | $398.09      | 48,910 | +0.1%                 | -0.1%               | -0.0%                   |\n",
       "| **2025-01-29** | $395.21     | $398.59    | $384.48   | $389.10      | 68,033 | -0.3%                 | +0.2%               | -0.2%                   |\n",
       "| **2025-01-30** | $410.78     | $412.50    | $384.41   | $400.28      | 98,092 | -0.1%                 | +0.2%               | -0.0%                   |\n",
       "| **2025-01-31** | $401.53     | $419.99    | $401.34   | $404.60      | 83,568 | -0.1%                 | +0.4%               | -0.1%                   |\n",
       "\n",
       "---\n",
       "\n",
       "#### **Causal Insights**\n",
       "1. **Price Fluctuations**: The stock experienced significant fluctuations throughout the period, with increases and decreases driven by market sentiment, company earnings, and macroeconomic factors.\n",
       "2. **Volume Analysis**: The volume numbers varied significantly, with higher trading activity on certain days, potentially reflecting investor interest or corporate earnings.\n",
       "3. **Market Sentiment**: There was evidence of both bullish and bearish sentiment, particularly evident on the 23rd and 24th days, where the stock opened higher despite ending lower.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Conclusion**\n",
       "Over the period from January 22nd to February 5th, 2025, Tesla stock exhibited both upward and downward movements. While the stock saw some resilience, it also faced challenges that contributed to its overall decline. The combination of short-term gains and sustained losses suggests that Tesla's stock performance during this period was influenced by a mix of market conditions and company-specific factors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_prompt_template_q1 =( \"\"\"\n",
    "    Here is the summarized Tesla data for Jan 22 - Feb 5:\n",
    "    {price_info}\n",
    "\n",
    "    **Question:**  \n",
    "    What was the performance of Tesla stock over this period?\n",
    "                          \n",
    "    **Please:**\n",
    "    - Write a brief **Introduction** stating the question and data scope.  \n",
    "    - In your **Analysis**, cite the exact figures (dates, prices, percent changes, volumes).  \n",
    "    - Draw any causal insights clearly (e.g., “the drop on Feb 1 may be linked to…”).  \n",
    "    - Finish with a concise **Conclusion** summarizing overall performance.\n",
    "    - You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\")\n",
    "\n",
    "# Fill in the template with specific data\n",
    "filled_user_prompt = user_prompt_template_q1.format(\n",
    "    price_info = get_prices_summary()\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": filled_user_prompt},\n",
    "]\n",
    "\n",
    "question1Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question1Answer[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee8adcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Evaluation Checklist\n",
       "\n",
       "1. **Does the answer use only the provided data?**\n",
       "   - **Yes**  \n",
       "     The answer includes all relevant data points such as open, high, low, close, and volume for each trading day within the specified period. No additional or external data is used.\n",
       "\n",
       "2. **Is the logic explained clearly?**\n",
       "   - **Yes**  \n",
       "     The answer demonstrates a logical flow by explaining how each metric influences the next. For example, it connects the percentage change from open to close with the subsequent day's performance, showing a clear cause-effect relationship.\n",
       "\n",
       "3. **Are cause-effect relationships directly attributed to the data?**\n",
       "   - **Yes**  \n",
       "     Each movement in the stock price is explained based on the provided data. For instance, the stock increasing after a positive open-price move is attributed to the data itself, without speculation.\n",
       "\n",
       "4. **Avoids speculation or made-up facts?**\n",
       "   - **Yes**  \n",
       "     The answer does not include any hypothetical scenarios or assumptions. All claims are grounded in the provided data, ensuring factual accuracy.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The provided financial analysis accurately uses only the given data, explains the logic clearly, attributes cause-effect relationships directly to the data, and avoids speculation or made-up facts. Therefore, it meets all the specified criteria."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating the response for Question 1 using the LLM\n",
    "question_1 = \"What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\"\n",
    "price_summary = get_prices_summary()\n",
    "evaluate_response(trim_reasoning(question1Answer[0]['generated_text']), price_summary, question_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc95b2",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 1\n",
    "\n",
    "Based on the ouptut, the model did a good job at summarizing the prices, neatly organziing everything into a table. The answer used the relevant data an provided the market movent details as well. It was able to notice key trends and link peices of data togehter such as arket movement and the volumes. The answer additonally did not include any hypothetical scenarios and assumptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb7491",
   "metadata": {},
   "source": [
    "# Question 2 \n",
    "### Why did the price increase on Jan 30? Please provide potential factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc284196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Our quarterly earnings for the period ending March 31, 2023, amounted to $1.5 billion, representing an 8% increase from the previous year.  \n",
      "- The company has outlined its strategic guidelines, emphasizing innovation, sustainability, and customer experience as core priorities.  \n",
      "- A notable achievement includes a 7% rise in gross margin compared to the same period last year, reflecting improved profitability.  \n",
      "- The CEO highlighted the importance of long-term growth and customer-centric strategies, underscoring the company's commitment to sustainable development.\n",
      "\n",
      "- Revenue growth achieved in the past quarter, targeting a 10% year-over-year increase.  \n",
      "- Company has implemented cost-efficient strategies and improved pricing models.  \n",
      "- Focus on innovation and enhancing customer experience to drive growth.  \n",
      "- Earnings per share (EPS) remains stable at $X, reflecting strong financial performance.\n",
      "\n",
      "- Revenue growth from $10B to $12B, driven by strong demand and efficient pricing strategies.  \n",
      "- Net profit increased by 15%, reflecting improved profitability and cost control measures.  \n",
      "- Cost management efforts reduced expenses by 8%, highlighting operational efficiency.  \n",
      "- Positive trends in product margins and customer acquisition costs (CAC) indicate strong market performance.  \n",
      "- Future outlook predicts a 7% revenue increase and a 10% profit rise, supported by strategic initiatives.  \n",
      "- Expansion into emerging markets and enhanced digital capabilities suggest potential for sustained growth.\n",
      "\n",
      "- Revenue growth from $10 billion to $12 billion.  \n",
      "- Gross margin increased by 5%.  \n",
      "- Cost management strategies achieved a 70% reduction in operational costs.  \n",
      "- Future outlook predicts a 10% increase in revenue and a 6% rise in net income.  \n",
      "- Customer satisfaction drives long-term success.\n",
      "\n",
      "- Revenue growth of [amount] and expansion into new markets, driven by strong performance in core products.  \n",
      "- Cost management improvements and efficiency gains, resulting in higher margins and reduced expenses.  \n",
      "- Focus on innovation and enhancing customer experience, signaling future growth opportunities.\n",
      "\n",
      "- Revenue Growth: Company reported a 20% year-over-year revenue increase from $10B to $12B.  \n",
      "- Net Profit Improvement: Net profit rose from $5B to $6B, reflecting stronger profitability.  \n",
      "- Cost Management: Expenses decreased by 15%, improving efficiency and profitability.  \n",
      "- Expansion Target: Company plans to expand production capacity to meet increased demand.\n",
      "\n",
      "- **Company Performance**: Strong Q2 results with revenue growth and improved profitability metrics.  \n",
      "- **Key Metrics**: Gross profit margin increased to 28%, while operating expenses declined by 7%.  \n",
      "- **Management Guidance**: Confident in business fundamentals and plans to accelerate expansion.  \n",
      "- **Future Outlook**: Anticipated revenue increases and cost reductions as part of expansion strategy.\n",
      "\n",
      "- **Company Overview**: Revenue grew 15% YoY, with gross profit and operating income increasing slightly (17% and 19% respectively). Costs were reduced by 20% relative to last year.  \n",
      "- **Revenue & Margin Trends**: Revenue increased 17% YoY, while gross profit and operating income rose 18% and 19% respectively.  \n",
      "- **Key Metrics**: Revenue was $1.2 billion, gross profit $600 million, operating income $150 million, EBITDA $120 million, net income $100 million, and EPS $2.5.  \n",
      "- **Management Comments**: Management emphasized cost control and improved pricing strategies, predicting future revenue growth of 18-20% annually, operating income increases of 15-17%, and net income rising by similar percentages.  \n",
      "- **Future Outlook**: The company expects revenue growth, operating income, and net income to increase by 15-17% annually, driven by strong fundamentals and continued cost efficiency improvements.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "system_prompt_ts = (\n",
    "    \"\"\"\n",
    "    You are an expert financial analysis assistant.  \n",
    "    Always respond in clear, concise English.  \n",
    "    Use only the information explicitly provided in the user’s inputs.  \n",
    "    Do not invent, fetch, or reference any external data.  \n",
    "    Produce only bullet points—no prose.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "user_prompt_ts = (\n",
    "    \"\"\"\n",
    "Please summarize the following earnings‑call excerpt into 3–4 bullet points,\n",
    "focusing on key financial metrics, guidance, or other actionable insights.\n",
    "Do not add commentary or restate the question—just the bullets.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "with open(\"447_dataset/earning_transcript.md\", \"r\") as f:\n",
    "    earnings_transcript_data = f.read()\n",
    "\n",
    "lines = earnings_transcript_data.splitlines()\n",
    "\n",
    "chunks = []\n",
    "current_chunk = []\n",
    "max_lines_per_chunk = 50\n",
    "\n",
    "for line in lines:\n",
    "    current_chunk.append(line)\n",
    "    if len(current_chunk) >= max_lines_per_chunk:\n",
    "        chunk_text = \"\\n\".join(current_chunk)\n",
    "        chunks.append(chunk_text)\n",
    "        current_chunk = []\n",
    "\n",
    "if current_chunk:\n",
    "    chunk_text = \"\\n\".join(current_chunk)\n",
    "    chunks.append(chunk_text)\n",
    "\n",
    "transcript_summary = []\n",
    "\n",
    "def clean_summary(raw):\n",
    "    s = re.sub(r\"<think>.*?</think>\", \"\", raw, flags=re.S)\n",
    "    s = re.sub(r\"(?m)^(Thought:|Thinking:?).*\\n?\", \"\", s)\n",
    "    m = re.search(r\"(?m)^[-•]\\s+\", s)\n",
    "    if m:\n",
    "        return s[m.start():].strip()\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "for i in range(len(chunks)):\n",
    "    filled_user_ts = user_prompt_ts.format(earnings_transcript=chunks[i])\n",
    "    messages_ts = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt_ts},\n",
    "        {\"role\": \"user\",   \"content\": filled_user_ts},\n",
    "    ] \n",
    "    out = pipe(messages_ts, **generation_args)\n",
    "    raw = out[0][\"generated_text\"]\n",
    "    summary = clean_summary(raw)\n",
    "    transcript_summary.append(summary)\n",
    "\n",
    "full_transcript_summary = \"\\n\\n\".join(transcript_summary)\n",
    "\n",
    "print(full_transcript_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d085a8",
   "metadata": {},
   "source": [
    "### Extract News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41d4ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "with open(\"447_dataset/news.json\", \"r\") as f:\n",
    "    all_news = json.load(f)\n",
    "\n",
    "def parse_date(s: str) -> datetime.date:\n",
    "    return datetime.strptime(s.strip(), \"%B %d, %Y\").date()\n",
    "\n",
    "\n",
    "start = datetime(2025, 1, 25).date()\n",
    "end   = datetime(2025, 1,  30).date()\n",
    "\n",
    "news_window = [\n",
    "    article\n",
    "    for article in all_news\n",
    "    if start <= parse_date(article[\"date\"]) <= end\n",
    "]\n",
    "\n",
    "# print(f\"Found {len(news_window)} articles between {start} and {end}:\")\n",
    "# for a in news_window:\n",
    "#     print(f\"- {a['date']}: {a['title']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e0243",
   "metadata": {},
   "source": [
    "### Extract Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "967b6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "with open(\"447_dataset/news.json\", \"r\") as f:\n",
    "    all_news = json.load(f)\n",
    "\n",
    "def parse_date(s: str) -> datetime.date:\n",
    "    return datetime.strptime(s.strip(), \"%B %d, %Y\").date()\n",
    "\n",
    "start = datetime(2025, 1, 25).date()\n",
    "end   = datetime(2025, 1,  30).date()\n",
    "\n",
    "news_window = [\n",
    "    article\n",
    "    for article in all_news\n",
    "    if start <= parse_date(article[\"date\"]) <= end\n",
    "]\n",
    "\n",
    "# print(f\"Found {len(news_window)} articles between {start} and {end}:\")\n",
    "# for a in news_window:\n",
    "#     print(f\"- {a['date']}: {a['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2ea22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"447_dataset/earning.json\", \"r\") as f:\n",
    "    earnings = json.load(f)\n",
    "\n",
    "earnings = json.dumps(earnings, indent=2, ensure_ascii=False)\n",
    "# print(earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76450e06",
   "metadata": {},
   "source": [
    "### Relavant Price Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "391b017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def load_prices(path: str):\n",
    "    \"\"\"Load the full list of price bars from a JSON file.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def filter_by_date(prices, start_date: str, end_date: str):\n",
    "    \"\"\"\n",
    "    Return only those price entries whose 'Date' field\n",
    "    falls between start_date and end_date, inclusive.\n",
    "    Dates must be in 'YYYY-MM-DD' format.\n",
    "    \"\"\"\n",
    "    start = datetime.fromisoformat(start_date).date()\n",
    "    end   = datetime.fromisoformat(end_date).date()\n",
    "\n",
    "    return [\n",
    "        p for p in prices\n",
    "        if start <= datetime.fromisoformat(p[\"Date\"]).date() <= end\n",
    "    ]\n",
    "\n",
    "\n",
    "    \n",
    "start_date = \"2025-01-20\"\n",
    "end_date   = \"2025-01-30\"\n",
    "\n",
    "prices = load_prices(\"447_dataset/prices.json\")\n",
    "window = filter_by_date(prices, start_date, end_date)\n",
    "\n",
    "relevant_prices = json.dumps(window, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8053d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **A) Executive Summary**  \n",
       "1–2 sentences: list the top 2–3 drivers (you’ll expand each below).  \n",
       "\n",
       "---\n",
       "\n",
       "### **B) Detailed Drivers**  \n",
       "Provide exactly four subsections **B1–B4**, one per dataset:  \n",
       "\n",
       "- **B1) Earnings-Driven Insight (Dataset: Earnings results*)**  \n",
       "  - **Title:**  \n",
       "  - **Data Point:** exact figure(s) with citation \n",
       "  - **Impact Analysis:** 2–3 sentences tying the earnings data to the price move.  \n",
       "\n",
       "- **B2) Stock-Price Insight (Dataset: Stock price summary)**  \n",
       "  - **Title:**  \n",
       "  - **Data Point:** exact value(s) with citation \n",
       "  - **Impact Analysis:** 2–3 sentences explaining how the stock price drove the move.  \n",
       "\n",
       "- **B3) News-Driven Insight (Dataset: News articles)**  \n",
       "  - **Title:**  \n",
       "  - **Data Point:** exact headline or excerpt with citation\n",
       "  - **Impact Analysis:** 2–3 sentences on the news’ effect on investor behavior.  \n",
       "\n",
       "- **B4) Transcript-Driven Insight (Dataset: Earnings-call transcript)**  \n",
       "  - **Title:**  \n",
       "  - **Data Point:** exact quote with citation (Transcript )\n",
       "  - **Impact Analysis:** 2–3 sentences on why that comment moved the stock.  \n",
       "\n",
       "---\n",
       "\n",
       "### **C) Driver Ranking**  \n",
       "List B1→B4 in order of strongest→weakest, one sentence each explaining the ranking.  \n",
       "\n",
       "---\n",
       "\n",
       "### **D) Data Gaps**  \n",
       "If any driver is “No driver found,” repeat that here for the empty dataset.  \n",
       "\n",
       "---\n",
       "\n",
       "### **E) Conclusion**  \n",
       "A 1–2 sentence wrap-up that ties all four insights together.  \n",
       "\n",
       "---\n",
       "\n",
       "### **Final Answer**  \n",
       "\n",
       "The stock price movement is driven by strong customer experience, growth, cost management, and the CEO's comments. The CEO's remarks highlight customer satisfaction and growth, while the stock presentation emphasizes the CEO's comments on customer experience and growth. Additionally, cost management efforts improve efficiency, and the strong customer experience contributes to the overall upward trend."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt_q2 = (\"\"\"\n",
    "You are an expert financial‐analysis assistant with NO external knowledge—only the four datasets the user provides.  \n",
    "You must:\n",
    "1. Review **every** dataset (*Earnings results, Stock price summary, News articles*, Earnings-call transcript).  \n",
    "2. Draw **exactly one** driver from each dataset (Earnings, Price, News, Transcript).\n",
    "3. Support every claim with an explicit citation.  \n",
    "4. If none of the datasets support a hypothesis, respond “Insufficient information.”  \n",
    "5. Explain your logic step by step.\n",
    "\"\"\")\n",
    "\n",
    "user_prompt_q2 = \"\"\"\n",
    "I’m giving you four data sources—no others allowed:\n",
    "\n",
    "1. **Earnings results** :  \n",
    "{earnings_data}\n",
    "\n",
    "2. **Stock price summary** :  \n",
    "{relevant_price_data}\n",
    "\n",
    "3. **News articles** :  \n",
    "{news_data}\n",
    "\n",
    "4. **Earnings-call transcript**:  \n",
    "{transcript_data}\n",
    "\n",
    "---\n",
    "\n",
    "**Question:** Why did the stock price increase on January 30?\n",
    "\n",
    "**Please structure your answer as follows:**\n",
    "\n",
    "**A) Executive Summary**  \n",
    "1–2 sentences: list the top 2–3 drivers (you’ll expand each below).\n",
    "\n",
    "**B) Detailed Drivers**  \n",
    "Provide exactly four subsections **B1–B4**, one per dataset:\n",
    "\n",
    "- **B1) Earnings-Driven Insight (Dataset: Earnings results*)**  \n",
    "  - **Title:**  \n",
    "  - **Data Point:** exact figure(s) with citation \n",
    "  - **Impact Analysis:** 2–3 sentences tying the earnings data to the price move.\n",
    "\n",
    "- **B2) Stock-Price Insight (Dataset: Stock price summary)**  \n",
    "  - **Title:**  \n",
    "  - **Data Point:** exact value(s) with citation \n",
    "  - **Impact Analysis:** 2–3 sentences explaining how the stock price drove the move.\n",
    "\n",
    "- **B3) News-Driven Insight (Dataset: News articles)**  \n",
    "  - **Title:**  \n",
    "  - **Data Point:** exact headline or excerpt with citation\n",
    "  - **Impact Analysis:** 2–3 sentences on the news’ effect on investor behavior.\n",
    "\n",
    "- **B4) Transcript-Driven Insight (Dataset: Earnings-call transcript)**  \n",
    "  - **Title:**  \n",
    "  - **Data Point:** exact quote with citation (Transcript )  \n",
    "  - **Impact Analysis:** 2–3 sentences on why that comment moved the stock.\n",
    "\n",
    "**C) Driver Ranking**  \n",
    "List B1→B4 in order of strongest→weakest, one sentence each explaining the ranking.\n",
    "\n",
    "**D) Data Gaps**  \n",
    "If any driver is “No driver found,” repeat that here for the empty dataset.\n",
    "\n",
    "**E) Conclusion**  \n",
    "A 1–2 sentence wrap-up that ties all four insights together.\n",
    "\n",
    "Cite **every** fact and **quantify** changes (%, volumes, dates) whenever possible.\n",
    "\"\"\"\n",
    "\n",
    "filled_user_q2 = user_prompt_q2.format(earnings_data = earnings, relevant_price_data = relevant_prices, news_data = news_window, transcript_data = full_transcript_summary)\n",
    "\n",
    "messagesQ2 = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt_q2},\n",
    "        {\"role\": \"user\",   \"content\": filled_user_q2},\n",
    "    ] \n",
    "\n",
    "question2Answer = pipe(messagesQ2, **generation_args)\n",
    "\n",
    "display(Markdown(trim_reasoning(question2Answer[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda52b9",
   "metadata": {},
   "source": [
    "### Quesion2 Evaluvation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the response for Question 1 using the LLM\n",
    "question_2 = \"Why did the price increase on Jan 30? Please provide potential factors.\"\n",
    "question_2_data = [earnings, relevant_prices, news_window, full_transcript_summary]\n",
    "evaluate_response(trim_reasoning(question1Answer[0]['generated_text']), price_summary, question_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6428e1",
   "metadata": {},
   "source": [
    "### Question 3:Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "#### Data Used for Prompt construction\n",
    "\n",
    "* For the LLM to have any insight of quaterly financial information, I will provide it the `balancesheet.json` as this file contains the quaterly financial figures. We will use this data so the LLM is a aware of the performance of the previous 1-2 years. This gives the LLM a base to compare against the current financial quater( 2025 Q1). Since the balance sheet has a lot of infomation, we dont want to overload the LLM with too many features to consider when it comes up with its decison so we will handpick some important features from the balance sheet from each quater.\n",
    "\n",
    "\n",
    "* The Data found in the `earnings.json` also contains relavant financial information for the past five quaters, which the LLM can use compare the performance of the company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a75f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earnings_summary():\n",
    "    \"\"\"\n",
    "    Reads earning.json and returns a plain summary with:\n",
    "    - EPS predicted / actual\n",
    "    - Revenue predicted / actual (in billions)\n",
    "    \"\"\"\n",
    "    earnings_path = os.path.join(DATA_DIR, \"earning.json\")\n",
    "\n",
    "    with open(earnings_path, \"r\") as f:\n",
    "        earnings_json = json.load(f)\n",
    "\n",
    "    lines = []\n",
    "    for rec in earnings_json:\n",
    "        dt = rec.get(\"EarningReleaseDate\") or rec.get(\"EarningReportDate\")\n",
    "        if not dt:\n",
    "            continue\n",
    "\n",
    "        date = pd.to_datetime(dt).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        eps_actual   = rec.get(\"EpsActual\", 0)\n",
    "        eps_forecast = rec.get(\"EpsForecast\", 0)\n",
    "        eps_surprise   = rec.get(\"EpsSurprise\", 0)\n",
    "\n",
    "        rev_actual   = rec.get(\"RevenueActual\", 0) / 1e9\n",
    "        rev_forecast = rec.get(\"RevenueForecast\", 0) / 1e9\n",
    "\n",
    "        line = (\n",
    "            f\"{date}: \"\n",
    "            f\"EPS predicted: {eps_forecast:.2f}, EPS actual: {eps_actual:.2f}, EPS surprise: {eps_surprise:.2f}; \"\n",
    "            f\"Revenue predicted: ${rev_forecast:.2f}B, Revenue actual: ${rev_actual:.2f}B\"\n",
    "        )\n",
    "        lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def get_balance_sheet_summary():\n",
    "    \"\"\"\n",
    "    This function extracts financial statement information from balencesheet.json\n",
    "    and returns a readable summary line for each quarter.\n",
    "    \"\"\"\n",
    "    bs_path = os.path.join(DATA_DIR, \"balencesheet.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(bs_path, \"r\") as f:\n",
    "        balance_sheet = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and sort\n",
    "    balance_sheet[\"Date\"] = pd.to_datetime(balance_sheet[\"Date\"])\n",
    "    balance_sheet = balance_sheet.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build human-readable lines\n",
    "    summaries = []\n",
    "    for date, row in balance_sheet.iterrows():\n",
    "        rev       = row.get(\"Total Revenue\", 0) / 1e6\n",
    "        gp        = row.get(\"Gross Profit\", 0) / 1e6\n",
    "        op_inc    = row.get(\"Operating Income\", 0) / 1e6\n",
    "        net_inc   = row.get(\"Net Income Common Stockholders\", 0) / 1e6\n",
    "        ebitda    = row.get(\"EBITDA\", 0) / 1e6\n",
    "        tot_exp   = row.get(\"Total Expenses\", 0) / 1e6\n",
    "\n",
    "        # Calculate margins and ratios safely\n",
    "        gross_margin   = gp / rev * 100 if rev else 0\n",
    "        op_margin      = op_inc / rev * 100 if rev else 0\n",
    "        net_margin     = net_inc / rev * 100 if rev else 0\n",
    "\n",
    "        summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Revenue ${rev:.1f}M, Gross Profit ${gp:.1f}M ({gross_margin:.1f}%), \"\n",
    "            f\"Operational Income ${op_inc:.1f}M ({op_margin:.1f}%), Net Income ${net_inc:.1f}M ({net_margin:.1f}%), \"\n",
    "            f\"EBITDA ${ebitda:.1f}M, Total Expenses ${tot_exp:.1f}M, \"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(summaries)\n",
    "\n",
    "print(\"----------Balance Sheet Summary----------\")\n",
    "print(get_balance_sheet_summary())\n",
    "print(\"\\n-----------Earnings Summary---------------\")\n",
    "print(get_earnings_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4695ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "question3_user_prompt = f\"\"\"\n",
    "Here are your two data summaries:\n",
    "\n",
    "**Balance Sheet Summary** \n",
    "- Balance sheet summary containing the quaterly financial information for the previous quaters \n",
    "{get_balance_sheet_summary()}\n",
    "\n",
    "\n",
    "**Earnings Summary**  \n",
    "- Earnings summary containing the quaterly earnings information for the previous quaters and the current quater(2025 Q1)\n",
    "{get_earnings_summary()}\n",
    "\n",
    "**Question:**  \n",
    "Compared with previous quarters, how is the performance of this quarter (ending 2025‑01‑29)?\n",
    "\n",
    "**Please:**  \n",
    "- Write a brief **Introduction** stating the question and data scope.  \n",
    "- In your **Analysis**, compare each metric (Revenue, Gross Profit, Operational Income, Net Income, EBITDA, EPS and Revenue surprises) quarter‑over‑quarter, citing the exact figures.  \n",
    "- Highlight any notable trends (e.g., margin expansions or EPS misses).  \n",
    "- Finish with a concise **Conclusion** summarizing whether performance improved or deteriorated and why.\n",
    "- You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\",   \"content\": question3_user_prompt},\n",
    "]\n",
    "\n",
    "question3Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question3Answer[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the response for question 3 using the LLM\n",
    "\n",
    "question_3 = \"Compared with previous quarters, how is the performance of this quarter (ending 2025‑01‑29)?\"\n",
    "data_q3 = \"\\n\".join([\n",
    "    \"----------Balance Sheet Summary----------\", \n",
    "    get_balance_sheet_summary(), \n",
    "    \"\\n-----------Earnings Summary---------------\", \n",
    "    get_earnings_summary()\n",
    "])\n",
    "\n",
    "evaluate_response(trim_reasoning(question3Answer[0]['generated_text']), data_q3, question_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a3abe",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 3\n",
    "\n",
    "The structure of the response is clear and well-organized, breaking down each metric effectively. However, it compares the wrong quarters — claiming a year-over-year comparison with 2024-01 but actually pulling numbers from 2024-12. Several values are also inaccurate: for example, revenue wasn’t flat, it increased slightly (~2%), and operating income was misreported. The revenue surprise was also miscalculated (off by several percentage points).The tone is professional, and the format works well. The model seems to struggle a bit with showing relationship to the data but it was abale to structure a decent answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707608a",
   "metadata": {},
   "source": [
    "### Question 4 : With unsupervised Full Self Driving scheduled to launch in limited markets like Austin by June, what regulatory challenges does Tesla foresee for a nationwide or international rollout, and how is the company strategically preparing to address these hurdles?\n",
    "\n",
    "* For this question we will look at the `news.json` to uncover any news about self driving cars, we filtered all the articles that contained any news about self driving cars. These selected Articles will then be summarised and used in the prompt for the LLM. The LLM can you this infomation to fomulate its answer. After we select the articles that speak about self-driving, we will summerise these sleced articles and include it in the prompt\n",
    "\n",
    "* For this question as mentioned we will be taking a look at the `earning_transcript.md` as this may uncover key infomation about the self driving cars to be unveiled. So we will search for the word 'self-driving' or 'self driving' and then take 6-7 sentences before and after each instance of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9080202e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Self Driving Article 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Self Driving Article 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Self Driving Article 3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Self Driving Article 4"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I see a path, I'm not saying it's an easy path, but I see a path for Tesla being the most valuable company in the world by far, not even close. Like, maybe several times more than, I mean, there is a path where Tesla is worth more than the next top five companies combined. There's a path to that. I mean, I think it's like an incredibly, just like a difficult path, but it is an achievable path. So -- and that is overwhelmingly due to autonomous vehicles and autonomous humanoid robots. So, our focus is actually building towards that. And that's where we're laying the ground. We laid the ground work for that in 2024. We'll continue to lay the ground work for that in 2025. In fact, more than laid the groundwork actually, so it would be building the structure, it’d be we're building the manufacturing lines and like -- like, setting up for what I think will be an epic 2026 and a ridiculous ‘27 and ‘28. Ridiculously good. That is my prediction. As yet, very few people understand the value of Full Self Driving and our ability to monetize the fleet. I've -- some of these things I've said for quite a long time and I know people said, well, Elon is the boy who cried wolf like several times but I'm telling you there's a damn wolf this time and you can drive it. In fact, it can drive you. It's a self-driving wolf. For a lot of people, like their experience of Tesla autonomy is like, if it's even a year old, if it's even two years old, it's like meeting someone when they're like a toddler and thinking that they're going to be a toddler forever. But obviously they're not going to be a toddler forever if they grow up. But if their last experience was like, FSD was a toddler, it's like, well, it's grown up now. Have you seen it? It's like walks and talks. And that's really what we've got. And it's difficult for people to understand this because human intuition is linear as opposed to what we're seeing is exponential progress. So, that's why my number one recommendation for anyone who doubts is simply try it. Have you tried it?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_self_driving_articles():\n",
    "    news_path = os.path.join(DATA_DIR, \"news.json\")\n",
    "\n",
    "    with open(news_path, \"r\") as f:\n",
    "        news_json = json.load(f)\n",
    "    # matches \"self-driving\", \"self driving\", or the typo \"self drving\", case-insensitive\n",
    "    pattern = re.compile(r'\\bself[- ]driving\\b', re.IGNORECASE)\n",
    "\n",
    "    results = []\n",
    "    for art in news_json:\n",
    "        text = art.get(\"content\", \"\")\n",
    "        if pattern.search(text):\n",
    "            results.append({\n",
    "                \"date\": art.get(\"date\", \"\"),\n",
    "                \"title\": art.get(\"title\", \"\"),\n",
    "                \"content\": text\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def extract_self_driving_context():\n",
    "    transcript_path = os.path.join(DATA_DIR, \"earning_transcript.md\")\n",
    "    with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "    pattern = re.compile(r'\\bself[- ]driving\\b', re.IGNORECASE)\n",
    "    window = 12\n",
    "\n",
    "    match_idx = next((i for i, s in enumerate(sentences) if pattern.search(s)), None)\n",
    "    if match_idx is None:\n",
    "        return []\n",
    "\n",
    "    start = max(match_idx - window, 0)\n",
    "    end   = min(match_idx + window + 1, len(sentences))\n",
    "\n",
    "    snippet = \" \".join(sentences[start:end])\n",
    "    return [snippet]\n",
    "\n",
    "\n",
    "self_driving_es_contexts = extract_self_driving_context()\n",
    "self_driving_articles = find_self_driving_articles()\n",
    "for idx, article in enumerate(self_driving_articles):\n",
    "    display(Markdown(f\"### Self Driving Article {idx + 1}\"))\n",
    "    #display(Markdown(article['content']))\n",
    "\n",
    "display(Markdown(self_driving_es_contexts[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9430b",
   "metadata": {},
   "source": [
    "### Question 5:What insights can be concluded from the earnings call?\n",
    "\n",
    "#### Data Used for Prompt construction\n",
    "\n",
    "* To gain insights from the earnings call, we used the transcript available in the `earning_transcript.md` file. Since the full transcript is quite lengthy, our strategy was to break it into smaller sections and summarize each section individually using the LLM. By combining these individual summaries, we created a comprehensive overview of the entire earnings call. For the final prompt, we provided the LLM with this summarized version of the transcript and asked it to identify the key insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_template_q5 = f\"\"\"\n",
    "\"Note: In this response, please pay particular attention to executive tone, guidance, and strategic priorities.\\n\\n\"\n",
    "Here is the summarized earnings call transcript:\n",
    "{full_transcript_summary}\n",
    "\n",
    "Question:\n",
    "What key insights can be concluded from the Tesla earnings call?\n",
    "\n",
    "Please:\n",
    "- Start with a **Overview** of the call’s focus.\n",
    "- Identify the **Key Themes** or concerns mentioned and briefly explain then with context from the call(e.g., demand, margin pressure, product roadmap).\n",
    "- Highlight any **management tone or forward-looking statements**.\n",
    "- Try to identify any statements about future goals of the company.\n",
    "- Finish with a concise **Conclusion** that summarizes the strategic outlook or market signal from the call.\n",
    "- You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt_template_q5},\n",
    "]\n",
    "\n",
    "question5Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question5Answer[0]['generated_text'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the response for question 5 using the LLM\n",
    "\n",
    "question_5 = \"What key insights can be concluded from the Tesla earnings call?\"\n",
    "evaluate_response(trim_reasoning(question5Answer[0]['generated_text']), full_transcript_summary, question_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc18829",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 5\n",
    "\n",
    "# INDY HAS TO FINIsh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17271034",
   "metadata": {},
   "source": [
    "### Question 6:Which key news events influenced the stock performance, and what insights do they offer?\n",
    "\n",
    "#### Prompt construction\n",
    "\n",
    "* To analyse what news events affected the stock perferomance we will take a look at the news articles found in `news.json`. This file has new events but it seems to be large sections of text which might be hard to include in the prompt for the LLM. We will use a similar strategy to extract the most important infomation out of the news articles. We will split the news articles into batches of 3 and then ask the LLM to summarise the key information. Then we will combined these summaries to create a comprehensive summary that will be included in the final prompt to the LLM, where it will use the summary to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed73a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing article 1/10...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     58\u001b[39m         summaries.append(response[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m summaries\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m news_summaries = \u001b[43msummarize_each_news_article_one_by_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_json\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36msummarize_each_news_article_one_by_one\u001b[39m\u001b[34m(news_json)\u001b[39m\n\u001b[32m     51\u001b[39m     messages = [\n\u001b[32m     52\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: summarise_news_system_prompt},\n\u001b[32m     53\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: user_prompt}\n\u001b[32m     54\u001b[39m     ]\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSummarizing article \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(news_json)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     response = \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     summaries.append(response[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m summaries\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:280\u001b[39m, in \u001b[36mTextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, text_inputs, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[39;00m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mChat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m         chats = (Chat(chat) \u001b[38;5;28;01mfor\u001b[39;00m chat \u001b[38;5;129;01min\u001b[39;00m text_inputs)  \u001b[38;5;66;03m# 🐈 🐈 🐈\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1379\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1372\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1373\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1376\u001b[39m         )\n\u001b[32m   1377\u001b[39m     )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1386\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1385\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1286\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1285\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:385\u001b[39m, in \u001b[36mTextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    383\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[32m    388\u001b[39m     generated_sequence = output.sequences\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/generation/utils.py:2465\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2457\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2458\u001b[39m         input_ids=input_ids,\n\u001b[32m   2459\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2460\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2461\u001b[39m         **model_kwargs,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2464\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2470\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2472\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2476\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2477\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2478\u001b[39m         input_ids=input_ids,\n\u001b[32m   2479\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2480\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2481\u001b[39m         **model_kwargs,\n\u001b[32m   2482\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/generation/utils.py:3431\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3428\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3430\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m3431\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3432\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/accelerate/hooks.py:176\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:823\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    818\u001b[39m output_hidden_states = (\n\u001b[32m    819\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    820\u001b[39m )\n\u001b[32m    822\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    836\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    837\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:526\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    523\u001b[39m hidden_states = inputs_embeds\n\u001b[32m    525\u001b[39m \u001b[38;5;66;03m# create position embeddings to be shared across the decoder layers\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m position_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrotary_emb\u001b[49m(hidden_states, position_ids)\n\u001b[32m    528\u001b[39m \u001b[38;5;66;03m# decoder layers\u001b[39;00m\n\u001b[32m    529\u001b[39m all_hidden_states = () \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/University/WINTER 2025/ECE 447/Stock-Data-Analyzer/project-venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1915\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28mself\u001b[39m._backward_pre_hooks = OrderedDict()\n\u001b[32m   1912\u001b[39m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[32m   1913\u001b[39m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[32m   1914\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1915\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Union[Tensor, \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1916\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m   1917\u001b[39m         _parameters = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def get_all_news_articles_individually():\n",
    "\n",
    "    news_path = os.path.join(DATA_DIR, \"news.json\")\n",
    "\n",
    "    with open(news_path, \"r\") as f:\n",
    "        news_json = json.load(f)\n",
    "\n",
    "    # Create a list of formatted articles\n",
    "    formatted_articles = [\n",
    "        textwrap.dedent(\n",
    "            f\"Article {i + 1}:\\n\"\n",
    "            f\"Title: {article['title']}\\n\"\n",
    "            f\"Date: {article['date']}\\n\"\n",
    "            f\"Content:\\n{article['content']}\"\n",
    "        )\n",
    "        for i, article in enumerate(news_json)\n",
    "    ]\n",
    "\n",
    "    return formatted_articles\n",
    "\n",
    "news_path = os.path.join(DATA_DIR, \"news.json\")\n",
    "with open(news_path, \"r\") as f:\n",
    "        news_json = json.load(f)\n",
    "\n",
    "def summarize_each_news_article_one_by_one(news_json):\n",
    "\n",
    "    # System prompt\n",
    "    summarise_news_system_prompt = (\n",
    "        \"You are a professional financial news summarizer.\\n\"\n",
    "        \"Given a news article about Tesla, produce a standalone summary that:\\n\"\n",
    "        \"- Is approximately 100–150 words long.\\n\"\n",
    "        \"- Clearly identifies the main event or announcement.\\n\"\n",
    "        \"- Highlights any financial, strategic, or regulatory implications.\\n\"\n",
    "        \"- Remains neutral and grounded in the content provided.\\n\"\n",
    "        \"Do not invent or assume any details beyond what's in the article.\"\n",
    "        \"You must respond in English!\"\n",
    "    )\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    for i, article in enumerate(news_json):\n",
    "        article_text = textwrap.dedent(f\"\"\"\n",
    "        Title: {article['title']}\n",
    "        Date: {article['date']}\n",
    "        Content:\n",
    "        {article['content']}\n",
    "        \"\"\")\n",
    "\n",
    "        user_prompt = f\"Summarize the following article:\\n\\n{article_text}\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": summarise_news_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "\n",
    "        print(f\"Summarizing article {i + 1}/{len(news_json)}...\")\n",
    "        response = pipe(messages, **generation_args)\n",
    "        summaries.append(response[0][\"generated_text\"])\n",
    "\n",
    "    return summaries\n",
    "\n",
    "news_summaries = summarize_each_news_article_one_by_one(news_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comprehensive_news_summary(news_summaries):\n",
    "  comprehensive_news_summary = []\n",
    "  for idx, summary in enumerate(news_summaries):\n",
    "    comprehensive_news_summary.append(f\"Article {idx + 1}: {(trim_reasoning(summary))}\")\n",
    "    comprehensive_news_summary.append(\"\\n\")\n",
    "  return \"\\n\".join(comprehensive_news_summary)\n",
    "\n",
    "comprehensive_news_summary =get_comprehensive_news_summary(news_summaries)\n",
    "#display(Markdown(comprehensive_news_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_analysis_user_prompt_template = f\"\"\"\n",
    "You are given a summary of key news events related to Tesla over a recent period.\n",
    "\n",
    "**Question:**  \n",
    "Which key news events influenced Tesla’s stock performance, and what insights do they offer?\n",
    "\n",
    "**News Summary:**  \n",
    "{comprehensive_news_summary}\n",
    "\n",
    "**Please:**\n",
    "- Identify the most impactful events and explain why they mattered.\n",
    "- Highlight whether the impact was positive or negative, and on which part of Tesla’s business (e.g., automotive, energy, robotics, AI, international).\n",
    "- Connect events to possible market sentiment (e.g., uncertainty, optimism, risk).\n",
    "- End with a concise **Conclusion** about the overall narrative and strategic outlook based on this news.\n",
    "- You must strictly avoid speculation or using made-up facts outside of the data provided.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": general_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": news_analysis_user_prompt_template},\n",
    "]\n",
    "\n",
    "question6Answer = pipe(messages, **generation_args)\n",
    "display(Markdown(trim_reasoning(question6Answer[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a568fa",
   "metadata": {},
   "source": [
    "### Chathila's and Induwara's evaluation of the response to Question 6\n",
    "\n",
    "As a team, we felt the response did a good job overall in structuring the analysis around key themes like earnings, tariffs, product recalls, and strategic commitments. Breaking down the news into categories helped make the insights easier to follow, and we appreciated that each event included a potential impact on Tesla’s stock or operations.\n",
    "\n",
    "That said, we noticed a few areas for improvement. First, Article 2 about Tesla and BMW suing the EU wasn’t included in the summary, even though it’s relevant to Tesla’s global operations and regulatory risks. We also felt that while the analysis mentions investor sentiment and resilience, it could have more clearly connected specific news events to actual stock movement. For example, how much the stock rose or fell after a specific announcement would have added more depth.\n",
    "\n",
    "Well-organized and insightful overall, but the response could be strengthened by ensuring all articles are covered, all claims are grounded in the data, and that cause-effect relationships are more explicitly shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3cb55a",
   "metadata": {},
   "source": [
    "## LLM responses to the Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_answers = {\n",
    "    \"Question 1 \": question1Answer[0][\"generated_text\"],\n",
    "    \"Question 2 \": \"\",\n",
    "    \"Question 3 \": question3Answer[0][\"generated_text\"],\n",
    "    \"Question 4 \": \" \",\n",
    "    \"Question 5 \": \" \",\n",
    "    \"Question 6 \":  question6Answer[0]['generated_text'],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
