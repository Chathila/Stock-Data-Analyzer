{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e030378",
   "metadata": {},
   "source": [
    "# Data Analysis and Q&A Project Using a Local LLM\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project requires you to perform a comprehensive analysis of a company's stock data using only the provided data sources and a local LLM. Your analysis should answer the following six questions strictly based on the supplied data and documents—no external data is allowed. All generated answers must be firmly based on the provided data, without any fabricated content. In addition, your logic must be clear, and any attribution of events must be causally linked.\n",
    "\n",
    "---\n",
    "\n",
    "## Provided Data\n",
    "\n",
    "You will be provided with the following data sets:\n",
    "\n",
    "#### Stock Price Data (Json format)\n",
    "* Timeframe: Jan 22 to Feb 5\n",
    "* Fields: Open, High, Low, Close, Volume\n",
    "\n",
    "#### Quarterly Earnings Data for the Past Year (Json format)\n",
    "* Contains key financial indicators (e.g., revenue, eps) for each quarter.\n",
    "\n",
    "#### Full Earnings Transcript Call\n",
    "* The complete transcript of the earnings call, including management discussions and Q&A.\n",
    "\n",
    "#### Balance Sheet Data for the Past Year (Json format)\n",
    "* Includes assets, liabilities, and shareholders' equity information.\n",
    "\n",
    "#### News Articles\n",
    "* Full text of 10 news articles related to the company during the analysis period.\n",
    "\n",
    "---\n",
    "\n",
    "## Questions\n",
    "Using the provided data and a local LLM, you need to answer the following six questions:\n",
    "\n",
    "1. What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "2. Why did the price increase on Jan 30? Please provide potential factors.\n",
    "\n",
    "3. Compared with previous quarters, how is the performance of this quarter?\n",
    "\n",
    "4. With unsupervised Full Self Driving scheduled to launch in limited markets like Austin by June, what regulatory challenges does Tesla foresee for a nationwide or international rollout, and how is the company strategically preparing to address these hurdles?\n",
    "\n",
    "5. What insights can be concluded from the earnings call?\n",
    "\n",
    "6. Which key news events influenced the stock performance, and what insights do they offer?\n",
    "\n",
    "---\n",
    "\n",
    "## Project Requirements\n",
    "- #### Data Source Restriction:\n",
    "Only use the provided data and documents. No external data or information is allowed.\n",
    "\n",
    "- #### Answer Generation:\n",
    "All generated answers must strictly be based on the provided data and documents. The LLM should not \"invent\" information.\n",
    "\n",
    "- #### Clear Logic and Causal Relationships:\n",
    "For each question, your answers must clearly demonstrate logical reasoning, and any attribution of cause must be explicitly linked to events in the data.\n",
    "\n",
    "- #### Prompt Design:\n",
    "You must design your own prompts for calling the local LLM to ensure that the responses are generated strictly based on the analysis results.\n",
    "\n",
    "- #### Result Evaluation:\n",
    "After generating the answers, implement an evaluation step to assess whether the responses meet the above requirements in terms of data reliance, logical clarity, and correct causation.\n",
    "\n",
    "- #### Please put the answers to these 6 questions in a dict at the end of your submitted Python nodebook file.\n",
    "\n",
    "For example\n",
    "```code\n",
    "{ \"Q1 answer\": \"Answer1\", \"Q2 answer\": \"Answer2\", \"Q3 answer\": \"Answer3\", \"Q4 answer4\": \"Answer4\", \"Q5 answer\": \"Answer5\", \"Q6 answer\": \"Answer6\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9bdfc",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "* Transformers\n",
    "* Torch (PyTorch)\n",
    "* Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ba393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/spear1/.local/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in /home/spear1/.local/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (1.3.5)\n",
      "Requirement already satisfied: filelock in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/spear1/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/spear1/.local/lib/python3.10/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/spear1/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/spear1/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/spear1/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/spear1/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/spear1/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/spear1/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers accelerate pandas\n",
    "# %pip install torch # Install PyTorch if you dont have it downloading \n",
    "\n",
    "DATA_DIR = \"447_dataset\"\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290d56f",
   "metadata": {},
   "source": [
    "## Loading and Running the Local LLM\n",
    "\n",
    "1. **Imports Transformers utilities**  \n",
    "   - `AutoModelForCausalLM`: generic class for loading any GPT‑style model  \n",
    "   - `AutoTokenizer`: matching tokenizer for converting text ↔ tokens  \n",
    "   - `pipeline`: high‑level helper that ties model + tokenizer into one callable  \n",
    "\n",
    "2. **Specifies the model repository**  \n",
    "   ```python\n",
    "   model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d52b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# The pipeline will automatically use the model and tokenizer you just loaded\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) # Load the tokenizer\n",
    "\n",
    " # Create a pipeline for text generation\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 2000, # Limit the number of tokens generated\n",
    "    \"return_full_text\": False, # Return only the generated text\n",
    "    \"do_sample\": True, # Use sampling to generate text\n",
    "    \"temperature\": 0.1,# Control the randomness of the output\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"top_p\": 0.9, # Control the diversity of the output\n",
    "    \"top_k\": 50, # Control the diversity of the output\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1d4bb",
   "metadata": {},
   "source": [
    "### Question 1:What is the performance of the Tesla stock during this period (Jan 22 to Feb 5)?\n",
    "\n",
    "#### Prompt construction\n",
    "\n",
    "* Here we need to monitor the performance of the tesla stock over the specified days. To monitor the performance of the stock the LLM just need to understand the how the pricing of the stock was through the given period hence why the LLM will need to see the infomation in the `prices.json` file.\n",
    "* To supplement the LLM to construct its answer we will also show the information in `balancesheet.json` so it can pickup on any trends to as why stock prices deviated and change through the mentioned days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55617ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-22: Open $416.81, High $428.00, Low $414.59, Close $415.11, Volume 60,963,300\n",
      "2025-01-23: Open $416.06, High $420.73, Low $408.95, Close $412.38, Volume 50,690,600\n",
      "2025-01-24: Open $414.45, High $418.88, Low $405.78, Close $406.58, Volume 56,427,100\n",
      "2025-01-27: Open $394.80, High $406.69, Low $389.00, Close $397.15, Volume 58,125,500\n",
      "2025-01-28: Open $396.91, High $400.59, Low $386.50, Close $398.09, Volume 48,910,700\n",
      "2025-01-29: Open $395.21, High $398.59, Low $384.48, Close $389.10, Volume 68,033,600\n",
      "2025-01-30: Open $410.78, High $412.50, Low $384.41, Close $400.28, Volume 98,092,900\n",
      "2025-01-31: Open $401.53, High $419.99, Low $401.34, Close $404.60, Volume 83,568,200\n",
      "2025-02-03: Open $386.68, High $389.17, Low $374.36, Close $383.68, Volume 93,732,100\n",
      "2025-02-04: Open $382.63, High $394.00, Low $381.40, Close $392.21, Volume 57,072,200\n",
      "2025-02-05: Open $387.51, High $388.39, Low $375.53, Close $378.17, Volume 57,223,300\n"
     ]
    }
   ],
   "source": [
    "\"\"\"   \n",
    "This Function extracts the price information and converts the informations\n",
    "into a simple readable format to be included in the prompt to the LLM\n",
    "\"\"\"\n",
    "def get_prices_summary():\n",
    "    prices_path = os.path.join(DATA_DIR, \"prices.json\")\n",
    "\n",
    "    # Load raw JSON into a DataFrame\n",
    "    with open(prices_path, \"r\") as f:\n",
    "        prices = pd.DataFrame(json.load(f))\n",
    "\n",
    "    # Parse dates and index\n",
    "    prices[\"Date\"] = pd.to_datetime(prices[\"Date\"])\n",
    "    prices = prices.set_index(\"Date\").sort_index()\n",
    "\n",
    "    # Build a human-readable summary for each day\n",
    "    daily_summaries = []\n",
    "    for date, row in prices.iterrows():\n",
    "        daily_summaries.append(\n",
    "            f\"{date.strftime('%Y-%m-%d')}: \"\n",
    "            f\"Open ${row['Open']:.2f}, \"\n",
    "            f\"High ${row['Hight']:.2f}, \"\n",
    "            f\"Low ${row['Low']:.2f}, \"\n",
    "            f\"Close ${row['Close']:.2f}, \"\n",
    "            f\"Volume {int(row['Volume']):,}\"\n",
    "        )\n",
    "\n",
    "    # Join them into one block of text\n",
    "    daily_summary_text = \"\\n\".join(daily_summaries)\n",
    "    return daily_summary_text\n",
    "\n",
    "print(get_prices_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e33e7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I need to figure out how to analyze the performance of Tesla stock from January 22 to February 5 based on the given data. Let me start by understanding what's being asked.\n",
      "\n",
      "First, the user wants a detailed analysis using only the data summaries provided. They also specified some criteria like using only the data, showing steps, explaining clearly, etc. So, I should make sure I follow those guidelines.\n",
      "\n",
      "Looking at the data, it's structured as daily closing prices along with volume and trading volume. Each date has its own set of numbers. I'll need to go through each day, note the price changes, see if there were any significant drops or rises, and consider the impact of these changes on the stock.\n",
      "\n",
      "Starting with January 22, the stock opened at $416.81 and closed slightly lower at $415.11. That's a small decrease. Then on January 23, it went up a bit to $412.38 but still didn't reach the previous day's high. On January 24, it dropped further to $406.58, which might have been due to market conditions or other factors. \n",
      "\n",
      "On January 27, the stock started to recover a bit, rising to $397.15 before dropping again on January 28 to $398.09. This suggests some volatility during the week. On January 29, it peaked at $389.10 before dropping again on January 30 to $400.28. There seems to be a pattern where the stock tends to rise after a dip.\n",
      "\n",
      "Moving into February, starting on January 31, the stock dipped to $383.68, then rose slightly on February 3 to $383.68, and then on February 4, it increased more to $392.21. By February 5, it dropped again to $378.17. This shows that even though the stock had some recovery, it didn't fully recover and ended the week lower than it started.\n",
      "\n",
      "I should calculate the percentage changes to understand the magnitude of these movements. For example, from $416.81 to $415.11 is a decrease of about 0.4%. On the other hand, from $397.15 to $398.09 is an increase of roughly 0.2%.\n",
      "\n",
      "Also, looking at the volume numbers can give insight into market sentiment. Higher volumes often indicate more interest or activity, which can affect stock prices. However, without specific data points, it's hard to say exactly how much volume influenced the price changes.\n",
      "\n",
      "Another thing to consider is whether there were any external factors affecting Tesla's performance during this period. For instance, economic events, company news, or global markets could have impacted the stock. But since the data doesn't specify such factors, I'll focus solely on the internal movements.\n",
      "\n",
      "In terms of trends, the stock showed signs of volatility, especially between January 24 and 28, and again between January 30 and 31. It recovered a bit on February 4 but then dropped again on February 5. This indicates that while there was some recovery, the stock wasn't able to fully recover from its lowest point.\n",
      "\n",
      "Overall, the stock performed relatively well compared to its initial low on January 22, but it struggled to recover enough to overcome the initial loss. The weekly fluctuations suggest that Tesla's performance isn't consistent and can be affected by various market conditions.\n",
      "\n",
      "To summarize, the key points are the daily price movements, the percentage changes, the recurring patterns of increases and decreases, and the lack of sustained recovery beyond the initial dip. These observations help in understanding the stock's performance over the given period.\n",
      "</think>\n",
      "\n",
      "### Introduction\n",
      "\n",
      "The analysis focuses on Tesla's stock performance from January 22 to February 5, examining daily price movements, percentage changes, and recurring patterns. The goal is to evaluate the stock's behavior and identify any causal insights.\n",
      "\n",
      "---\n",
      "\n",
      "### Analysis\n",
      "\n",
      "#### Data Overview\n",
      "- **Dates**: January 22 to February 5\n",
      "- **Key Metrics**: Closing price, volume, percentage change, and trend direction\n",
      "\n",
      "#### Performance Breakdown\n",
      "\n",
      "1. **January 22-23**\n",
      "   - **Price Movement**: Decrease from $416.81 to $415.11 (0.4%)\n",
      "   - **Trend**: Decline\n",
      "\n",
      "2. **January 24**\n",
      "   - **Price Movement**: Further decline to $406.58 (-1.4%)\n",
      "\n",
      "3. **January 27-28**\n",
      "   - **Price Movement**: Recovery to $397.15 (+0.2%) then slight rise to $398.09 (+0.2%)\n",
      "\n",
      "4. **January 29-30**\n",
      "   - **Price Movement**: Drop to $389.10 (-0.8%)\n",
      "\n",
      "5. **January 31**\n",
      "   - **Price Movement**: Further decline to $383.68 (-1.5%)\n",
      "\n",
      "6. **February 3-4**\n",
      "   - **Price Movement**: Small increase to $383.68 (+0.1%), then rise to $392.21 (+0.5%)\n",
      "\n",
      "7. **February 5**\n",
      "   - **Price Movement**: Drop to $378.17 (-2.3%)\n",
      "\n",
      "#### Percentage Changes\n",
      "- **January 22-23**: -0.4%\n",
      "- **January 24**: -1.4%\n",
      "- **January 27-28**: +0.2%\n",
      "- **January 29-30**: -0.8%\n",
      "- **January 31**: -1.5%\n",
      "- **February 3-4**: +0.1%\n",
      "- **February 5**: -2.3%\n",
      "\n",
      "#### Volume Analysis\n",
      "- **January 22**: 60,963,300\n",
      "- **January 23**: 50,690,600\n",
      "- **January 24**: 56,427,100\n",
      "- **January 27**: 58,125,500\n",
      "- **January 28**: 48,910,700\n",
      "- **January 29**: 68,033,600\n",
      "- **February 3**: 93,732,100\n",
      "- **February 4**: 57,072,200\n",
      "- **February 5**: 57,223,300\n",
      "\n",
      "#### Trends and Patterns\n",
      "- **Recovery Pattern**: The stock experienced partial recovery on February 4 but failed to sustain it, ending the week lower than the start.\n",
      "- **Volatility**: Weekly fluctuations indicated instability, suggesting external factors may influence stock performance.\n",
      "\n",
      "#### Causal Insights\n",
      "- **Market Sentiment**: Volatility likely reflects investor sentiment, influenced by broader market conditions.\n",
      "- **External Factors**: While data does not specify, market dynamics and economic indicators could play roles.\n",
      "\n",
      "---\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Tesla's stock demonstrated moderate performance from January 22 to February 5, with notable declines and recoveries. The stock exhibited recurring volatility, suggesting instability influenced by external factors. The lack of sustained recovery beyond the initial dip highlights the challenges Tesla faces in maintaining consistent performance.\n"
     ]
    }
   ],
   "source": [
    "system_prompt_q1 = ( \n",
    "    \"You are an expert financial data analyst LLM.\\n\"\n",
    "    \"Please ensure that bellow rules are followed:\\n\"\n",
    "    \"1. Use only the data summaries provided in the prompt\\n\"\n",
    "    \"2. Show clear step-by-step reasoning , linking each claim to the data.\\n\"\n",
    "    \"3. The explanation is clear, logical, and accurate.\\n\"\n",
    "    \"4. Do not invent or hallucinate any information.\\n\"\n",
    "    \"After your answer, provide a checklist summary indicating whether each criterion is satisfied. \"\n",
    "    \"If any criterion is not met, include a brief explanation.\"\n",
    ")\n",
    "\n",
    "user_prompt_template_q1 =( \"\"\"\n",
    "    Here is the summarized Tesla data for Jan 22 - Feb 5:\n",
    "    {price_info}\n",
    "\n",
    "    **Question:**  \n",
    "    What was the performance of Tesla stock over this period?\n",
    "                          \n",
    "    **Please:**\n",
    "    - Write a brief **Introduction** stating the question and data scope.  \n",
    "    - In your **Analysis**, cite the exact figures (dates, prices, percent changes, volumes).  \n",
    "    - Draw any causal insights clearly (e.g., “the drop on Feb 1 may be linked to…”).  \n",
    "    - Finish with a concise **Conclusion** summarizing overall performance.\n",
    "\"\"\")\n",
    "\n",
    "# Fill in the template with specific data\n",
    "filled_user_prompt = user_prompt_template_q1.format(\n",
    "    price_info = get_prices_summary()\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_q1},\n",
    "    {\"role\": \"user\", \"content\": filled_user_prompt},\n",
    "]\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
